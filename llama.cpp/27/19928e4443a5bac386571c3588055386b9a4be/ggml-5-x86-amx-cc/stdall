Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu
Collecting numpy~=1.26.4
  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)
Collecting sentencepiece~=0.2.0
  Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
Collecting transformers<5.0.0,>=4.45.1
  Using cached transformers-4.45.2-py3-none-any.whl (9.9 MB)
Collecting gguf>=0.1.0
  Downloading gguf-0.10.0-py3-none-any.whl (71 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.6/71.6 KB 3.1 MB/s eta 0:00:00
Collecting protobuf<5.0.0,>=4.21.0
  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.6/294.6 KB 7.9 MB/s eta 0:00:00
Collecting torch~=2.2.1
  Using cached https://download.pytorch.org/whl/cpu/torch-2.2.2%2Bcpu-cp310-cp310-linux_x86_64.whl (186.8 MB)
Collecting huggingface-hub<1.0,>=0.23.2
  Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 436.6/436.6 KB 12.4 MB/s eta 0:00:00
Collecting regex!=2019.12.17
  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 782.7/782.7 KB 16.6 MB/s eta 0:00:00
Collecting safetensors>=0.4.1
  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 435.0/435.0 KB 16.3 MB/s eta 0:00:00
Collecting tokenizers<0.21,>=0.20
  Using cached tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
Collecting pyyaml>=5.1
  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)
Collecting filelock
  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)
Collecting tqdm>=4.27
  Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)
Collecting requests
  Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Collecting packaging>=20.0
  Using cached packaging-24.1-py3-none-any.whl (53 kB)
Collecting sympy
  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 41.9 MB/s eta 0:00:00
Collecting networkx
  Downloading networkx-3.4.1-py3-none-any.whl (1.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 58.1 MB/s eta 0:00:00
Collecting typing-extensions>=4.8.0
  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Collecting jinja2
  Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)
Collecting fsspec
  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 179.3/179.3 KB 21.3 MB/s eta 0:00:00
Collecting MarkupSafe>=2.0
  Downloading MarkupSafe-3.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)
Collecting certifi>=2017.4.17
  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.3/167.3 KB 23.1 MB/s eta 0:00:00
Collecting charset-normalizer<4,>=2
  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 144.8/144.8 KB 17.9 MB/s eta 0:00:00
Collecting urllib3<3,>=1.21.1
  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.3/126.3 KB 19.3 MB/s eta 0:00:00
Collecting idna<4,>=2.5
  Downloading idna-3.10-py3-none-any.whl (70 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 70.4/70.4 KB 9.1 MB/s eta 0:00:00
Collecting mpmath<1.4,>=1.1.0
  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
Installing collected packages: sentencepiece, mpmath, urllib3, typing-extensions, tqdm, sympy, safetensors, regex, pyyaml, protobuf, packaging, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, jinja2, gguf, torch, huggingface-hub, tokenizers, transformers
Successfully installed MarkupSafe-3.0.1 certifi-2024.8.30 charset-normalizer-3.4.0 filelock-3.16.1 fsspec-2024.9.0 gguf-0.10.0 huggingface-hub-0.25.2 idna-3.10 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.1 numpy-1.26.4 packaging-24.1 protobuf-4.25.5 pyyaml-6.0.2 regex-2024.9.11 requests-2.32.3 safetensors-0.4.5 sentencepiece-0.2.0 sympy-1.13.3 tokenizers-0.20.1 torch-2.2.2+cpu tqdm-4.66.5 transformers-4.45.2 typing-extensions-4.12.2 urllib3-2.2.3
Obtaining file:///home/ggml/work/llama.cpp/gguf-py
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: sentencepiece<=0.2.0,>=0.1.98 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from gguf==0.10.0) (0.2.0)
Requirement already satisfied: numpy>=1.17 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from gguf==0.10.0) (1.26.4)
Requirement already satisfied: pyyaml>=5.1 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from gguf==0.10.0) (6.0.2)
Requirement already satisfied: tqdm>=4.27 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from gguf==0.10.0) (4.66.5)
Building wheels for collected packages: gguf
  Building editable for gguf (pyproject.toml): started
  Building editable for gguf (pyproject.toml): finished with status 'done'
  Created wheel for gguf: filename=gguf-0.10.0-py3-none-any.whl size=3392 sha256=f4071d478eb6306f859cf6bc7d6c80844fb0458194dca98571766b758355bf49
  Stored in directory: /tmp/pip-ephem-wheel-cache-ui4zd8ke/wheels/a3/4c/52/c5934ad001d1a70ca5434f11ddc622cad9c0a484e9bf6feda3
Successfully built gguf
Installing collected packages: gguf
  Attempting uninstall: gguf
    Found existing installation: gguf 0.10.0
    Uninstalling gguf-0.10.0:
      Successfully uninstalled gguf-0.10.0
Successfully installed gguf-0.10.0
+ gg_run_ctest_debug
+ cd /home/ggml/work/llama.cpp
+ rm -rf build-ci-debug
+ tee /home/ggml/results/llama.cpp/27/19928e4443a5bac386571c3588055386b9a4be/ggml-5-x86-amx-cc/ctest_debug.log
+ mkdir build-ci-debug
+ cd build-ci-debug
+ set -e
+ gg_check_build_requirements
+ command -v cmake
+ command -v make
+ command -v ctest
+ tee -a /home/ggml/results/llama.cpp/27/19928e4443a5bac386571c3588055386b9a4be/ggml-5-x86-amx-cc/ctest_debug-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_FATAL_WARNINGS=ON ..
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1") 
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- Found OpenMP_C: -fopenmp (found version "4.5") 
-- Found OpenMP_CXX: -fopenmp (found version "4.5") 
-- Found OpenMP: TRUE (found version "4.5")  
-- OpenMP found
-- Using llamafile
-- Using AMX
-- ccache found, compilation results will be cached. Disable with GGML_CCACHE=OFF.
-- CMAKE_SYSTEM_PROCESSOR: x86_64
-- x86 detected
-- Configuring done
-- Generating done
-- Build files have been written to: /home/ggml/work/llama.cpp/build-ci-debug

real	0m0.928s
user	0m0.640s
sys	0m0.292s
+ tee -a /home/ggml/results/llama.cpp/27/19928e4443a5bac386571c3588055386b9a4be/ggml-5-x86-amx-cc/ctest_debug-make.log
++ nproc
+ make -j8
[  1%] Building C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o
[  2%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  3%] Building C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o
[  3%] Building C object ggml/src/CMakeFiles/ggml.dir/ggml.c.o
[  4%] Building C object ggml/src/CMakeFiles/ggml.dir/ggml-alloc.c.o
[  5%] Building C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o
[  5%] Building C object ggml/src/CMakeFiles/ggml.dir/ggml-quants.c.o
[  5%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend.cpp.o
[  5%] Built target sha1
[  5%] Built target sha256
[  5%] Built target xxhash
[  5%] Building CXX object ggml/src/CMakeFiles/ggml.dir/llamafile/sgemm.cpp.o
[  6%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-amx/mmq.cpp.o
[  7%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-amx.cpp.o
[  7%] Built target build_info
[  7%] Building C object ggml/src/CMakeFiles/ggml.dir/ggml-aarch64.c.o
In file included from /home/ggml/work/llama.cpp/ggml/src/./ggml-cpu-impl.h:6,
                 from /home/ggml/work/llama.cpp/ggml/src/ggml-amx/common.h:4,
                 from /home/ggml/work/llama.cpp/ggml/src/ggml-amx.cpp:2:
/home/ggml/work/llama.cpp/ggml/src/./ggml-impl.h:23:26: error: expected unqualified-id before numeric constant
   23 | #define TENSOR_ALIGNMENT 32
      |                          ^~
/home/ggml/work/llama.cpp/ggml/src/ggml-amx.cpp:18:21: note: in expansion of macro ‘TENSOR_ALIGNMENT’
   18 | static const size_t TENSOR_ALIGNMENT = 64;
      |                     ^~~~~~~~~~~~~~~~
make[2]: *** [ggml/src/CMakeFiles/ggml.dir/build.make:160: ggml/src/CMakeFiles/ggml.dir/ggml-amx.cpp.o] Error 1
make[2]: *** Waiting for unfinished jobs....
make[1]: *** [CMakeFiles/Makefile2:1591: ggml/src/CMakeFiles/ggml.dir/all] Error 2
make: *** [Makefile:146: all] Error 2

real	0m1.432s
user	0m5.414s
sys	0m0.686s
+ cur=2
+ echo 2
+ set +x
cat: /home/ggml/results/llama.cpp/27/19928e4443a5bac386571c3588055386b9a4be/ggml-5-x86-amx-cc/ctest_debug-ctest.log: No such file or directory
