+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_FATAL_WARNINGS=ON -DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=native ..
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1") 
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- ccache found, compilation results will be cached. Disable with GGML_CCACHE=OFF.
-- CMAKE_SYSTEM_PROCESSOR: x86_64
-- Including CPU backend
-- Found OpenMP_C: -fopenmp (found version "4.5") 
-- Found OpenMP_CXX: -fopenmp (found version "4.5") 
-- Found OpenMP: TRUE (found version "4.5")  
-- x86 detected
-- Adding CPU backend variant ggml-cpu: -march=native 
-- Found CUDAToolkit: /usr/local/cuda-12.2/include (found version "12.2.140") 
-- CUDA Toolkit found
-- Using CUDA architectures: native
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda-12.2/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- CUDA host compiler is GNU 11.4.0

-- Including CUDA backend
-- Configuring done (9.0s)
-- Generating done (0.2s)
-- Build files have been written to: /home/ggml/work/llama.cpp/build-ci-debug

real	0m9.290s
user	0m7.340s
sys	0m1.958s
++ nproc
+ make -j6
[  0%] Generating build details from Git
[  1%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o
[  1%] Building C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o
[  2%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o
[  2%] Building C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o
[  3%] Building C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o
-- Found Git: /usr/bin/git (found version "2.34.1") 
[  3%] Built target sha1
[  3%] Built target sha256
[  4%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o
[  4%] Built target xxhash
[  4%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o
[  5%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o
[  5%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o
[  5%] Linking CXX shared library libggml-base.so
[  5%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  5%] Built target build_info
[  5%] Built target ggml-base
[  5%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o
[  6%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o
[  6%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o
[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o
[  7%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o
[  7%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o
[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o
[  8%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o
[  8%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o
[  8%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o
[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o
[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o
[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o
[ 10%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o
[ 11%] Linking CXX shared library libggml-cpu.so
[ 11%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o
[ 11%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o
[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o
[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o
[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o
[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o
[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o
[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o
[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o
[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o
[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o
[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o
[ 16%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o
[ 16%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o
[ 16%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o
[ 17%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmv.cu.o
[ 17%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o
[ 17%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o
[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o
[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o
[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o
[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o
[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o
[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o
[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o
[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o
[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o
[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o
[ 21%] Built target ggml-cpu
[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o
[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o
[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o
[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv6.cu.o
[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu.o
[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu.o
[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu.o
[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu.o
[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu.o
[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o
[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o
[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o
[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o
[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o
[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o
[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o
[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o
[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o
[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o
[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o
[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o
[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o
[ 30%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o
[ 30%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o
[ 31%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o
[ 31%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o
[ 31%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o
[ 32%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o
[ 32%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o
[ 32%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o
[ 33%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o
[ 33%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o
[ 34%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o
[ 34%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o
[ 34%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o
[ 35%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o
[ 35%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o
[ 35%] Linking CUDA shared library libggml-cuda.so
[ 35%] Built target ggml-cuda
[ 35%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o
[ 35%] Linking CXX shared library libggml.so
[ 35%] Built target ggml
[ 35%] Building CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o
[ 36%] Building CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o
[ 36%] Building CXX object src/CMakeFiles/llama.dir/llama.cpp.o
[ 36%] Building CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o
[ 37%] Building CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o
[ 37%] Building CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o
[ 38%] Linking CXX executable ../../bin/llama-gguf
[ 38%] Linking CXX executable ../../bin/llama-gguf-hash
[ 38%] Built target llama-gguf
[ 38%] Building CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o
[ 38%] Built target llama-gguf-hash
[ 39%] Building CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o
[ 39%] Building CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o
[ 39%] Building CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o
[ 40%] Building CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o
[ 40%] Building CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o
[ 41%] Building CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o
[ 41%] Building CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp: In function ‘bool llama_kv_cache_seq_rm(llama_kv_cache&, llama_seq_id, llama_pos, llama_pos)’:
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:370:27: error: ‘numeric_limits’ is not a member of ‘std’
  370 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                           ^~~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:370:51: error: expected primary-expression before ‘>’ token
  370 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                                                   ^
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:370:54: error: ‘::max’ has not been declared; did you mean ‘std::max’?
  370 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                                                      ^~~
      |                                                      std::max
In file included from /usr/include/c++/11/algorithm:62,
                 from /home/ggml/work/llama.cpp/src/llama-batch.h:7,
                 from /home/ggml/work/llama.cpp/src/llama-kv-cache.h:3,
                 from /home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:1:
/usr/include/c++/11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here
 3467 |     max(initializer_list<_Tp> __l, _Compare __comp)
      |     ^~~
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:393:52: error: ‘numeric_limits’ is not a member of ‘std’
  393 |             if (p0 != p1 && (p0 != 0 || p1 != std::numeric_limits<llama_pos>::max())) {
      |                                                    ^~~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:393:76: error: expected primary-expression before ‘>’ token
  393 |             if (p0 != p1 && (p0 != 0 || p1 != std::numeric_limits<llama_pos>::max())) {
      |                                                                            ^
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:393:79: error: ‘::max’ has not been declared; did you mean ‘std::max’?
  393 |             if (p0 != p1 && (p0 != 0 || p1 != std::numeric_limits<llama_pos>::max())) {
      |                                                                               ^~~
      |                                                                               std::max
In file included from /usr/include/c++/11/algorithm:62,
                 from /home/ggml/work/llama.cpp/src/llama-batch.h:7,
                 from /home/ggml/work/llama.cpp/src/llama-kv-cache.h:3,
                 from /home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:1:
/usr/include/c++/11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here
 3467 |     max(initializer_list<_Tp> __l, _Compare __comp)
      |     ^~~
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp: In function ‘void llama_kv_cache_seq_cp(llama_kv_cache&, llama_seq_id, llama_seq_id, llama_pos, llama_pos)’:
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:432:27: error: ‘numeric_limits’ is not a member of ‘std’
  432 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                           ^~~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:432:51: error: expected primary-expression before ‘>’ token
  432 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                                                   ^
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:432:54: error: ‘::max’ has not been declared; did you mean ‘std::max’?
  432 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                                                      ^~~
      |                                                      std::max
In file included from /usr/include/c++/11/algorithm:62,
                 from /home/ggml/work/llama.cpp/src/llama-batch.h:7,
                 from /home/ggml/work/llama.cpp/src/llama-kv-cache.h:3,
                 from /home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:1:
/usr/include/c++/11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here
 3467 |     max(initializer_list<_Tp> __l, _Compare __comp)
      |     ^~~
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp: In function ‘void llama_kv_cache_seq_add(llama_kv_cache&, llama_seq_id, llama_pos, llama_pos, llama_pos)’:
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:504:27: error: ‘numeric_limits’ is not a member of ‘std’
  504 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                           ^~~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:504:51: error: expected primary-expression before ‘>’ token
  504 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                                                   ^
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:504:54: error: ‘::max’ has not been declared; did you mean ‘std::max’?
  504 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                                                      ^~~
      |                                                      std::max
In file included from /usr/include/c++/11/algorithm:62,
                 from /home/ggml/work/llama.cpp/src/llama-batch.h:7,
                 from /home/ggml/work/llama.cpp/src/llama-kv-cache.h:3,
                 from /home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:1:
/usr/include/c++/11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here
 3467 |     max(initializer_list<_Tp> __l, _Compare __comp)
      |     ^~~
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp: In function ‘void llama_kv_cache_seq_div(llama_kv_cache&, llama_seq_id, llama_pos, llama_pos, int)’:
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:553:27: error: ‘numeric_limits’ is not a member of ‘std’
  553 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                           ^~~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:553:51: error: expected primary-expression before ‘>’ token
  553 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                                                   ^
/home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:553:54: error: ‘::max’ has not been declared; did you mean ‘std::max’?
  553 |     if (p1 < 0) p1 = std::numeric_limits<llama_pos>::max();
      |                                                      ^~~
      |                                                      std::max
In file included from /usr/include/c++/11/algorithm:62,
                 from /home/ggml/work/llama.cpp/src/llama-batch.h:7,
                 from /home/ggml/work/llama.cpp/src/llama-kv-cache.h:3,
                 from /home/ggml/work/llama.cpp/src/llama-kv-cache.cpp:1:
/usr/include/c++/11/bits/stl_algo.h:3467:5: note: ‘std::max’ declared here
 3467 |     max(initializer_list<_Tp> __l, _Compare __comp)
      |     ^~~
make[2]: *** [src/CMakeFiles/llama.dir/build.make:188: src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o] Error 1
make[2]: *** Waiting for unfinished jobs....
make[1]: *** [CMakeFiles/Makefile2:1813: src/CMakeFiles/llama.dir/all] Error 2
make: *** [Makefile:146: all] Error 2

real	0m11.042s
user	0m22.202s
sys	0m2.970s
