## Summary

- status:  FAILURE ‚ùå (2)
- runtime: 0:11.19
- date:    Mon Feb 19 08:26:00 UTC 2024
- repo:    https://github.com/ggerganov/llama.cpp
- commit:  https://github.com/ggerganov/llama.cpp/commit/4480542b2271ba1438f0daff8e5f3a74b1dc8609
- author:  NawafAlansari
```
baby-llama : allocate graphs in ggml_context (#5573)

* Fixed the baby-llama issue (see issue #4830)

* minor : fix whitespaces

---------

Co-authored-by: Georgi Gerganov <ggerganov@gmail.com>
```

## Environment

```
GG_BUILD_CUDA=1
GG_BUILD_CXX_COMPILER=g++
GG_BUILD_C_COMPILER=gcc
```

## Output

### ctest_debug

Runs ctest in debug mode
- status: 2
```

```

