+ gg_run_ctest_debug
+ cd /home/ggml/work/llama.cpp
+ rm -rf build-ci-debug
+ tee /home/ggml/results/llama.cpp/8a/22f2a0c0ebc175d30c8257a1eee8eec8819334/ggml-0-x86-cpu-low-perf/ctest_debug.log
+ mkdir build-ci-debug
+ cd build-ci-debug
+ set -e
+ gg_check_build_requirements
+ command -v cmake
+ command -v make
+ command -v ctest
+ tee -a /home/ggml/results/llama.cpp/8a/22f2a0c0ebc175d30c8257a1eee8eec8819334/ggml-0-x86-cpu-low-perf/ctest_debug-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_FATAL_WARNINGS=ON ..
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1") 
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- Found OpenMP_C: -fopenmp (found version "4.5") 
-- Found OpenMP_CXX: -fopenmp (found version "4.5") 
-- Found OpenMP: TRUE (found version "4.5")  
-- OpenMP found
-- Using llamafile
-- ccache found, compilation results will be cached. Disable with GGML_CCACHE=OFF.
-- CMAKE_SYSTEM_PROCESSOR: x86_64
-- x86 detected
-- Configuring done (0.6s)
-- Generating done (0.1s)
-- Build files have been written to: /home/ggml/work/llama.cpp/build-ci-debug

real	0m0.706s
user	0m0.532s
sys	0m0.176s
+ tee -a /home/ggml/results/llama.cpp/8a/22f2a0c0ebc175d30c8257a1eee8eec8819334/ggml-0-x86-cpu-low-perf/ctest_debug-make.log
++ nproc
+ make -j4
[  0%] Generating build details from Git
[  1%] Building C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o
[  1%] Building C object ggml/src/CMakeFiles/ggml.dir/ggml.c.o
[  1%] Building C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o
-- Found Git: /usr/bin/git (found version "2.34.1") 
[  1%] Built target sha256
[  1%] Built target xxhash
[  2%] Building C object ggml/src/CMakeFiles/ggml.dir/ggml-alloc.c.o
[  2%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend.cpp.o
[  3%] Building C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o
[  4%] Building C object ggml/src/CMakeFiles/ggml.dir/ggml-quants.c.o
[  4%] Built target sha1
[  4%] Building CXX object ggml/src/CMakeFiles/ggml.dir/llamafile/sgemm.cpp.o
[  5%] Building C object ggml/src/CMakeFiles/ggml.dir/ggml-aarch64.c.o
[  6%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  7%] Linking CXX shared library libggml.so
[  7%] Built target build_info
[  7%] Built target ggml
[  8%] Building CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o
[  8%] Building CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o
[  9%] Building CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o
[  9%] Building CXX object src/CMakeFiles/llama.dir/llama.cpp.o
[ 10%] Linking CXX executable ../../bin/llama-gguf
[ 10%] Linking CXX executable ../../bin/llama-gguf-hash
[ 10%] Built target llama-gguf-hash
[ 10%] Built target llama-gguf
[ 10%] Building CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o
[ 11%] Building CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o
[ 11%] Building CXX object src/CMakeFiles/llama.dir/unicode.cpp.o
[ 12%] Building CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o
[ 13%] Linking CXX shared library libllama.so
[ 13%] Built target llama
[ 15%] Building CXX object examples/llava/CMakeFiles/llava.dir/llava.cpp.o
[ 15%] Building C object tests/CMakeFiles/test-c.dir/test-c.c.o
[ 16%] Building CXX object common/CMakeFiles/common.dir/arg.cpp.o
[ 16%] Building CXX object examples/quantize-stats/CMakeFiles/llama-quantize-stats.dir/quantize-stats.cpp.o
[ 16%] Linking C executable ../bin/test-c
[ 16%] Built target test-c
[ 16%] Building CXX object examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o
[ 17%] Linking CXX executable ../../bin/llama-simple
[ 17%] Building CXX object examples/llava/CMakeFiles/llava.dir/clip.cpp.o
[ 17%] Built target llava
[ 17%] Linking CXX static library libllava_static.a
[ 17%] Built target llama-simple
[ 18%] Linking CXX shared library libllava_shared.so
[ 18%] Built target llava_static
[ 19%] Building CXX object common/CMakeFiles/common.dir/common.cpp.o
[ 19%] Built target llava_shared
[ 19%] Building CXX object common/CMakeFiles/common.dir/console.cpp.o
[ 20%] Building CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o
[ 20%] Building CXX object common/CMakeFiles/common.dir/log.cpp.o
[ 21%] Building CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o
[ 22%] Building CXX object common/CMakeFiles/common.dir/sampling.cpp.o
/home/ggml/work/llama.cpp/common/sampling.cpp: In function ‘std::vector<common_sampler_type> common_sampler_types_from_chars(const string&)’:
/home/ggml/work/llama.cpp/common/sampling.cpp:458:9: error: expected ‘}’ before ‘{’ token
  458 |         { common_sampler_type_to_chr(COMMON_SAMPLER_TYPE_INFILL),      COMMON_SAMPLER_TYPE_INFILL },
      |         ^
/home/ggml/work/llama.cpp/common/sampling.cpp:450:70: note: to match this ‘{’
  450 |     std::unordered_map<char, common_sampler_type> sampler_name_map = {
      |                                                                      ^
/home/ggml/work/llama.cpp/common/sampling.cpp:458:9: error: expected ‘,’ or ‘;’ before ‘{’ token
  458 |         { common_sampler_type_to_chr(COMMON_SAMPLER_TYPE_INFILL),      COMMON_SAMPLER_TYPE_INFILL },
      |         ^
/home/ggml/work/llama.cpp/common/sampling.cpp:458:100: error: expected primary-expression before ‘,’ token
  458 |         { common_sampler_type_to_chr(COMMON_SAMPLER_TYPE_INFILL),      COMMON_SAMPLER_TYPE_INFILL },
      |                                                                                                    ^
/home/ggml/work/llama.cpp/common/sampling.cpp:459:5: error: expected primary-expression before ‘}’ token
  459 |     };
      |     ^
/home/ggml/work/llama.cpp/common/sampling.cpp:459:5: warning: no return statement in function returning non-void [-Wreturn-type]
/home/ggml/work/llama.cpp/common/sampling.cpp: At global scope:
/home/ggml/work/llama.cpp/common/sampling.cpp:462:5: error: ‘samplers’ does not name a type
  462 |     samplers.reserve(chars.size());
      |     ^~~~~~~~
/home/ggml/work/llama.cpp/common/sampling.cpp:464:5: error: expected unqualified-id before ‘for’
  464 |     for (const auto & c : chars) {
      |     ^~~
/home/ggml/work/llama.cpp/common/sampling.cpp:471:5: error: expected unqualified-id before ‘return’
  471 |     return samplers;
      |     ^~~~~~
/home/ggml/work/llama.cpp/common/sampling.cpp:472:1: error: expected declaration before ‘}’ token
  472 | }
      | ^
make[2]: *** [common/CMakeFiles/common.dir/build.make:160: common/CMakeFiles/common.dir/sampling.cpp.o] Error 1
make[2]: *** Waiting for unfinished jobs....
[ 22%] Linking CXX executable ../../bin/llama-quantize-stats
[ 22%] Built target llama-quantize-stats
make[1]: *** [CMakeFiles/Makefile2:1671: common/CMakeFiles/common.dir/all] Error 2
make: *** [Makefile:146: all] Error 2

real	0m14.982s
user	0m30.807s
sys	0m2.566s
+ cur=2
+ echo 2
+ set +x
cat: /home/ggml/results/llama.cpp/8a/22f2a0c0ebc175d30c8257a1eee8eec8819334/ggml-0-x86-cpu-low-perf/ctest_debug-ctest.log: No such file or directory
