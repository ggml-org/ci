++ nproc
+ make -j8
[  0%] Generating build details from Git
[  2%] Building C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o
[  2%] Building C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o
[  3%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o
[  3%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o
[  3%] Building C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o
[  3%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o
[  4%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o
-- Found Git: /usr/bin/git (found version "2.34.1") 
[  4%] Built target sha256
[  4%] Built target sha1
[  4%] Built target xxhash
[  4%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o
[  5%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o
[  5%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o
[  5%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  6%] Linking CXX shared library ../../bin/libggml-base.so
[  6%] Built target build_info
[  6%] Built target ggml-base
[  7%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o
[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o
[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o
[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o
[  9%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o
[  9%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o
[  9%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o
[  9%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o
[ 10%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o
[ 10%] Linking CXX shared library ../../bin/libggml-cpu.so
[ 10%] Built target ggml-cpu
[ 10%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o
[ 11%] Linking CXX shared library ../../bin/libggml.so
[ 11%] Built target ggml
[ 11%] Building CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o
[ 11%] Building CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o
[ 12%] Building CXX object src/CMakeFiles/llama.dir/llama.cpp.o
[ 12%] Building CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o
[ 12%] Building CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o
[ 14%] Building CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o
[ 14%] Building CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o
[ 14%] Building CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o
[ 15%] Linking CXX executable ../../bin/llama-gguf
[ 16%] Building CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o
[ 17%] Linking CXX executable ../../bin/llama-gguf-hash
[ 18%] Building CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o
[ 18%] Building CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o
[ 19%] Building CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o
[ 19%] Building CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o
[ 19%] Building CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o
[ 20%] Building CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o
[ 20%] Building CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o
[ 20%] Building CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o
[ 21%] Building CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o
[ 21%] Building CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o
[ 22%] Building CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o
[ 22%] Building CXX object src/CMakeFiles/llama.dir/unicode.cpp.o
[ 23%] Building CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_inp_s_copy(ggml_context*, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:5:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
    5 | ggml_tensor * llama_graph_i::build_inp_s_copy(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_inp_s_mask(ggml_context*, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:15:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   15 | ggml_tensor * llama_graph_i::build_inp_s_mask(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_copy_mask_state(ggml_context*, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int32_t, int32_t, int32_t, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:25:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   25 | ggml_tensor * llama_graph_i::build_copy_mask_state(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_mamba_layer(ggml_context*, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, const llama_ubatch&, int, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:49:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   49 | ggml_tensor * llama_graph_i::build_mamba_layer(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_rwkv_token_shift_load(ggml_context*, ggml_cgraph*, ggml_tensor*, ggml_tensor*, const llama_ubatch&, int, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:71:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   71 | ggml_tensor * llama_graph_i::build_rwkv_token_shift_load(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_rwkv_token_shift_store(ggml_context*, ggml_tensor*, const llama_ubatch&, int, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:91:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   91 | ggml_tensor * llama_graph_i::build_rwkv_token_shift_store(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_rwkv6_time_mix(ggml_context*, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, const llama_ubatch&, int, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:107:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
  107 | ggml_tensor * llama_graph_i::build_rwkv6_time_mix(
      |               ^~~~~~~~~~~~~
cc1plus: all warnings being treated as errors
make[2]: *** [src/CMakeFiles/llama.dir/build.make:174: src/CMakeFiles/llama.dir/llama-graph.cpp.o] Error 1
make[2]: *** Waiting for unfinished jobs....
make[1]: *** [CMakeFiles/Makefile2:1771: src/CMakeFiles/llama.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
[ 23%] Built target llama-gguf-hash
[ 23%] Built target llama-gguf
make: *** [Makefile:146: all] Error 2

real	0m0.629s
user	0m0.964s
sys	0m0.673s
