+ ./bin/main --model ../models-mnt/open-llama/3B-v2/ggml-model-q8_0.gguf -s 1234 -n 64 --ignore-eos -p 'I believe the meaning of life is'
Log start
main: build = 1470 (f39e607)
main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu
main: seed  = 1234
llama_model_loader: loaded meta data with 19 key-value pairs and 237 tensors from ../models-mnt/open-llama/3B-v2/ggml-model-q8_0.gguf (version GGUF V3 (latest))
llama_model_loader: - tensor    0:                token_embd.weight q8_0     [  3200, 32000,     1,     1 ]
llama_model_loader: - tensor    1:              blk.0.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor    2:              blk.0.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor    3:              blk.0.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor    4:         blk.0.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor    6:            blk.0.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor    7:              blk.0.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   10:              blk.1.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   11:              blk.1.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   12:              blk.1.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   13:         blk.1.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   15:            blk.1.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   16:              blk.1.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   19:              blk.2.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   20:              blk.2.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   21:              blk.2.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   22:         blk.2.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   24:            blk.2.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   25:              blk.2.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   28:              blk.3.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   29:              blk.3.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   30:              blk.3.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   31:         blk.3.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   33:            blk.3.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   34:              blk.3.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   37:              blk.4.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   38:              blk.4.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   39:              blk.4.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   40:         blk.4.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   42:            blk.4.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   43:              blk.4.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   46:              blk.5.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   47:              blk.5.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   48:              blk.5.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   49:         blk.5.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   51:            blk.5.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   52:              blk.5.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   55:              blk.6.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   56:              blk.6.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   57:              blk.6.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   58:         blk.6.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   60:            blk.6.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   61:              blk.6.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   64:              blk.7.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   65:              blk.7.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   66:              blk.7.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   67:         blk.7.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   69:            blk.7.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   70:              blk.7.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   73:              blk.8.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   74:              blk.8.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   75:              blk.8.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   76:         blk.8.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   78:            blk.8.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   79:              blk.8.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   82:              blk.9.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   83:              blk.9.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   84:              blk.9.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   85:         blk.9.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   87:            blk.9.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   88:              blk.9.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   91:             blk.10.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   92:             blk.10.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   93:             blk.10.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   94:        blk.10.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   96:           blk.10.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   97:             blk.10.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  100:             blk.11.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  101:             blk.11.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  102:             blk.11.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  103:        blk.11.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  105:           blk.11.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  106:             blk.11.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  109:             blk.12.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  110:             blk.12.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  111:             blk.12.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  112:        blk.12.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  114:           blk.12.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  115:             blk.12.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  118:             blk.13.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  119:             blk.13.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  120:             blk.13.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  121:        blk.13.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  123:           blk.13.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  124:             blk.13.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  127:             blk.14.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  128:             blk.14.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  129:             blk.14.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  130:        blk.14.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  132:           blk.14.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  133:             blk.14.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  136:             blk.15.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  137:             blk.15.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  138:             blk.15.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  139:        blk.15.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  141:           blk.15.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  142:             blk.15.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  145:             blk.16.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  146:             blk.16.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  147:             blk.16.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  148:        blk.16.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  150:           blk.16.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  151:             blk.16.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  154:             blk.17.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  155:             blk.17.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  156:             blk.17.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  157:        blk.17.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  159:           blk.17.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  160:             blk.17.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  163:             blk.18.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  164:             blk.18.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  165:             blk.18.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  166:        blk.18.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  168:           blk.18.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  169:             blk.18.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  172:             blk.19.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  173:             blk.19.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  174:             blk.19.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  175:        blk.19.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  177:           blk.19.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  178:             blk.19.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  181:             blk.20.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  182:             blk.20.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  183:             blk.20.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  184:        blk.20.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  186:           blk.20.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  187:             blk.20.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  190:             blk.21.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  191:             blk.21.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  192:             blk.21.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  193:        blk.21.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  195:           blk.21.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  196:             blk.21.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  199:             blk.22.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  200:             blk.22.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  201:             blk.22.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  202:        blk.22.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  204:           blk.22.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  205:             blk.22.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  208:             blk.23.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  209:             blk.23.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  210:             blk.23.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  211:        blk.23.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  213:           blk.23.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  214:             blk.23.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  217:             blk.24.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  218:             blk.24.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  219:             blk.24.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  220:        blk.24.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  222:           blk.24.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  223:             blk.24.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  226:             blk.25.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  227:             blk.25.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  228:             blk.25.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  229:        blk.25.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  231:           blk.25.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  232:             blk.25.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  235:               output_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  236:                    output.weight q8_0     [  3200, 32000,     1,     1 ]
llama_model_loader: - kv   0:                       general.architecture str     
llama_model_loader: - kv   1:                               general.name str     
llama_model_loader: - kv   2:                       llama.context_length u32     
llama_model_loader: - kv   3:                     llama.embedding_length u32     
llama_model_loader: - kv   4:                          llama.block_count u32     
llama_model_loader: - kv   5:                  llama.feed_forward_length u32     
llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     
llama_model_loader: - kv   7:                 llama.attention.head_count u32     
llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     
llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     
llama_model_loader: - kv  10:                          general.file_type u32     
llama_model_loader: - kv  11:                       tokenizer.ggml.model str     
llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     
llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     
llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     
llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     
llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     
llama_model_loader: - kv  17:            tokenizer.ggml.padding_token_id u32     
llama_model_loader: - kv  18:               general.quantization_version u32     
llama_model_loader: - type  f32:   53 tensors
llama_model_loader: - type q8_0:  184 tensors
llm_load_vocab: special tokens definition check successful ( 259/32000 ).
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = llama
llm_load_print_meta: vocab type       = SPM
llm_load_print_meta: n_vocab          = 32000
llm_load_print_meta: n_merges         = 0
llm_load_print_meta: n_ctx_train      = 2048
llm_load_print_meta: n_embd           = 3200
llm_load_print_meta: n_head           = 32
llm_load_print_meta: n_head_kv        = 32
llm_load_print_meta: n_layer          = 26
llm_load_print_meta: n_rot            = 100
llm_load_print_meta: n_gqa            = 1
llm_load_print_meta: f_norm_eps       = 0.0e+00
llm_load_print_meta: f_norm_rms_eps   = 1.0e-06
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: n_ff             = 8640
llm_load_print_meta: freq_base_train  = 10000.0
llm_load_print_meta: freq_scale_train = 1
llm_load_print_meta: model type       = 3B
llm_load_print_meta: model ftype      = mostly Q8_0
llm_load_print_meta: model params     = 3.43 B
llm_load_print_meta: model size       = 3.39 GiB (8.50 BPW) 
llm_load_print_meta: general.name   = open-llama
llm_load_print_meta: BOS token = 1 '<s>'
llm_load_print_meta: EOS token = 2 '</s>'
llm_load_print_meta: UNK token = 0 '<unk>'
llm_load_print_meta: PAD token = 0 '<unk>'
llm_load_print_meta: LF token  = 13 '<0x0A>'
llm_load_tensors: ggml ctx size =    0.08 MB
llm_load_tensors: mem required  = 3472.53 MB
.................................................................................................
llama_new_context_with_model: n_ctx      = 512
llama_new_context_with_model: freq_base  = 10000.0
llama_new_context_with_model: freq_scale = 1
llama_new_context_with_model: kv self size  =  162.50 MB
operator():                       inp_tokens: not offloaded (ref: https://github.com/ggerganov/llama.cpp/pull/3837)
operator():                         inp_embd: not offloaded (ref: https://github.com/ggerganov/llama.cpp/pull/3837)
operator():                          inp_pos: CPU
operator():                         KQ_scale: not offloaded (ref: https://github.com/ggerganov/llama.cpp/pull/3837)
operator():                          KQ_mask: CPU
operator():                          K_shift: CPU
operator():                           norm-0: CPU
operator():                      attn_norm-0: CPU
operator():                           Qcur-0: CPU
operator():                           Kcur-0: CPU
operator():                           Vcur-0: CPU
operator():                           Qcur-0: CPU
operator():                           Kcur-0: CPU
operator():                             kq-0: CPU
operator():                      kq_scaled-0: CPU
operator():                      kq_masked-0: CPU
operator():                    kq_soft_max-0: CPU
operator():                            kqv-0: CPU
operator():                kqv_merged_cont-0: CPU
operator():                        kqv_out-0: CPU
operator():                          inpFF-0: CPU
operator():                           norm-0: CPU
operator():                       ffn_norm-0: CPU
operator():                         ffn_up-0: CPU
operator():                       ffn_gate-0: CPU
operator():                       ffn_silu-0: CPU
operator():                   ffn_gate_par-0: CPU
operator():                     ffn_result-0: CPU
operator():              inpFF_+_result_w2-0: CPU
operator():                           norm-1: CPU
operator():                      attn_norm-1: CPU
operator():                           Qcur-1: CPU
operator():                           Kcur-1: CPU
operator():                           Vcur-1: CPU
operator():                           Qcur-1: CPU
operator():                           Kcur-1: CPU
operator():                             kq-1: CPU
operator():                      kq_scaled-1: CPU
operator():                      kq_masked-1: CPU
operator():                    kq_soft_max-1: CPU
operator():                            kqv-1: CPU
operator():                kqv_merged_cont-1: CPU
operator():                        kqv_out-1: CPU
operator():                          inpFF-1: CPU
operator():                           norm-1: CPU
operator():                       ffn_norm-1: CPU
operator():                         ffn_up-1: CPU
operator():                       ffn_gate-1: CPU
operator():                       ffn_silu-1: CPU
operator():                   ffn_gate_par-1: CPU
operator():                     ffn_result-1: CPU
operator():              inpFF_+_result_w2-1: CPU
operator():                           norm-2: CPU
operator():                      attn_norm-2: CPU
operator():                           Qcur-2: CPU
operator():                           Kcur-2: CPU
operator():                           Vcur-2: CPU
operator():                           Qcur-2: CPU
operator():                           Kcur-2: CPU
operator():                             kq-2: CPU
operator():                      kq_scaled-2: CPU
operator():                      kq_masked-2: CPU
operator():                    kq_soft_max-2: CPU
operator():                            kqv-2: CPU
operator():                kqv_merged_cont-2: CPU
operator():                        kqv_out-2: CPU
operator():                          inpFF-2: CPU
operator():                           norm-2: CPU
operator():                       ffn_norm-2: CPU
operator():                         ffn_up-2: CPU
operator():                       ffn_gate-2: CPU
operator():                       ffn_silu-2: CPU
operator():                   ffn_gate_par-2: CPU
operator():                     ffn_result-2: CPU
operator():              inpFF_+_result_w2-2: CPU
operator():                           norm-3: CPU
operator():                      attn_norm-3: CPU
operator():                           Qcur-3: CPU
operator():                           Kcur-3: CPU
operator():                           Vcur-3: CPU
operator():                           Qcur-3: CPU
operator():                           Kcur-3: CPU
operator():                             kq-3: CPU
operator():                      kq_scaled-3: CPU
operator():                      kq_masked-3: CPU
operator():                    kq_soft_max-3: CPU
operator():                            kqv-3: CPU
operator():                kqv_merged_cont-3: CPU
operator():                        kqv_out-3: CPU
operator():                          inpFF-3: CPU
operator():                           norm-3: CPU
operator():                       ffn_norm-3: CPU
operator():                         ffn_up-3: CPU
operator():                       ffn_gate-3: CPU
operator():                       ffn_silu-3: CPU
operator():                   ffn_gate_par-3: CPU
operator():                     ffn_result-3: CPU
operator():              inpFF_+_result_w2-3: CPU
operator():                           norm-4: CPU
operator():                      attn_norm-4: CPU
operator():                           Qcur-4: CPU
operator():                           Kcur-4: CPU
operator():                           Vcur-4: CPU
operator():                           Qcur-4: CPU
operator():                           Kcur-4: CPU
operator():                             kq-4: CPU
operator():                      kq_scaled-4: CPU
operator():                      kq_masked-4: CPU
operator():                    kq_soft_max-4: CPU
operator():                            kqv-4: CPU
operator():                kqv_merged_cont-4: CPU
operator():                        kqv_out-4: CPU
operator():                          inpFF-4: CPU
operator():                           norm-4: CPU
operator():                       ffn_norm-4: CPU
operator():                         ffn_up-4: CPU
operator():                       ffn_gate-4: CPU
operator():                       ffn_silu-4: CPU
operator():                   ffn_gate_par-4: CPU
operator():                     ffn_result-4: CPU
operator():              inpFF_+_result_w2-4: CPU
operator():                           norm-5: CPU
operator():                      attn_norm-5: CPU
operator():                           Qcur-5: CPU
operator():                           Kcur-5: CPU
operator():                           Vcur-5: CPU
operator():                           Qcur-5: CPU
operator():                           Kcur-5: CPU
operator():                             kq-5: CPU
operator():                      kq_scaled-5: CPU
operator():                      kq_masked-5: CPU
operator():                    kq_soft_max-5: CPU
operator():                            kqv-5: CPU
operator():                kqv_merged_cont-5: CPU
operator():                        kqv_out-5: CPU
operator():                          inpFF-5: CPU
operator():                           norm-5: CPU
operator():                       ffn_norm-5: CPU
operator():                         ffn_up-5: CPU
operator():                       ffn_gate-5: CPU
operator():                       ffn_silu-5: CPU
operator():                   ffn_gate_par-5: CPU
operator():                     ffn_result-5: CPU
operator():              inpFF_+_result_w2-5: CPU
operator():                           norm-6: CPU
operator():                      attn_norm-6: CPU
operator():                           Qcur-6: CPU
operator():                           Kcur-6: CPU
operator():                           Vcur-6: CPU
operator():                           Qcur-6: CPU
operator():                           Kcur-6: CPU
operator():                             kq-6: CPU
operator():                      kq_scaled-6: CPU
operator():                      kq_masked-6: CPU
operator():                    kq_soft_max-6: CPU
operator():                            kqv-6: CPU
operator():                kqv_merged_cont-6: CPU
operator():                        kqv_out-6: CPU
operator():                          inpFF-6: CPU
operator():                           norm-6: CPU
operator():                       ffn_norm-6: CPU
operator():                         ffn_up-6: CPU
operator():                       ffn_gate-6: CPU
operator():                       ffn_silu-6: CPU
operator():                   ffn_gate_par-6: CPU
operator():                     ffn_result-6: CPU
operator():              inpFF_+_result_w2-6: CPU
operator():                           norm-7: CPU
operator():                      attn_norm-7: CPU
operator():                           Qcur-7: CPU
operator():                           Kcur-7: CPU
operator():                           Vcur-7: CPU
operator():                           Qcur-7: CPU
operator():                           Kcur-7: CPU
operator():                             kq-7: CPU
operator():                      kq_scaled-7: CPU
operator():                      kq_masked-7: CPU
operator():                    kq_soft_max-7: CPU
operator():                            kqv-7: CPU
operator():                kqv_merged_cont-7: CPU
operator():                        kqv_out-7: CPU
operator():                          inpFF-7: CPU
operator():                           norm-7: CPU
operator():                       ffn_norm-7: CPU
operator():                         ffn_up-7: CPU
operator():                       ffn_gate-7: CPU
operator():                       ffn_silu-7: CPU
operator():                   ffn_gate_par-7: CPU
operator():                     ffn_result-7: CPU
operator():              inpFF_+_result_w2-7: CPU
operator():                           norm-8: CPU
operator():                      attn_norm-8: CPU
operator():                           Qcur-8: CPU
operator():                           Kcur-8: CPU
operator():                           Vcur-8: CPU
operator():                           Qcur-8: CPU
operator():                           Kcur-8: CPU
operator():                             kq-8: CPU
operator():                      kq_scaled-8: CPU
operator():                      kq_masked-8: CPU
operator():                    kq_soft_max-8: CPU
operator():                            kqv-8: CPU
operator():                kqv_merged_cont-8: CPU
operator():                        kqv_out-8: CPU
operator():                          inpFF-8: CPU
operator():                           norm-8: CPU
operator():                       ffn_norm-8: CPU
operator():                         ffn_up-8: CPU
operator():                       ffn_gate-8: CPU
operator():                       ffn_silu-8: CPU
operator():                   ffn_gate_par-8: CPU
operator():                     ffn_result-8: CPU
operator():              inpFF_+_result_w2-8: CPU
operator():                           norm-9: CPU
operator():                      attn_norm-9: CPU
operator():                           Qcur-9: CPU
operator():                           Kcur-9: CPU
operator():                           Vcur-9: CPU
operator():                           Qcur-9: CPU
operator():                           Kcur-9: CPU
operator():                             kq-9: CPU
operator():                      kq_scaled-9: CPU
operator():                      kq_masked-9: CPU
operator():                    kq_soft_max-9: CPU
operator():                            kqv-9: CPU
operator():                kqv_merged_cont-9: CPU
operator():                        kqv_out-9: CPU
operator():                          inpFF-9: CPU
operator():                           norm-9: CPU
operator():                       ffn_norm-9: CPU
operator():                         ffn_up-9: CPU
operator():                       ffn_gate-9: CPU
operator():                       ffn_silu-9: CPU
operator():                   ffn_gate_par-9: CPU
operator():                     ffn_result-9: CPU
operator():              inpFF_+_result_w2-9: CPU
operator():                          norm-10: CPU
operator():                     attn_norm-10: CPU
operator():                          Qcur-10: CPU
operator():                          Kcur-10: CPU
operator():                          Vcur-10: CPU
operator():                          Qcur-10: CPU
operator():                          Kcur-10: CPU
operator():                            kq-10: CPU
operator():                     kq_scaled-10: CPU
operator():                     kq_masked-10: CPU
operator():                   kq_soft_max-10: CPU
operator():                           kqv-10: CPU
operator():               kqv_merged_cont-10: CPU
operator():                       kqv_out-10: CPU
operator():                         inpFF-10: CPU
operator():                          norm-10: CPU
operator():                      ffn_norm-10: CPU
operator():                        ffn_up-10: CPU
operator():                      ffn_gate-10: CPU
operator():                      ffn_silu-10: CPU
operator():                  ffn_gate_par-10: CPU
operator():                    ffn_result-10: CPU
operator():             inpFF_+_result_w2-10: CPU
operator():                          norm-11: CPU
operator():                     attn_norm-11: CPU
operator():                          Qcur-11: CPU
operator():                          Kcur-11: CPU
operator():                          Vcur-11: CPU
operator():                          Qcur-11: CPU
operator():                          Kcur-11: CPU
operator():                            kq-11: CPU
operator():                     kq_scaled-11: CPU
operator():                     kq_masked-11: CPU
operator():                   kq_soft_max-11: CPU
operator():                           kqv-11: CPU
operator():               kqv_merged_cont-11: CPU
operator():                       kqv_out-11: CPU
operator():                         inpFF-11: CPU
operator():                          norm-11: CPU
operator():                      ffn_norm-11: CPU
operator():                        ffn_up-11: CPU
operator():                      ffn_gate-11: CPU
operator():                      ffn_silu-11: CPU
operator():                  ffn_gate_par-11: CPU
operator():                    ffn_result-11: CPU
operator():             inpFF_+_result_w2-11: CPU
operator():                          norm-12: CPU
operator():                     attn_norm-12: CPU
operator():                          Qcur-12: CPU
operator():                          Kcur-12: CPU
operator():                          Vcur-12: CPU
operator():                          Qcur-12: CPU
operator():                          Kcur-12: CPU
operator():                            kq-12: CPU
operator():                     kq_scaled-12: CPU
operator():                     kq_masked-12: CPU
operator():                   kq_soft_max-12: CPU
operator():                           kqv-12: CPU
operator():               kqv_merged_cont-12: CPU
operator():                       kqv_out-12: CPU
operator():                         inpFF-12: CPU
operator():                          norm-12: CPU
operator():                      ffn_norm-12: CPU
operator():                        ffn_up-12: CPU
operator():                      ffn_gate-12: CPU
operator():                      ffn_silu-12: CPU
operator():                  ffn_gate_par-12: CPU
operator():                    ffn_result-12: CPU
operator():             inpFF_+_result_w2-12: CPU
operator():                          norm-13: CPU
operator():                     attn_norm-13: CPU
operator():                          Qcur-13: CPU
operator():                          Kcur-13: CPU
operator():                          Vcur-13: CPU
operator():                          Qcur-13: CPU
operator():                          Kcur-13: CPU
operator():                            kq-13: CPU
operator():                     kq_scaled-13: CPU
operator():                     kq_masked-13: CPU
operator():                   kq_soft_max-13: CPU
operator():                           kqv-13: CPU
operator():               kqv_merged_cont-13: CPU
operator():                       kqv_out-13: CPU
operator():                         inpFF-13: CPU
operator():                          norm-13: CPU
operator():                      ffn_norm-13: CPU
operator():                        ffn_up-13: CPU
operator():                      ffn_gate-13: CPU
operator():                      ffn_silu-13: CPU
operator():                  ffn_gate_par-13: CPU
operator():                    ffn_result-13: CPU
operator():             inpFF_+_result_w2-13: CPU
operator():                          norm-14: CPU
operator():                     attn_norm-14: CPU
operator():                          Qcur-14: CPU
operator():                          Kcur-14: CPU
operator():                          Vcur-14: CPU
operator():                          Qcur-14: CPU
operator():                          Kcur-14: CPU
operator():                            kq-14: CPU
operator():                     kq_scaled-14: CPU
operator():                     kq_masked-14: CPU
operator():                   kq_soft_max-14: CPU
operator():                           kqv-14: CPU
operator():               kqv_merged_cont-14: CPU
operator():                       kqv_out-14: CPU
operator():                         inpFF-14: CPU
operator():                          norm-14: CPU
operator():                      ffn_norm-14: CPU
operator():                        ffn_up-14: CPU
operator():                      ffn_gate-14: CPU
operator():                      ffn_silu-14: CPU
operator():                  ffn_gate_par-14: CPU
operator():                    ffn_result-14: CPU
operator():             inpFF_+_result_w2-14: CPU
operator():                          norm-15: CPU
operator():                     attn_norm-15: CPU
operator():                          Qcur-15: CPU
operator():                          Kcur-15: CPU
operator():                          Vcur-15: CPU
operator():                          Qcur-15: CPU
operator():                          Kcur-15: CPU
operator():                            kq-15: CPU
operator():                     kq_scaled-15: CPU
operator():                     kq_masked-15: CPU
operator():                   kq_soft_max-15: CPU
operator():                           kqv-15: CPU
operator():               kqv_merged_cont-15: CPU
operator():                       kqv_out-15: CPU
operator():                         inpFF-15: CPU
operator():                          norm-15: CPU
operator():                      ffn_norm-15: CPU
operator():                        ffn_up-15: CPU
operator():                      ffn_gate-15: CPU
operator():                      ffn_silu-15: CPU
operator():                  ffn_gate_par-15: CPU
operator():                    ffn_result-15: CPU
operator():             inpFF_+_result_w2-15: CPU
operator():                          norm-16: CPU
operator():                     attn_norm-16: CPU
operator():                          Qcur-16: CPU
operator():                          Kcur-16: CPU
operator():                          Vcur-16: CPU
operator():                          Qcur-16: CPU
operator():                          Kcur-16: CPU
operator():                            kq-16: CPU
operator():                     kq_scaled-16: CPU
operator():                     kq_masked-16: CPU
operator():                   kq_soft_max-16: CPU
operator():                           kqv-16: CPU
operator():               kqv_merged_cont-16: CPU
operator():                       kqv_out-16: CPU
operator():                         inpFF-16: CPU
operator():                          norm-16: CPU
operator():                      ffn_norm-16: CPU
operator():                        ffn_up-16: CPU
operator():                      ffn_gate-16: CPU
operator():                      ffn_silu-16: CPU
operator():                  ffn_gate_par-16: CPU
operator():                    ffn_result-16: CPU
operator():             inpFF_+_result_w2-16: CPU
operator():                          norm-17: CPU
operator():                     attn_norm-17: CPU
operator():                          Qcur-17: CPU
operator():                          Kcur-17: CPU
operator():                          Vcur-17: CPU
operator():                          Qcur-17: CPU
operator():                          Kcur-17: CPU
operator():                            kq-17: CPU
operator():                     kq_scaled-17: CPU
operator():                     kq_masked-17: CPU
operator():                   kq_soft_max-17: CPU
operator():                           kqv-17: CPU
operator():               kqv_merged_cont-17: CPU
operator():                       kqv_out-17: CPU
operator():                         inpFF-17: CPU
operator():                          norm-17: CPU
operator():                      ffn_norm-17: CPU
operator():                        ffn_up-17: CPU
operator():                      ffn_gate-17: CPU
operator():                      ffn_silu-17: CPU
operator():                  ffn_gate_par-17: CPU
operator():                    ffn_result-17: CPU
operator():             inpFF_+_result_w2-17: CPU
operator():                          norm-18: CPU
operator():                     attn_norm-18: CPU
operator():                          Qcur-18: CPU
operator():                          Kcur-18: CPU
operator():                          Vcur-18: CPU
operator():                          Qcur-18: CPU
operator():                          Kcur-18: CPU
operator():                            kq-18: CPU
operator():                     kq_scaled-18: CPU
operator():                     kq_masked-18: CPU
operator():                   kq_soft_max-18: CPU
operator():                           kqv-18: CPU
operator():               kqv_merged_cont-18: CPU
operator():                       kqv_out-18: CPU
operator():                         inpFF-18: CPU
operator():                          norm-18: CPU
operator():                      ffn_norm-18: CPU
operator():                        ffn_up-18: CPU
operator():                      ffn_gate-18: CPU
operator():                      ffn_silu-18: CPU
operator():                  ffn_gate_par-18: CPU
operator():                    ffn_result-18: CPU
operator():             inpFF_+_result_w2-18: CPU
operator():                          norm-19: CPU
operator():                     attn_norm-19: CPU
operator():                          Qcur-19: CPU
operator():                          Kcur-19: CPU
operator():                          Vcur-19: CPU
operator():                          Qcur-19: CPU
operator():                          Kcur-19: CPU
operator():                            kq-19: CPU
operator():                     kq_scaled-19: CPU
operator():                     kq_masked-19: CPU
operator():                   kq_soft_max-19: CPU
operator():                           kqv-19: CPU
operator():               kqv_merged_cont-19: CPU
operator():                       kqv_out-19: CPU
operator():                         inpFF-19: CPU
operator():                          norm-19: CPU
operator():                      ffn_norm-19: CPU
operator():                        ffn_up-19: CPU
operator():                      ffn_gate-19: CPU
operator():                      ffn_silu-19: CPU
operator():                  ffn_gate_par-19: CPU
operator():                    ffn_result-19: CPU
operator():             inpFF_+_result_w2-19: CPU
operator():                          norm-20: CPU
operator():                     attn_norm-20: CPU
operator():                          Qcur-20: CPU
operator():                          Kcur-20: CPU
operator():                          Vcur-20: CPU
operator():                          Qcur-20: CPU
operator():                          Kcur-20: CPU
operator():                            kq-20: CPU
operator():                     kq_scaled-20: CPU
operator():                     kq_masked-20: CPU
operator():                   kq_soft_max-20: CPU
operator():                           kqv-20: CPU
operator():               kqv_merged_cont-20: CPU
operator():                       kqv_out-20: CPU
operator():                         inpFF-20: CPU
operator():                          norm-20: CPU
operator():                      ffn_norm-20: CPU
operator():                        ffn_up-20: CPU
operator():                      ffn_gate-20: CPU
operator():                      ffn_silu-20: CPU
operator():                  ffn_gate_par-20: CPU
operator():                    ffn_result-20: CPU
operator():             inpFF_+_result_w2-20: CPU
operator():                          norm-21: CPU
operator():                     attn_norm-21: CPU
operator():                          Qcur-21: CPU
operator():                          Kcur-21: CPU
operator():                          Vcur-21: CPU
operator():                          Qcur-21: CPU
operator():                          Kcur-21: CPU
operator():                            kq-21: CPU
operator():                     kq_scaled-21: CPU
operator():                     kq_masked-21: CPU
operator():                   kq_soft_max-21: CPU
operator():                           kqv-21: CPU
operator():               kqv_merged_cont-21: CPU
operator():                       kqv_out-21: CPU
operator():                         inpFF-21: CPU
operator():                          norm-21: CPU
operator():                      ffn_norm-21: CPU
operator():                        ffn_up-21: CPU
operator():                      ffn_gate-21: CPU
operator():                      ffn_silu-21: CPU
operator():                  ffn_gate_par-21: CPU
operator():                    ffn_result-21: CPU
operator():             inpFF_+_result_w2-21: CPU
operator():                          norm-22: CPU
operator():                     attn_norm-22: CPU
operator():                          Qcur-22: CPU
operator():                          Kcur-22: CPU
operator():                          Vcur-22: CPU
operator():                          Qcur-22: CPU
operator():                          Kcur-22: CPU
operator():                            kq-22: CPU
operator():                     kq_scaled-22: CPU
operator():                     kq_masked-22: CPU
operator():                   kq_soft_max-22: CPU
operator():                           kqv-22: CPU
operator():               kqv_merged_cont-22: CPU
operator():                       kqv_out-22: CPU
operator():                         inpFF-22: CPU
operator():                          norm-22: CPU
operator():                      ffn_norm-22: CPU
operator():                        ffn_up-22: CPU
operator():                      ffn_gate-22: CPU
operator():                      ffn_silu-22: CPU
operator():                  ffn_gate_par-22: CPU
operator():                    ffn_result-22: CPU
operator():             inpFF_+_result_w2-22: CPU
operator():                          norm-23: CPU
operator():                     attn_norm-23: CPU
operator():                          Qcur-23: CPU
operator():                          Kcur-23: CPU
operator():                          Vcur-23: CPU
operator():                          Qcur-23: CPU
operator():                          Kcur-23: CPU
operator():                            kq-23: CPU
operator():                     kq_scaled-23: CPU
operator():                     kq_masked-23: CPU
operator():                   kq_soft_max-23: CPU
operator():                           kqv-23: CPU
operator():               kqv_merged_cont-23: CPU
operator():                       kqv_out-23: CPU
operator():                         inpFF-23: CPU
operator():                          norm-23: CPU
operator():                      ffn_norm-23: CPU
operator():                        ffn_up-23: CPU
operator():                      ffn_gate-23: CPU
operator():                      ffn_silu-23: CPU
operator():                  ffn_gate_par-23: CPU
operator():                    ffn_result-23: CPU
operator():             inpFF_+_result_w2-23: CPU
operator():                          norm-24: CPU
operator():                     attn_norm-24: CPU
operator():                          Qcur-24: CPU
operator():                          Kcur-24: CPU
operator():                          Vcur-24: CPU
operator():                          Qcur-24: CPU
operator():                          Kcur-24: CPU
operator():                            kq-24: CPU
operator():                     kq_scaled-24: CPU
operator():                     kq_masked-24: CPU
operator():                   kq_soft_max-24: CPU
operator():                           kqv-24: CPU
operator():               kqv_merged_cont-24: CPU
operator():                       kqv_out-24: CPU
operator():                         inpFF-24: CPU
operator():                          norm-24: CPU
operator():                      ffn_norm-24: CPU
operator():                        ffn_up-24: CPU
operator():                      ffn_gate-24: CPU
operator():                      ffn_silu-24: CPU
operator():                  ffn_gate_par-24: CPU
operator():                    ffn_result-24: CPU
operator():             inpFF_+_result_w2-24: CPU
operator():                          norm-25: CPU
operator():                     attn_norm-25: CPU
operator():                          Qcur-25: CPU
operator():                          Kcur-25: CPU
operator():                          Vcur-25: CPU
operator():                          Qcur-25: CPU
operator():                          Kcur-25: CPU
operator():                            kq-25: CPU
operator():                     kq_scaled-25: CPU
operator():                     kq_masked-25: CPU
operator():                   kq_soft_max-25: CPU
operator():                           kqv-25: CPU
operator():               kqv_merged_cont-25: CPU
operator():                       kqv_out-25: CPU
operator():                         inpFF-25: CPU
operator():                          norm-25: CPU
operator():                      ffn_norm-25: CPU
operator():                        ffn_up-25: CPU
operator():                      ffn_gate-25: CPU
operator():                      ffn_silu-25: CPU
operator():                  ffn_gate_par-25: CPU
operator():                    ffn_result-25: CPU
operator():             inpFF_+_result_w2-25: CPU
operator():                             norm: CPU
operator():                      result_norm: CPU
operator():                    result_output: CPU
llama_new_context_with_model: compute buffer total size = 74.88 MB

system_info: n_threads = 4 / 8 | AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | 
sampling: 
	repeat_last_n = 64, repeat_penalty = 1.100, frequency_penalty = 0.000, presence_penalty = 0.000
	top_k = 40, tfs_z = 1.000, top_p = 0.950, typical_p = 1.000, temp = 0.800
	mirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000
generate: n_ctx = 512, n_batch = 512, n_predict = 64, n_keep = 0


I believe the meaning of life is to do something great for humanity. My goal in this project was simply that, I wanted my work on society or human beings and how we live our lives has a purpose greater than ourselves as well..
With these values above everything else it would be an honor if people could see what they are capable of creating within themselves
llama_print_timings:        load time =     362.83 ms
llama_print_timings:      sample time =      12.47 ms /    64 runs   (    0.19 ms per token,  5132.32 tokens per second)
llama_print_timings: prompt eval time =     355.52 ms /     8 tokens (   44.44 ms per token,    22.50 tokens per second)
llama_print_timings:        eval time =    6165.97 ms /    63 runs   (   97.87 ms per token,    10.22 tokens per second)
llama_print_timings:       total time =    6552.68 ms
Log end

real	0m7.178s
user	0m26.581s
sys	0m0.476s
+ ./bin/perplexity --model ../models-mnt/open-llama/3B-v2/ggml-model-q8_0.gguf -f ../models-mnt/wikitext/wikitext-2-raw/wiki.test-60.raw -c 128 -b 128 --chunks 2
main: build = 1470 (f39e607)
main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu
main: seed  = 1698612841
llama_model_loader: loaded meta data with 19 key-value pairs and 237 tensors from ../models-mnt/open-llama/3B-v2/ggml-model-q8_0.gguf (version GGUF V3 (latest))
llama_model_loader: - tensor    0:                token_embd.weight q8_0     [  3200, 32000,     1,     1 ]
llama_model_loader: - tensor    1:              blk.0.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor    2:              blk.0.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor    3:              blk.0.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor    4:         blk.0.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor    6:            blk.0.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor    7:              blk.0.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   10:              blk.1.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   11:              blk.1.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   12:              blk.1.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   13:         blk.1.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   15:            blk.1.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   16:              blk.1.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   19:              blk.2.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   20:              blk.2.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   21:              blk.2.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   22:         blk.2.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   24:            blk.2.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   25:              blk.2.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   28:              blk.3.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   29:              blk.3.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   30:              blk.3.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   31:         blk.3.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   33:            blk.3.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   34:              blk.3.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   37:              blk.4.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   38:              blk.4.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   39:              blk.4.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   40:         blk.4.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   42:            blk.4.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   43:              blk.4.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   46:              blk.5.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   47:              blk.5.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   48:              blk.5.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   49:         blk.5.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   51:            blk.5.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   52:              blk.5.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   55:              blk.6.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   56:              blk.6.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   57:              blk.6.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   58:         blk.6.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   60:            blk.6.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   61:              blk.6.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   64:              blk.7.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   65:              blk.7.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   66:              blk.7.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   67:         blk.7.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   69:            blk.7.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   70:              blk.7.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   73:              blk.8.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   74:              blk.8.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   75:              blk.8.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   76:         blk.8.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   78:            blk.8.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   79:              blk.8.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   82:              blk.9.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   83:              blk.9.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   84:              blk.9.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   85:         blk.9.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   87:            blk.9.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   88:              blk.9.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   91:             blk.10.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   92:             blk.10.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   93:             blk.10.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   94:        blk.10.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   96:           blk.10.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor   97:             blk.10.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  100:             blk.11.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  101:             blk.11.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  102:             blk.11.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  103:        blk.11.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  105:           blk.11.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  106:             blk.11.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  109:             blk.12.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  110:             blk.12.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  111:             blk.12.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  112:        blk.12.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  114:           blk.12.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  115:             blk.12.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  118:             blk.13.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  119:             blk.13.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  120:             blk.13.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  121:        blk.13.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  123:           blk.13.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  124:             blk.13.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  127:             blk.14.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  128:             blk.14.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  129:             blk.14.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  130:        blk.14.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  132:           blk.14.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  133:             blk.14.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  136:             blk.15.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  137:             blk.15.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  138:             blk.15.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  139:        blk.15.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  141:           blk.15.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  142:             blk.15.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  145:             blk.16.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  146:             blk.16.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  147:             blk.16.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  148:        blk.16.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  150:           blk.16.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  151:             blk.16.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  154:             blk.17.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  155:             blk.17.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  156:             blk.17.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  157:        blk.17.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  159:           blk.17.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  160:             blk.17.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  163:             blk.18.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  164:             blk.18.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  165:             blk.18.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  166:        blk.18.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  168:           blk.18.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  169:             blk.18.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  172:             blk.19.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  173:             blk.19.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  174:             blk.19.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  175:        blk.19.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  177:           blk.19.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  178:             blk.19.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  181:             blk.20.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  182:             blk.20.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  183:             blk.20.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  184:        blk.20.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  186:           blk.20.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  187:             blk.20.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  190:             blk.21.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  191:             blk.21.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  192:             blk.21.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  193:        blk.21.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  195:           blk.21.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  196:             blk.21.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  199:             blk.22.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  200:             blk.22.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  201:             blk.22.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  202:        blk.22.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  204:           blk.22.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  205:             blk.22.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  208:             blk.23.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  209:             blk.23.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  210:             blk.23.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  211:        blk.23.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  213:           blk.23.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  214:             blk.23.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  217:             blk.24.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  218:             blk.24.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  219:             blk.24.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  220:        blk.24.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  222:           blk.24.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  223:             blk.24.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  226:             blk.25.attn_q.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  227:             blk.25.attn_k.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  228:             blk.25.attn_v.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  229:        blk.25.attn_output.weight q8_0     [  3200,  3200,     1,     1 ]
llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  231:           blk.25.ffn_down.weight q8_0     [  8640,  3200,     1,     1 ]
llama_model_loader: - tensor  232:             blk.25.ffn_up.weight q8_0     [  3200,  8640,     1,     1 ]
llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  235:               output_norm.weight f32      [  3200,     1,     1,     1 ]
llama_model_loader: - tensor  236:                    output.weight q8_0     [  3200, 32000,     1,     1 ]
llama_model_loader: - kv   0:                       general.architecture str     
llama_model_loader: - kv   1:                               general.name str     
llama_model_loader: - kv   2:                       llama.context_length u32     
llama_model_loader: - kv   3:                     llama.embedding_length u32     
llama_model_loader: - kv   4:                          llama.block_count u32     
llama_model_loader: - kv   5:                  llama.feed_forward_length u32     
llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     
llama_model_loader: - kv   7:                 llama.attention.head_count u32     
llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     
llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     
llama_model_loader: - kv  10:                          general.file_type u32     
llama_model_loader: - kv  11:                       tokenizer.ggml.model str     
llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     
llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     
llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     
llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     
llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     
llama_model_loader: - kv  17:            tokenizer.ggml.padding_token_id u32     
llama_model_loader: - kv  18:               general.quantization_version u32     
llama_model_loader: - type  f32:   53 tensors
llama_model_loader: - type q8_0:  184 tensors
llm_load_vocab: special tokens definition check successful ( 259/32000 ).
llm_load_print_meta: format           = GGUF V3 (latest)
llm_load_print_meta: arch             = llama
llm_load_print_meta: vocab type       = SPM
llm_load_print_meta: n_vocab          = 32000
llm_load_print_meta: n_merges         = 0
llm_load_print_meta: n_ctx_train      = 2048
llm_load_print_meta: n_embd           = 3200
llm_load_print_meta: n_head           = 32
llm_load_print_meta: n_head_kv        = 32
llm_load_print_meta: n_layer          = 26
llm_load_print_meta: n_rot            = 100
llm_load_print_meta: n_gqa            = 1
llm_load_print_meta: f_norm_eps       = 0.0e+00
llm_load_print_meta: f_norm_rms_eps   = 1.0e-06
llm_load_print_meta: f_clamp_kqv      = 0.0e+00
llm_load_print_meta: f_max_alibi_bias = 0.0e+00
llm_load_print_meta: n_ff             = 8640
llm_load_print_meta: freq_base_train  = 10000.0
llm_load_print_meta: freq_scale_train = 1
llm_load_print_meta: model type       = 3B
llm_load_print_meta: model ftype      = mostly Q8_0
llm_load_print_meta: model params     = 3.43 B
llm_load_print_meta: model size       = 3.39 GiB (8.50 BPW) 
llm_load_print_meta: general.name   = open-llama
llm_load_print_meta: BOS token = 1 '<s>'
llm_load_print_meta: EOS token = 2 '</s>'
llm_load_print_meta: UNK token = 0 '<unk>'
llm_load_print_meta: PAD token = 0 '<unk>'
llm_load_print_meta: LF token  = 13 '<0x0A>'
llm_load_tensors: ggml ctx size =    0.08 MB
llm_load_tensors: mem required  = 3472.53 MB
.................................................................................................
llama_new_context_with_model: n_ctx      = 128
llama_new_context_with_model: freq_base  = 10000.0
llama_new_context_with_model: freq_scale = 1
llama_new_context_with_model: kv self size  =   40.62 MB
operator():                       inp_tokens: not offloaded (ref: https://github.com/ggerganov/llama.cpp/pull/3837)
operator():                         inp_embd: not offloaded (ref: https://github.com/ggerganov/llama.cpp/pull/3837)
operator():                          inp_pos: CPU
operator():                         KQ_scale: not offloaded (ref: https://github.com/ggerganov/llama.cpp/pull/3837)
operator():                          KQ_mask: CPU
operator():                          K_shift: CPU
operator():                           norm-0: CPU
operator():                      attn_norm-0: CPU
operator():                           Qcur-0: CPU
operator():                           Kcur-0: CPU
operator():                           Vcur-0: CPU
operator():                           Qcur-0: CPU
operator():                           Kcur-0: CPU
operator():                             kq-0: CPU
operator():                      kq_scaled-0: CPU
operator():                      kq_masked-0: CPU
operator():                    kq_soft_max-0: CPU
operator():                            kqv-0: CPU
operator():                kqv_merged_cont-0: CPU
operator():                        kqv_out-0: CPU
operator():                          inpFF-0: CPU
operator():                           norm-0: CPU
operator():                       ffn_norm-0: CPU
operator():                         ffn_up-0: CPU
operator():                       ffn_gate-0: CPU
operator():                       ffn_silu-0: CPU
operator():                   ffn_gate_par-0: CPU
operator():                     ffn_result-0: CPU
operator():              inpFF_+_result_w2-0: CPU
operator():                           norm-1: CPU
operator():                      attn_norm-1: CPU
operator():                           Qcur-1: CPU
operator():                           Kcur-1: CPU
operator():                           Vcur-1: CPU
operator():                           Qcur-1: CPU
operator():                           Kcur-1: CPU
operator():                             kq-1: CPU
operator():                      kq_scaled-1: CPU
operator():                      kq_masked-1: CPU
operator():                    kq_soft_max-1: CPU
operator():                            kqv-1: CPU
operator():                kqv_merged_cont-1: CPU
operator():                        kqv_out-1: CPU
operator():                          inpFF-1: CPU
operator():                           norm-1: CPU
operator():                       ffn_norm-1: CPU
operator():                         ffn_up-1: CPU
operator():                       ffn_gate-1: CPU
operator():                       ffn_silu-1: CPU
operator():                   ffn_gate_par-1: CPU
operator():                     ffn_result-1: CPU
operator():              inpFF_+_result_w2-1: CPU
operator():                           norm-2: CPU
operator():                      attn_norm-2: CPU
operator():                           Qcur-2: CPU
operator():                           Kcur-2: CPU
operator():                           Vcur-2: CPU
operator():                           Qcur-2: CPU
operator():                           Kcur-2: CPU
operator():                             kq-2: CPU
operator():                      kq_scaled-2: CPU
operator():                      kq_masked-2: CPU
operator():                    kq_soft_max-2: CPU
operator():                            kqv-2: CPU
operator():                kqv_merged_cont-2: CPU
operator():                        kqv_out-2: CPU
operator():                          inpFF-2: CPU
operator():                           norm-2: CPU
operator():                       ffn_norm-2: CPU
operator():                         ffn_up-2: CPU
operator():                       ffn_gate-2: CPU
operator():                       ffn_silu-2: CPU
operator():                   ffn_gate_par-2: CPU
operator():                     ffn_result-2: CPU
operator():              inpFF_+_result_w2-2: CPU
operator():                           norm-3: CPU
operator():                      attn_norm-3: CPU
operator():                           Qcur-3: CPU
operator():                           Kcur-3: CPU
operator():                           Vcur-3: CPU
operator():                           Qcur-3: CPU
operator():                           Kcur-3: CPU
operator():                             kq-3: CPU
operator():                      kq_scaled-3: CPU
operator():                      kq_masked-3: CPU
operator():                    kq_soft_max-3: CPU
operator():                            kqv-3: CPU
operator():                kqv_merged_cont-3: CPU
operator():                        kqv_out-3: CPU
operator():                          inpFF-3: CPU
operator():                           norm-3: CPU
operator():                       ffn_norm-3: CPU
operator():                         ffn_up-3: CPU
operator():                       ffn_gate-3: CPU
operator():                       ffn_silu-3: CPU
operator():                   ffn_gate_par-3: CPU
operator():                     ffn_result-3: CPU
operator():              inpFF_+_result_w2-3: CPU
operator():                           norm-4: CPU
operator():                      attn_norm-4: CPU
operator():                           Qcur-4: CPU
operator():                           Kcur-4: CPU
operator():                           Vcur-4: CPU
operator():                           Qcur-4: CPU
operator():                           Kcur-4: CPU
operator():                             kq-4: CPU
operator():                      kq_scaled-4: CPU
operator():                      kq_masked-4: CPU
operator():                    kq_soft_max-4: CPU
operator():                            kqv-4: CPU
operator():                kqv_merged_cont-4: CPU
operator():                        kqv_out-4: CPU
operator():                          inpFF-4: CPU
operator():                           norm-4: CPU
operator():                       ffn_norm-4: CPU
operator():                         ffn_up-4: CPU
operator():                       ffn_gate-4: CPU
operator():                       ffn_silu-4: CPU
operator():                   ffn_gate_par-4: CPU
operator():                     ffn_result-4: CPU
operator():              inpFF_+_result_w2-4: CPU
operator():                           norm-5: CPU
operator():                      attn_norm-5: CPU
operator():                           Qcur-5: CPU
operator():                           Kcur-5: CPU
operator():                           Vcur-5: CPU
operator():                           Qcur-5: CPU
operator():                           Kcur-5: CPU
operator():                             kq-5: CPU
operator():                      kq_scaled-5: CPU
operator():                      kq_masked-5: CPU
operator():                    kq_soft_max-5: CPU
operator():                            kqv-5: CPU
operator():                kqv_merged_cont-5: CPU
operator():                        kqv_out-5: CPU
operator():                          inpFF-5: CPU
operator():                           norm-5: CPU
operator():                       ffn_norm-5: CPU
operator():                         ffn_up-5: CPU
operator():                       ffn_gate-5: CPU
operator():                       ffn_silu-5: CPU
operator():                   ffn_gate_par-5: CPU
operator():                     ffn_result-5: CPU
operator():              inpFF_+_result_w2-5: CPU
operator():                           norm-6: CPU
operator():                      attn_norm-6: CPU
operator():                           Qcur-6: CPU
operator():                           Kcur-6: CPU
operator():                           Vcur-6: CPU
operator():                           Qcur-6: CPU
operator():                           Kcur-6: CPU
operator():                             kq-6: CPU
operator():                      kq_scaled-6: CPU
operator():                      kq_masked-6: CPU
operator():                    kq_soft_max-6: CPU
operator():                            kqv-6: CPU
operator():                kqv_merged_cont-6: CPU
operator():                        kqv_out-6: CPU
operator():                          inpFF-6: CPU
operator():                           norm-6: CPU
operator():                       ffn_norm-6: CPU
operator():                         ffn_up-6: CPU
operator():                       ffn_gate-6: CPU
operator():                       ffn_silu-6: CPU
operator():                   ffn_gate_par-6: CPU
operator():                     ffn_result-6: CPU
operator():              inpFF_+_result_w2-6: CPU
operator():                           norm-7: CPU
operator():                      attn_norm-7: CPU
operator():                           Qcur-7: CPU
operator():                           Kcur-7: CPU
operator():                           Vcur-7: CPU
operator():                           Qcur-7: CPU
operator():                           Kcur-7: CPU
operator():                             kq-7: CPU
operator():                      kq_scaled-7: CPU
operator():                      kq_masked-7: CPU
operator():                    kq_soft_max-7: CPU
operator():                            kqv-7: CPU
operator():                kqv_merged_cont-7: CPU
operator():                        kqv_out-7: CPU
operator():                          inpFF-7: CPU
operator():                           norm-7: CPU
operator():                       ffn_norm-7: CPU
operator():                         ffn_up-7: CPU
operator():                       ffn_gate-7: CPU
operator():                       ffn_silu-7: CPU
operator():                   ffn_gate_par-7: CPU
operator():                     ffn_result-7: CPU
operator():              inpFF_+_result_w2-7: CPU
operator():                           norm-8: CPU
operator():                      attn_norm-8: CPU
operator():                           Qcur-8: CPU
operator():                           Kcur-8: CPU
operator():                           Vcur-8: CPU
operator():                           Qcur-8: CPU
operator():                           Kcur-8: CPU
operator():                             kq-8: CPU
operator():                      kq_scaled-8: CPU
operator():                      kq_masked-8: CPU
operator():                    kq_soft_max-8: CPU
operator():                            kqv-8: CPU
operator():                kqv_merged_cont-8: CPU
operator():                        kqv_out-8: CPU
operator():                          inpFF-8: CPU
operator():                           norm-8: CPU
operator():                       ffn_norm-8: CPU
operator():                         ffn_up-8: CPU
operator():                       ffn_gate-8: CPU
operator():                       ffn_silu-8: CPU
operator():                   ffn_gate_par-8: CPU
operator():                     ffn_result-8: CPU
operator():              inpFF_+_result_w2-8: CPU
operator():                           norm-9: CPU
operator():                      attn_norm-9: CPU
operator():                           Qcur-9: CPU
operator():                           Kcur-9: CPU
operator():                           Vcur-9: CPU
operator():                           Qcur-9: CPU
operator():                           Kcur-9: CPU
operator():                             kq-9: CPU
operator():                      kq_scaled-9: CPU
operator():                      kq_masked-9: CPU
operator():                    kq_soft_max-9: CPU
operator():                            kqv-9: CPU
operator():                kqv_merged_cont-9: CPU
operator():                        kqv_out-9: CPU
operator():                          inpFF-9: CPU
operator():                           norm-9: CPU
operator():                       ffn_norm-9: CPU
operator():                         ffn_up-9: CPU
operator():                       ffn_gate-9: CPU
operator():                       ffn_silu-9: CPU
operator():                   ffn_gate_par-9: CPU
operator():                     ffn_result-9: CPU
operator():              inpFF_+_result_w2-9: CPU
operator():                          norm-10: CPU
operator():                     attn_norm-10: CPU
operator():                          Qcur-10: CPU
operator():                          Kcur-10: CPU
operator():                          Vcur-10: CPU
operator():                          Qcur-10: CPU
operator():                          Kcur-10: CPU
operator():                            kq-10: CPU
operator():                     kq_scaled-10: CPU
operator():                     kq_masked-10: CPU
operator():                   kq_soft_max-10: CPU
operator():                           kqv-10: CPU
operator():               kqv_merged_cont-10: CPU
operator():                       kqv_out-10: CPU
operator():                         inpFF-10: CPU
operator():                          norm-10: CPU
operator():                      ffn_norm-10: CPU
operator():                        ffn_up-10: CPU
operator():                      ffn_gate-10: CPU
operator():                      ffn_silu-10: CPU
operator():                  ffn_gate_par-10: CPU
operator():                    ffn_result-10: CPU
operator():             inpFF_+_result_w2-10: CPU
operator():                          norm-11: CPU
operator():                     attn_norm-11: CPU
operator():                          Qcur-11: CPU
operator():                          Kcur-11: CPU
operator():                          Vcur-11: CPU
operator():                          Qcur-11: CPU
operator():                          Kcur-11: CPU
operator():                            kq-11: CPU
operator():                     kq_scaled-11: CPU
operator():                     kq_masked-11: CPU
operator():                   kq_soft_max-11: CPU
operator():                           kqv-11: CPU
operator():               kqv_merged_cont-11: CPU
operator():                       kqv_out-11: CPU
operator():                         inpFF-11: CPU
operator():                          norm-11: CPU
operator():                      ffn_norm-11: CPU
operator():                        ffn_up-11: CPU
operator():                      ffn_gate-11: CPU
operator():                      ffn_silu-11: CPU
operator():                  ffn_gate_par-11: CPU
operator():                    ffn_result-11: CPU
operator():             inpFF_+_result_w2-11: CPU
operator():                          norm-12: CPU
operator():                     attn_norm-12: CPU
operator():                          Qcur-12: CPU
operator():                          Kcur-12: CPU
operator():                          Vcur-12: CPU
operator():                          Qcur-12: CPU
operator():                          Kcur-12: CPU
operator():                            kq-12: CPU
operator():                     kq_scaled-12: CPU
operator():                     kq_masked-12: CPU
operator():                   kq_soft_max-12: CPU
operator():                           kqv-12: CPU
operator():               kqv_merged_cont-12: CPU
operator():                       kqv_out-12: CPU
operator():                         inpFF-12: CPU
operator():                          norm-12: CPU
operator():                      ffn_norm-12: CPU
operator():                        ffn_up-12: CPU
operator():                      ffn_gate-12: CPU
operator():                      ffn_silu-12: CPU
operator():                  ffn_gate_par-12: CPU
operator():                    ffn_result-12: CPU
operator():             inpFF_+_result_w2-12: CPU
operator():                          norm-13: CPU
operator():                     attn_norm-13: CPU
operator():                          Qcur-13: CPU
operator():                          Kcur-13: CPU
operator():                          Vcur-13: CPU
operator():                          Qcur-13: CPU
operator():                          Kcur-13: CPU
operator():                            kq-13: CPU
operator():                     kq_scaled-13: CPU
operator():                     kq_masked-13: CPU
operator():                   kq_soft_max-13: CPU
operator():                           kqv-13: CPU
operator():               kqv_merged_cont-13: CPU
operator():                       kqv_out-13: CPU
operator():                         inpFF-13: CPU
operator():                          norm-13: CPU
operator():                      ffn_norm-13: CPU
operator():                        ffn_up-13: CPU
operator():                      ffn_gate-13: CPU
operator():                      ffn_silu-13: CPU
operator():                  ffn_gate_par-13: CPU
operator():                    ffn_result-13: CPU
operator():             inpFF_+_result_w2-13: CPU
operator():                          norm-14: CPU
operator():                     attn_norm-14: CPU
operator():                          Qcur-14: CPU
operator():                          Kcur-14: CPU
operator():                          Vcur-14: CPU
operator():                          Qcur-14: CPU
operator():                          Kcur-14: CPU
operator():                            kq-14: CPU
operator():                     kq_scaled-14: CPU
operator():                     kq_masked-14: CPU
operator():                   kq_soft_max-14: CPU
operator():                           kqv-14: CPU
operator():               kqv_merged_cont-14: CPU
operator():                       kqv_out-14: CPU
operator():                         inpFF-14: CPU
operator():                          norm-14: CPU
operator():                      ffn_norm-14: CPU
operator():                        ffn_up-14: CPU
operator():                      ffn_gate-14: CPU
operator():                      ffn_silu-14: CPU
operator():                  ffn_gate_par-14: CPU
operator():                    ffn_result-14: CPU
operator():             inpFF_+_result_w2-14: CPU
operator():                          norm-15: CPU
operator():                     attn_norm-15: CPU
operator():                          Qcur-15: CPU
operator():                          Kcur-15: CPU
operator():                          Vcur-15: CPU
operator():                          Qcur-15: CPU
operator():                          Kcur-15: CPU
operator():                            kq-15: CPU
operator():                     kq_scaled-15: CPU
operator():                     kq_masked-15: CPU
operator():                   kq_soft_max-15: CPU
operator():                           kqv-15: CPU
operator():               kqv_merged_cont-15: CPU
operator():                       kqv_out-15: CPU
operator():                         inpFF-15: CPU
operator():                          norm-15: CPU
operator():                      ffn_norm-15: CPU
operator():                        ffn_up-15: CPU
operator():                      ffn_gate-15: CPU
operator():                      ffn_silu-15: CPU
operator():                  ffn_gate_par-15: CPU
operator():                    ffn_result-15: CPU
operator():             inpFF_+_result_w2-15: CPU
operator():                          norm-16: CPU
operator():                     attn_norm-16: CPU
operator():                          Qcur-16: CPU
operator():                          Kcur-16: CPU
operator():                          Vcur-16: CPU
operator():                          Qcur-16: CPU
operator():                          Kcur-16: CPU
operator():                            kq-16: CPU
operator():                     kq_scaled-16: CPU
operator():                     kq_masked-16: CPU
operator():                   kq_soft_max-16: CPU
operator():                           kqv-16: CPU
operator():               kqv_merged_cont-16: CPU
operator():                       kqv_out-16: CPU
operator():                         inpFF-16: CPU
operator():                          norm-16: CPU
operator():                      ffn_norm-16: CPU
operator():                        ffn_up-16: CPU
operator():                      ffn_gate-16: CPU
operator():                      ffn_silu-16: CPU
operator():                  ffn_gate_par-16: CPU
operator():                    ffn_result-16: CPU
operator():             inpFF_+_result_w2-16: CPU
operator():                          norm-17: CPU
operator():                     attn_norm-17: CPU
operator():                          Qcur-17: CPU
operator():                          Kcur-17: CPU
operator():                          Vcur-17: CPU
operator():                          Qcur-17: CPU
operator():                          Kcur-17: CPU
operator():                            kq-17: CPU
operator():                     kq_scaled-17: CPU
operator():                     kq_masked-17: CPU
operator():                   kq_soft_max-17: CPU
operator():                           kqv-17: CPU
operator():               kqv_merged_cont-17: CPU
operator():                       kqv_out-17: CPU
operator():                         inpFF-17: CPU
operator():                          norm-17: CPU
operator():                      ffn_norm-17: CPU
operator():                        ffn_up-17: CPU
operator():                      ffn_gate-17: CPU
operator():                      ffn_silu-17: CPU
operator():                  ffn_gate_par-17: CPU
operator():                    ffn_result-17: CPU
operator():             inpFF_+_result_w2-17: CPU
operator():                          norm-18: CPU
operator():                     attn_norm-18: CPU
operator():                          Qcur-18: CPU
operator():                          Kcur-18: CPU
operator():                          Vcur-18: CPU
operator():                          Qcur-18: CPU
operator():                          Kcur-18: CPU
operator():                            kq-18: CPU
operator():                     kq_scaled-18: CPU
operator():                     kq_masked-18: CPU
operator():                   kq_soft_max-18: CPU
operator():                           kqv-18: CPU
operator():               kqv_merged_cont-18: CPU
operator():                       kqv_out-18: CPU
operator():                         inpFF-18: CPU
operator():                          norm-18: CPU
operator():                      ffn_norm-18: CPU
operator():                        ffn_up-18: CPU
operator():                      ffn_gate-18: CPU
operator():                      ffn_silu-18: CPU
operator():                  ffn_gate_par-18: CPU
operator():                    ffn_result-18: CPU
operator():             inpFF_+_result_w2-18: CPU
operator():                          norm-19: CPU
operator():                     attn_norm-19: CPU
operator():                          Qcur-19: CPU
operator():                          Kcur-19: CPU
operator():                          Vcur-19: CPU
operator():                          Qcur-19: CPU
operator():                          Kcur-19: CPU
operator():                            kq-19: CPU
operator():                     kq_scaled-19: CPU
operator():                     kq_masked-19: CPU
operator():                   kq_soft_max-19: CPU
operator():                           kqv-19: CPU
operator():               kqv_merged_cont-19: CPU
operator():                       kqv_out-19: CPU
operator():                         inpFF-19: CPU
operator():                          norm-19: CPU
operator():                      ffn_norm-19: CPU
operator():                        ffn_up-19: CPU
operator():                      ffn_gate-19: CPU
operator():                      ffn_silu-19: CPU
operator():                  ffn_gate_par-19: CPU
operator():                    ffn_result-19: CPU
operator():             inpFF_+_result_w2-19: CPU
operator():                          norm-20: CPU
operator():                     attn_norm-20: CPU
operator():                          Qcur-20: CPU
operator():                          Kcur-20: CPU
operator():                          Vcur-20: CPU
operator():                          Qcur-20: CPU
operator():                          Kcur-20: CPU
operator():                            kq-20: CPU
operator():                     kq_scaled-20: CPU
operator():                     kq_masked-20: CPU
operator():                   kq_soft_max-20: CPU
operator():                           kqv-20: CPU
operator():               kqv_merged_cont-20: CPU
operator():                       kqv_out-20: CPU
operator():                         inpFF-20: CPU
operator():                          norm-20: CPU
operator():                      ffn_norm-20: CPU
operator():                        ffn_up-20: CPU
operator():                      ffn_gate-20: CPU
operator():                      ffn_silu-20: CPU
operator():                  ffn_gate_par-20: CPU
operator():                    ffn_result-20: CPU
operator():             inpFF_+_result_w2-20: CPU
operator():                          norm-21: CPU
operator():                     attn_norm-21: CPU
operator():                          Qcur-21: CPU
operator():                          Kcur-21: CPU
operator():                          Vcur-21: CPU
operator():                          Qcur-21: CPU
operator():                          Kcur-21: CPU
operator():                            kq-21: CPU
operator():                     kq_scaled-21: CPU
operator():                     kq_masked-21: CPU
operator():                   kq_soft_max-21: CPU
operator():                           kqv-21: CPU
operator():               kqv_merged_cont-21: CPU
operator():                       kqv_out-21: CPU
operator():                         inpFF-21: CPU
operator():                          norm-21: CPU
operator():                      ffn_norm-21: CPU
operator():                        ffn_up-21: CPU
operator():                      ffn_gate-21: CPU
operator():                      ffn_silu-21: CPU
operator():                  ffn_gate_par-21: CPU
operator():                    ffn_result-21: CPU
operator():             inpFF_+_result_w2-21: CPU
operator():                          norm-22: CPU
operator():                     attn_norm-22: CPU
operator():                          Qcur-22: CPU
operator():                          Kcur-22: CPU
operator():                          Vcur-22: CPU
operator():                          Qcur-22: CPU
operator():                          Kcur-22: CPU
operator():                            kq-22: CPU
operator():                     kq_scaled-22: CPU
operator():                     kq_masked-22: CPU
operator():                   kq_soft_max-22: CPU
operator():                           kqv-22: CPU
operator():               kqv_merged_cont-22: CPU
operator():                       kqv_out-22: CPU
operator():                         inpFF-22: CPU
operator():                          norm-22: CPU
operator():                      ffn_norm-22: CPU
operator():                        ffn_up-22: CPU
operator():                      ffn_gate-22: CPU
operator():                      ffn_silu-22: CPU
operator():                  ffn_gate_par-22: CPU
operator():                    ffn_result-22: CPU
operator():             inpFF_+_result_w2-22: CPU
operator():                          norm-23: CPU
operator():                     attn_norm-23: CPU
operator():                          Qcur-23: CPU
operator():                          Kcur-23: CPU
operator():                          Vcur-23: CPU
operator():                          Qcur-23: CPU
operator():                          Kcur-23: CPU
operator():                            kq-23: CPU
operator():                     kq_scaled-23: CPU
operator():                     kq_masked-23: CPU
operator():                   kq_soft_max-23: CPU
operator():                           kqv-23: CPU
operator():               kqv_merged_cont-23: CPU
operator():                       kqv_out-23: CPU
operator():                         inpFF-23: CPU
operator():                          norm-23: CPU
operator():                      ffn_norm-23: CPU
operator():                        ffn_up-23: CPU
operator():                      ffn_gate-23: CPU
operator():                      ffn_silu-23: CPU
operator():                  ffn_gate_par-23: CPU
operator():                    ffn_result-23: CPU
operator():             inpFF_+_result_w2-23: CPU
operator():                          norm-24: CPU
operator():                     attn_norm-24: CPU
operator():                          Qcur-24: CPU
operator():                          Kcur-24: CPU
operator():                          Vcur-24: CPU
operator():                          Qcur-24: CPU
operator():                          Kcur-24: CPU
operator():                            kq-24: CPU
operator():                     kq_scaled-24: CPU
operator():                     kq_masked-24: CPU
operator():                   kq_soft_max-24: CPU
operator():                           kqv-24: CPU
operator():               kqv_merged_cont-24: CPU
operator():                       kqv_out-24: CPU
operator():                         inpFF-24: CPU
operator():                          norm-24: CPU
operator():                      ffn_norm-24: CPU
operator():                        ffn_up-24: CPU
operator():                      ffn_gate-24: CPU
operator():                      ffn_silu-24: CPU
operator():                  ffn_gate_par-24: CPU
operator():                    ffn_result-24: CPU
operator():             inpFF_+_result_w2-24: CPU
operator():                          norm-25: CPU
operator():                     attn_norm-25: CPU
operator():                          Qcur-25: CPU
operator():                          Kcur-25: CPU
operator():                          Vcur-25: CPU
operator():                          Qcur-25: CPU
operator():                          Kcur-25: CPU
operator():                            kq-25: CPU
operator():                     kq_scaled-25: CPU
operator():                     kq_masked-25: CPU
operator():                   kq_soft_max-25: CPU
operator():                           kqv-25: CPU
operator():               kqv_merged_cont-25: CPU
operator():                       kqv_out-25: CPU
operator():                         inpFF-25: CPU
operator():                          norm-25: CPU
operator():                      ffn_norm-25: CPU
operator():                        ffn_up-25: CPU
operator():                      ffn_gate-25: CPU
operator():                      ffn_silu-25: CPU
operator():                  ffn_gate_par-25: CPU
operator():                    ffn_result-25: CPU
operator():             inpFF_+_result_w2-25: CPU
operator():                             norm: CPU
operator():                      result_norm: CPU
operator():                    result_output: CPU
llama_new_context_with_model: compute buffer total size = 23.31 MB

system_info: n_threads = 4 / 8 | AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | 
perplexity: tokenizing the input ..
perplexity: tokenization took 7.864 ms
perplexity: calculating perplexity over 2 chunks, batch_size=128
perplexity: 4.98 seconds per pass - ETA 0.15 minutes
[1]4.2539,[2]7.2768,
llama_print_timings:        load time =     335.60 ms
llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)
llama_print_timings: prompt eval time =   10029.71 ms /   256 tokens (   39.18 ms per token,    25.52 tokens per second)
llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)
llama_print_timings:       total time =   10052.37 ms

Final estimate: PPL = 7.2768 +/- 1.62712

real	0m10.526s
user	0m40.687s
sys	0m0.332s
