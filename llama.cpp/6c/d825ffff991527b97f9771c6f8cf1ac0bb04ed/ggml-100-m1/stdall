Requirement already satisfied: numpy~=1.24.4 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 1)) (1.24.4)
Requirement already satisfied: sentencepiece~=0.2.0 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 2)) (0.2.0)
Requirement already satisfied: transformers<5.0.0,>=4.40.1 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.40.1)
Requirement already satisfied: gguf>=0.1.0 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 4)) (0.6.0)
Requirement already satisfied: protobuf<5.0.0,>=4.21.0 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 5)) (4.25.2)
Requirement already satisfied: torch~=2.1.1 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.2)
Requirement already satisfied: requests in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.31.0)
Requirement already satisfied: regex!=2019.12.17 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.12.25)
Requirement already satisfied: packaging>=20.0 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (23.2)
Requirement already satisfied: tqdm>=4.27 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.66.1)
Requirement already satisfied: filelock in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.13.1)
Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.19.1)
Requirement already satisfied: safetensors>=0.4.1 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.4.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.20.2)
Requirement already satisfied: pyyaml>=5.1 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (6.0.1)
Requirement already satisfied: typing-extensions in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (4.9.0)
Requirement already satisfied: sympy in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.12)
Requirement already satisfied: jinja2 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1.3)
Requirement already satisfied: fsspec in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2023.12.2)
Requirement already satisfied: networkx in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.2.1)
Requirement already satisfied: MarkupSafe>=2.0 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from jinja2->torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.4)
Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.1.0)
Requirement already satisfied: certifi>=2017.4.17 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.40.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.11.17)
Requirement already satisfied: mpmath>=0.19 in /Users/ggml/mnt/llama.cpp/venv/lib/python3.9/site-packages (from sympy->torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.3.0)
ERROR: File "setup.py" or "setup.cfg" not found. Directory cannot be installed in editable mode: /Users/ggml/work/llama.cpp/gguf-py
(A "pyproject.toml" file was found, but editable mode currently requires a setuptools-based build.)
+ gg_run_ctest_debug
+ cd /Users/ggml/work/llama.cpp
+ rm -rf build-ci-debug
+ tee /Users/ggml/results/llama.cpp/6c/d825ffff991527b97f9771c6f8cf1ac0bb04ed/ggml-100-m1/ctest_debug.log
+ mkdir build-ci-debug
+ cd build-ci-debug
+ set -e
+ tee -a /Users/ggml/results/llama.cpp/6c/d825ffff991527b97f9771c6f8cf1ac0bb04ed/ggml-100-m1/ctest_debug-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_FATAL_WARNINGS=ON -DLLAMA_METAL_SHADER_DEBUG=ON ..
-- The C compiler identification is AppleClang 15.0.0.15000100
-- The CXX compiler identification is AppleClang 15.0.0.15000100
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.39.3 (Apple Git-145)") 
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- Accelerate framework found
-- Metal framework found
-- ccache found, compilation results will be cached. Disable with LLAMA_CCACHE=OFF.
-- CMAKE_SYSTEM_PROCESSOR: arm64
-- ARM detected
-- Performing Test COMPILER_SUPPORTS_FP16_FORMAT_I3E
-- Performing Test COMPILER_SUPPORTS_FP16_FORMAT_I3E - Failed
-- Configuring done (5.6s)
-- Generating done (0.3s)
-- Build files have been written to: /Users/ggml/work/llama.cpp/build-ci-debug

real	0m5.985s
user	0m0.448s
sys	0m0.545s
+ tee -a /Users/ggml/results/llama.cpp/6c/d825ffff991527b97f9771c6f8cf1ac0bb04ed/ggml-100-m1/ctest_debug-make.log
+ make -j
[  1%] Generating build details from Git
[  1%] Compiling Metal kernels
[  1%] Building C object CMakeFiles/ggml.dir/ggml-quants.c.o
[  1%] Building C object CMakeFiles/ggml.dir/ggml.c.o
[  2%] Building C object CMakeFiles/ggml.dir/ggml-alloc.c.o
[  3%] Building CXX object CMakeFiles/ggml.dir/sgemm.cpp.o
[  4%] Building C object CMakeFiles/ggml.dir/ggml-backend.c.o
[  5%] Building C object CMakeFiles/ggml.dir/ggml-metal.m.o
-- Found Git: /usr/bin/git (found version "2.39.3 (Apple Git-145)") 
[  6%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  6%] Built target build_info
/Users/ggml/work/llama.cpp/ggml.c:10999:57: error: arithmetic on a pointer to void is a GNU extension [-Werror,-Wgnu-pointer-arith]
                        x = (const float *) (src0->data + (i0       )*nb00 + (i1       )*nb01 + (i2       )*nb02 + (i3       )*nb03);
                                             ~~~~~~~~~~ ^
/Users/ggml/work/llama.cpp/ggml.c:10999:76: error: arithmetic on a pointer to void is a GNU extension [-Werror,-Wgnu-pointer-arith]
                        x = (const float *) (src0->data + (i0       )*nb00 + (i1       )*nb01 + (i2       )*nb02 + (i3       )*nb03);
                                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^
/Users/ggml/work/llama.cpp/ggml.c:10999:95: error: arithmetic on a pointer to void is a GNU extension [-Werror,-Wgnu-pointer-arith]
                        x = (const float *) (src0->data + (i0       )*nb00 + (i1       )*nb01 + (i2       )*nb02 + (i3       )*nb03);
                                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^
/Users/ggml/work/llama.cpp/ggml.c:10999:114: error: arithmetic on a pointer to void is a GNU extension [-Werror,-Wgnu-pointer-arith]
                        x = (const float *) (src0->data + (i0       )*nb00 + (i1       )*nb01 + (i2       )*nb02 + (i3       )*nb03);
                                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^
/Users/ggml/work/llama.cpp/ggml.c:11001:57: error: arithmetic on a pointer to void is a GNU extension [-Werror,-Wgnu-pointer-arith]
                        x = (const float *) (src1->data + (i0 - o[0])*nb10 + (i1 - o[1])*nb11 + (i2 - o[2])*nb12 + (i3 - o[3])*nb13);
                                             ~~~~~~~~~~ ^
/Users/ggml/work/llama.cpp/ggml.c:11001:76: error: arithmetic on a pointer to void is a GNU extension [-Werror,-Wgnu-pointer-arith]
                        x = (const float *) (src1->data + (i0 - o[0])*nb10 + (i1 - o[1])*nb11 + (i2 - o[2])*nb12 + (i3 - o[3])*nb13);
                                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^
/Users/ggml/work/llama.cpp/ggml.c:11001:95: error: arithmetic on a pointer to void is a GNU extension [-Werror,-Wgnu-pointer-arith]
                        x = (const float *) (src1->data + (i0 - o[0])*nb10 + (i1 - o[1])*nb11 + (i2 - o[2])*nb12 + (i3 - o[3])*nb13);
                                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^
/Users/ggml/work/llama.cpp/ggml.c:11001:114: error: arithmetic on a pointer to void is a GNU extension [-Werror,-Wgnu-pointer-arith]
                        x = (const float *) (src1->data + (i0 - o[0])*nb10 + (i1 - o[1])*nb11 + (i2 - o[2])*nb12 + (i3 - o[3])*nb13);
                                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^
8 errors generated.
make[2]: *** [CMakeFiles/ggml.dir/ggml.c.o] Error 1
make[1]: *** [CMakeFiles/ggml.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
[  6%] Built target ggml-metal
make: *** [all] Error 2
+ cur=2
+ echo 2
+ set +x
cat: /Users/ggml/results/llama.cpp/6c/d825ffff991527b97f9771c6f8cf1ac0bb04ed/ggml-100-m1/ctest_debug-ctest.log: No such file or directory
