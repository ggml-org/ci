rm: /Users/ggml/results/llama.cpp/ca/0c6dd42a357716f5b964f885b5dd31dadb93f6/ggml-100-m1/*.log: No such file or directory
rm: /Users/ggml/results/llama.cpp/ca/0c6dd42a357716f5b964f885b5dd31dadb93f6/ggml-100-m1/*.exit: No such file or directory
rm: /Users/ggml/results/llama.cpp/ca/0c6dd42a357716f5b964f885b5dd31dadb93f6/ggml-100-m1/*.md: No such file or directory
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: numpy~=1.24.4 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 1)) (1.24.4)
Requirement already satisfied: sentencepiece~=0.1.98 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 2)) (0.1.98)
Requirement already satisfied: transformers<5.0.0,>=4.35.2 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.36.2)
Requirement already satisfied: gguf>=0.1.0 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 4)) (0.4.5)
Requirement already satisfied: protobuf<5.0.0,>=4.21.0 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 5)) (4.25.1)
Requirement already satisfied: torch~=2.1.1 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.2)
Requirement already satisfied: tqdm>=4.27 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.66.1)
Requirement already satisfied: filelock in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.12.4)
Requirement already satisfied: safetensors>=0.3.1 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.4.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.19.4)
Requirement already satisfied: requests in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.31.0)
Requirement already satisfied: packaging>=20.0 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (23.2)
Requirement already satisfied: pyyaml>=5.1 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (6.0.1)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.15.0)
Requirement already satisfied: regex!=2019.12.17 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.10.3)
Requirement already satisfied: fsspec in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2023.9.2)
Requirement already satisfied: networkx in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1)
Requirement already satisfied: sympy in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.12)
Requirement already satisfied: typing-extensions in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (4.8.0)
Requirement already satisfied: jinja2 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1.2)
Requirement already satisfied: MarkupSafe>=2.0 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from jinja2->torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.3)
Requirement already satisfied: idna<4,>=2.5 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.0.6)
Requirement already satisfied: certifi>=2017.4.17 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.7.22)
Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.3.0)
Requirement already satisfied: mpmath>=0.19 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from sympy->torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.3.0)
WARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.
Defaulting to user installation because normal site-packages is not writeable
ERROR: File "setup.py" or "setup.cfg" not found. Directory cannot be installed in editable mode: /Users/ggml/work/llama.cpp/gguf-py
(A "pyproject.toml" file was found, but editable mode currently requires a setuptools-based build.)
WARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.
+ gg_run_ctest_debug
+ cd /Users/ggml/work/llama.cpp
+ rm -rf build-ci-debug
+ tee /Users/ggml/results/llama.cpp/ca/0c6dd42a357716f5b964f885b5dd31dadb93f6/ggml-100-m1/ctest_debug.log
+ mkdir build-ci-debug
+ cd build-ci-debug
+ set -e
+ tee -a /Users/ggml/results/llama.cpp/ca/0c6dd42a357716f5b964f885b5dd31dadb93f6/ggml-100-m1/ctest_debug-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_METAL_SHADER_DEBUG=ON ..
-- The C compiler identification is AppleClang 15.0.0.15000100
-- The CXX compiler identification is AppleClang 15.0.0.15000100
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.39.3 (Apple Git-145)") 
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- Accelerate framework found
-- Metal framework found
-- CMAKE_SYSTEM_PROCESSOR: arm64
-- ARM detected
-- Performing Test COMPILER_SUPPORTS_FP16_FORMAT_I3E
-- Performing Test COMPILER_SUPPORTS_FP16_FORMAT_I3E - Failed
-- Configuring done (1.0s)
-- Generating done (0.2s)
-- Build files have been written to: /Users/ggml/work/llama.cpp/build-ci-debug

real	0m1.246s
user	0m0.404s
sys	0m0.752s
+ tee -a /Users/ggml/results/llama.cpp/ca/0c6dd42a357716f5b964f885b5dd31dadb93f6/ggml-100-m1/ctest_debug-make.log
+ make -j
[  1%] Generating build details from Git
[  1%] Building C object CMakeFiles/ggml.dir/ggml.c.o
[  3%] Compiling Metal kernels
[  3%] Building C object CMakeFiles/ggml.dir/ggml-backend.c.o
[  4%] Building C object CMakeFiles/ggml.dir/ggml-quants.c.o
[  5%] Building C object CMakeFiles/ggml.dir/ggml-alloc.c.o
[  6%] Building C object CMakeFiles/ggml.dir/ggml-metal.m.o
-- Found Git: /usr/bin/git (found version "2.39.3 (Apple Git-145)") 
[  7%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  7%] Built target build_info
/Users/ggml/work/llama.cpp/ggml-metal.m:2531:9: error: void function 'ggml_backend_metal_buffer_cpy_tensor' should not return a value [-Wreturn-type]
        return true;
        ^      ~~~~
/Users/ggml/work/llama.cpp/ggml-metal.m:2533:5: error: void function 'ggml_backend_metal_buffer_cpy_tensor' should not return a value [-Wreturn-type]
    return false;
    ^      ~~~~~
/Users/ggml/work/llama.cpp/ggml-metal.m:2551:30: warning: incompatible function pointer types initializing 'bool (*)(ggml_backend_buffer_t, const struct ggml_tensor *, struct ggml_tensor *)' (aka 'bool (*)(struct ggml_backend_buffer *, const struct ggml_tensor *, struct ggml_tensor *)') with an expression of type 'void (ggml_backend_buffer_t, const struct ggml_tensor *, struct ggml_tensor *)' (aka 'void (struct ggml_backend_buffer *, const struct ggml_tensor *, struct ggml_tensor *)') [-Wincompatible-function-pointer-types]
    /* .cpy_tensor      = */ ggml_backend_metal_buffer_cpy_tensor,
                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
1 warning and 2 errors generated.
make[2]: *** [CMakeFiles/ggml.dir/ggml-metal.m.o] Error 1
make[2]: *** Waiting for unfinished jobs....
make[1]: *** [CMakeFiles/ggml.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
[  7%] Built target ggml-metal
make: *** [all] Error 2
+ cur=2
+ echo 2
+ set +x
cat: /Users/ggml/results/llama.cpp/ca/0c6dd42a357716f5b964f885b5dd31dadb93f6/ggml-100-m1/ctest_debug-ctest.log: No such file or directory
