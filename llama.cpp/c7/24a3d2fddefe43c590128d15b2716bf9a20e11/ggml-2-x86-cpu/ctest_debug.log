+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_FATAL_WARNINGS=ON ..
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1")
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE
-- ccache found, compilation results will be cached. Disable with GGML_CCACHE=OFF.
-- CMAKE_SYSTEM_PROCESSOR: x86_64
-- Including CPU backend
-- Found OpenMP_C: -fopenmp (found version "4.5")
-- Found OpenMP_CXX: -fopenmp (found version "4.5")
-- Found OpenMP: TRUE (found version "4.5")
-- x86 detected
-- Adding CPU backend variant ggml-cpu: -march=native 
-- Configuring done (0.6s)
-- Generating done (0.1s)
-- Build files have been written to: /home/ggml/work/llama.cpp/build-ci-debug

real	0m0.797s
user	0m0.578s
sys	0m0.224s
++ nproc
+ make -j8
[  0%] Generating build details from Git
[  1%] Building C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o
[  2%] Building C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o
[  2%] Building C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o
[  3%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o
[  3%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o
[  4%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o
-- Found Git: /usr/bin/git (found version "2.34.1")
[  4%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o
[  4%] Built target sha256
[  4%] Built target xxhash
[  4%] Built target sha1
[  5%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o
[  5%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o
[  5%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o
[  6%] Linking CXX shared library ../../bin/libggml-base.so
[  6%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  6%] Built target build_info
[  6%] Built target ggml-base
[  6%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o
[  6%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o
[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o
[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o
[  8%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o
[  8%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o
[  9%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o
[  9%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o
[ 10%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o
[ 10%] Linking CXX shared library ../../bin/libggml-cpu.so
[ 10%] Built target ggml-cpu
[ 10%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o
[ 11%] Linking CXX shared library ../../bin/libggml.so
[ 11%] Built target ggml
[ 11%] Building CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o
[ 11%] Building CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o
[ 12%] Building CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o
[ 12%] Building CXX object src/CMakeFiles/llama.dir/llama.cpp.o
[ 13%] Building CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o
[ 13%] Building CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o
[ 14%] Building CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o
[ 14%] Building CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o
[ 15%] Linking CXX executable ../../bin/llama-gguf
[ 16%] Linking CXX executable ../../bin/llama-gguf-hash
[ 17%] Building CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o
[ 18%] Building CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o
[ 18%] Building CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o
[ 18%] Building CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o
[ 19%] Building CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o
[ 19%] Building CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o
[ 20%] Building CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o
[ 20%] Building CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o
[ 20%] Building CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o
[ 21%] Building CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_inp_s_copy(ggml_context*, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:5:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
    5 | ggml_tensor * llama_graph_i::build_inp_s_copy(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_inp_s_mask(ggml_context*, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:13:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   13 | ggml_tensor * llama_graph_i::build_inp_s_mask(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_copy_mask_state(ggml_context*, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int32_t, int32_t, int32_t, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:21:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   21 | ggml_tensor * llama_graph_i::build_copy_mask_state(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_mamba_layer(ggml_context*, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, const llama_ubatch&, int, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:43:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   43 | ggml_tensor * llama_graph_i::build_mamba_layer(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_rwkv_token_shift_load(ggml_context*, ggml_cgraph*, ggml_tensor*, ggml_tensor*, const llama_ubatch&, int, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:63:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   63 | ggml_tensor * llama_graph_i::build_rwkv_token_shift_load(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_rwkv_token_shift_store(ggml_context*, ggml_tensor*, const llama_ubatch&, int, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:81:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   81 | ggml_tensor * llama_graph_i::build_rwkv_token_shift_store(
      |               ^~~~~~~~~~~~~
/home/ggml/work/llama.cpp/src/llama-graph.cpp: In member function ‘virtual ggml_tensor* llama_graph_i::build_rwkv6_time_mix(ggml_context*, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, const llama_ubatch&, int, bool)’:
/home/ggml/work/llama.cpp/src/llama-graph.cpp:95:15: error: function might be candidate for attribute ‘noreturn’ [-Werror=suggest-attribute=noreturn]
   95 | ggml_tensor * llama_graph_i::build_rwkv6_time_mix(
      |               ^~~~~~~~~~~~~
cc1plus: all warnings being treated as errors
make[2]: *** [src/CMakeFiles/llama.dir/build.make:174: src/CMakeFiles/llama.dir/llama-graph.cpp.o] Error 1
make[2]: *** Waiting for unfinished jobs....
[ 21%] Building CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o
[ 21%] Built target llama-gguf-hash
[ 21%] Built target llama-gguf
make[1]: *** [CMakeFiles/Makefile2:1771: src/CMakeFiles/llama.dir/all] Error 2
make: *** [Makefile:146: all] Error 2

real	0m3.072s
user	0m6.466s
sys	0m0.761s
