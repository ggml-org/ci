mkdir: cannot create directory ‘/mnt/llama.cpp’: Permission denied
+ gg_run_ctest_debug
+ cd /home/ggml/work/llama.cpp
+ rm -rf build-ci-debug
+ tee /home/ggml/results/llama.cpp/2f/04c6efe1e293cf963dc07e1da074692fe50362/ggml-0-x86-cpu-low-perf/ctest_debug.log
+ mkdir build-ci-debug
+ cd build-ci-debug
+ set -e
+ tee -a /home/ggml/results/llama.cpp/2f/04c6efe1e293cf963dc07e1da074692fe50362/ggml-0-x86-cpu-low-perf/ctest_debug-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=Debug ..
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1") 
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with LLAMA_CCACHE=OFF
-- CMAKE_SYSTEM_PROCESSOR: x86_64
-- x86 detected
-- Configuring done
-- Generating done
-- Build files have been written to: /home/ggml/work/llama.cpp/build-ci-debug

real	0m0.434s
user	0m0.277s
sys	0m0.139s
+ tee -a /home/ggml/results/llama.cpp/2f/04c6efe1e293cf963dc07e1da074692fe50362/ggml-0-x86-cpu-low-perf/ctest_debug-make.log
+ make -j
[  1%] Generating build details from Git
[  2%] Building C object CMakeFiles/ggml.dir/ggml.c.o
[  3%] Building C object CMakeFiles/ggml.dir/ggml-alloc.c.o
[  4%] Building C object CMakeFiles/ggml.dir/ggml-quants.c.o
[  5%] Building C object CMakeFiles/ggml.dir/ggml-backend.c.o
-- Found Git: /usr/bin/git (found version "2.34.1") 
[  6%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  6%] Built target build_info
/home/ggml/work/llama.cpp/ggml-backend.c: In function ‘ggml_backend_sched_alloc_splits’:
/home/ggml/work/llama.cpp/ggml-backend.c:1414:1: warning: control reaches end of non-void function [-Wreturn-type]
 1414 | }
      | ^
[  6%] Built target ggml
[  7%] Linking C static library libggml_static.a
[  7%] Building CXX object CMakeFiles/llama.dir/llama.cpp.o
[  7%] Built target ggml_static
/home/ggml/work/llama.cpp/llama.cpp: In function ‘ggml_cgraph* llama_build_graph(llama_context&, const llama_batch&)’:
/home/ggml/work/llama.cpp/llama.cpp:7003:29: error: ‘ggml_tallocr_is_measure’ was not declared in this scope; did you mean ‘ggml_tallocr_free’?
 7003 |     const bool worst_case = ggml_tallocr_is_measure(lctx.alloc);
      |                             ^~~~~~~~~~~~~~~~~~~~~~~
      |                             ggml_tallocr_free
/home/ggml/work/llama.cpp/llama.cpp: In function ‘llama_context* llama_new_context_with_model(llama_model*, llama_context_params)’:
/home/ggml/work/llama.cpp/llama.cpp:10844:26: error: ‘ggml_backend_sched_get_tallocr’ was not declared in this scope; did you mean ‘ggml_backend_sched_get_n_splits’?
10844 |             ctx->alloc = ggml_backend_sched_get_tallocr(ctx->sched, ctx->backend_cpu);
      |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |                          ggml_backend_sched_get_n_splits
/home/ggml/work/llama.cpp/llama.cpp:10853:13: error: ‘ggml_backend_sched_init_measure’ was not declared in this scope; did you mean ‘ggml_backend_sched_reserve’?
10853 |             ggml_backend_sched_init_measure(ctx->sched, gf);
      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |             ggml_backend_sched_reserve
/home/ggml/work/llama.cpp/llama.cpp:10857:45: error: ‘ggml_backend_sched_get_buffer’ was not declared in this scope; did you mean ‘ggml_backend_sched_get_buffer_size’?
10857 |                 ggml_backend_buffer_t buf = ggml_backend_sched_get_buffer(ctx->sched, backend);
      |                                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |                                             ggml_backend_sched_get_buffer_size
make[2]: *** [CMakeFiles/llama.dir/build.make:76: CMakeFiles/llama.dir/llama.cpp.o] Error 1
make[1]: *** [CMakeFiles/Makefile2:772: CMakeFiles/llama.dir/all] Error 2
make: *** [Makefile:146: all] Error 2

real	0m3.424s
user	0m4.333s
sys	0m0.471s
+ cur=2
+ echo 2
+ set +x
cat: /home/ggml/results/llama.cpp/2f/04c6efe1e293cf963dc07e1da074692fe50362/ggml-0-x86-cpu-low-perf/ctest_debug-ctest.log: No such file or directory
