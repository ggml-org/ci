The virtual environment was not created successfully because ensurepip is not
available.  On Debian/Ubuntu systems, you need to install the python3-venv
package using the following command.

    apt install python3.10-venv

You may need to use sudo with that command.  After installing the python3-venv
package, recreate your virtual environment.

Failing command: /mnt/llama.cpp/venv/bin/python3

ci/run.sh: line 626: /mnt/llama.cpp/venv/bin/activate: No such file or directory
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: numpy~=1.24.4 in /home/ggml/.local/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 1)) (1.24.4)
Requirement already satisfied: sentencepiece~=0.1.98 in /home/ggml/.local/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 2)) (0.1.98)
Requirement already satisfied: transformers<5.0.0,>=4.35.2 in /home/ggml/.local/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.37.1)
Requirement already satisfied: gguf>=0.1.0 in /home/ggml/.local/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 4)) (0.7.0)
Requirement already satisfied: protobuf<5.0.0,>=4.21.0 in /home/ggml/.local/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 5)) (4.23.4)
Requirement already satisfied: torch~=2.1.1 in /home/ggml/.local/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.2)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ggml/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.15.1)
Requirement already satisfied: tqdm>=4.27 in /home/ggml/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.65.0)
Requirement already satisfied: filelock in /home/ggml/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.12.2)
Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/ggml/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.19.4)
Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (5.4.1)
Requirement already satisfied: packaging>=20.0 in /home/ggml/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (23.1)
Requirement already satisfied: regex!=2019.12.17 in /home/ggml/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.6.3)
Requirement already satisfied: requests in /home/ggml/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.31.0)
Requirement already satisfied: safetensors>=0.3.1 in /home/ggml/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.4.1)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)
Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.0.3)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.0.106)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.3.1)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (8.9.2.26)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (11.0.2.54)
Requirement already satisfied: triton==2.1.0 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.0)
Requirement already satisfied: networkx in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1)
Requirement already satisfied: fsspec in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2023.6.0)
Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.18.1)
Requirement already satisfied: typing-extensions in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (4.7.1)
Requirement already satisfied: sympy in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.12)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (11.4.5.107)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ggml/.local/lib/python3.10/site-packages (from torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (10.3.2.106)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ggml/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.3.101)
Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.3)
Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ggml/.local/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.1.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /home/ggml/.local/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.3.2)
Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2020.6.20)
Requirement already satisfied: mpmath>=0.19 in /home/ggml/.local/lib/python3.10/site-packages (from sympy->torch~=2.1.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.3.0)
Defaulting to user installation because normal site-packages is not writeable
Obtaining file:///home/ggml/work/llama.cpp/gguf-py
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: numpy>=1.17 in /home/ggml/.local/lib/python3.10/site-packages (from gguf==0.7.0) (1.24.4)
Building wheels for collected packages: gguf
  Building editable for gguf (pyproject.toml): started
  Building editable for gguf (pyproject.toml): finished with status 'done'
  Created wheel for gguf: filename=gguf-0.7.0-py3-none-any.whl size=3229 sha256=e77d3489e0beea138863799a05abb421092af60b67ffc67b376508ee3f0720bf
  Stored in directory: /tmp/pip-ephem-wheel-cache-qwvfge4z/wheels/a3/4c/52/c5934ad001d1a70ca5434f11ddc622cad9c0a484e9bf6feda3
Successfully built gguf
Installing collected packages: gguf
  Attempting uninstall: gguf
    Found existing installation: gguf 0.7.0
    Uninstalling gguf-0.7.0:
      Successfully uninstalled gguf-0.7.0
Successfully installed gguf-0.7.0
+ gg_run_ctest_debug
+ cd /home/ggml/work/llama.cpp
+ tee /home/ggml/results/llama.cpp/97/d6a0cc0663d52248def278ee6472b9ede7742c/ggml-4-x86-cuda-v100/ctest_debug.log
+ rm -rf build-ci-debug
+ mkdir build-ci-debug
+ cd build-ci-debug
+ set -e
+ tee -a /home/ggml/results/llama.cpp/97/d6a0cc0663d52248def278ee6472b9ede7742c/ggml-4-x86-cuda-v100/ctest_debug-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_CUBLAS=1 ..
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1") 
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- Found CUDAToolkit: /usr/local/cuda-12.2/include (found version "12.2.140") 
-- cuBLAS found
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda-12.2/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Using CUDA architectures: 52;61;70
-- CUDA host compiler is GNU 11.4.0

-- ccache found, compilation results will be cached. Disable with LLAMA_CCACHE=OFF.
-- CMAKE_SYSTEM_PROCESSOR: x86_64
-- x86 detected
-- Configuring done (3.0s)
-- Generating done (0.1s)
-- Build files have been written to: /home/ggml/work/llama.cpp/build-ci-debug

real	0m3.202s
user	0m2.452s
sys	0m0.757s
+ tee -a /home/ggml/results/llama.cpp/97/d6a0cc0663d52248def278ee6472b9ede7742c/ggml-4-x86-cuda-v100/ctest_debug-make.log
+ make -j
[  0%] Generating build details from Git
[  0%] Building C object CMakeFiles/ggml.dir/ggml.c.o
[  2%] Building C object CMakeFiles/ggml.dir/ggml-alloc.c.o
[  2%] Building C object CMakeFiles/ggml.dir/ggml-backend.c.o
[  3%] Building C object CMakeFiles/ggml.dir/ggml-quants.c.o
[  4%] Building CUDA object CMakeFiles/ggml.dir/ggml-cuda.cu.o
-- Found Git: /usr/bin/git (found version "2.34.1") 
[  5%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  5%] Built target build_info
/home/ggml/work/llama.cpp/ggml-cuda.cu(645): warning #177-D: function "warp_reduce_sum(half2)" was declared but never referenced
                                   half2 warp_reduce_sum(half2 a) {
                                         ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/home/ggml/work/llama.cpp/ggml-cuda.cu(666): warning #177-D: function "warp_reduce_max(half2)" was declared but never referenced
                                   half2 warp_reduce_max(half2 x) {
                                         ^

/home/ggml/work/llama.cpp/ggml-cuda.cu(1696): warning #177-D: variable "ksigns64" was declared but never referenced
                         uint64_t ksigns64[128] = {
                                  ^

[  5%] Built target ggml
[  6%] Linking CUDA static library libggml_static.a
[  7%] Building CXX object CMakeFiles/llama.dir/llama.cpp.o
[  7%] Building CXX object examples/gguf/CMakeFiles/gguf.dir/gguf.cpp.o
[  7%] Built target ggml_static
[  8%] Linking CXX executable ../../bin/gguf
[  8%] Built target gguf
[  9%] Linking CXX static library libllama.a
[  9%] Built target llama
[ 10%] Building C object tests/CMakeFiles/test-c.dir/test-c.c.o
[ 11%] Building CXX object common/CMakeFiles/common.dir/common.cpp.o
[ 12%] Building CXX object examples/benchmark/CMakeFiles/benchmark.dir/benchmark-matmult.cpp.o
[ 12%] Building CXX object examples/llava/CMakeFiles/llava.dir/llava.cpp.o
[ 13%] Building CXX object common/CMakeFiles/common.dir/console.cpp.o
[ 14%] Building CXX object examples/llava/CMakeFiles/llava.dir/clip.cpp.o
[ 15%] Building CXX object common/CMakeFiles/common.dir/grammar-parser.cpp.o
[ 16%] Building CXX object common/CMakeFiles/common.dir/sampling.cpp.o
[ 17%] Building CXX object examples/quantize-stats/CMakeFiles/quantize-stats.dir/quantize-stats.cpp.o
[ 18%] Building CXX object examples/quantize/CMakeFiles/quantize.dir/quantize.cpp.o
[ 18%] Building CXX object common/CMakeFiles/common.dir/train.cpp.o
[ 18%] Linking CXX executable ../bin/test-c
[ 18%] Built target test-c
[ 19%] Linking CXX executable ../../bin/benchmark
[ 19%] Built target benchmark
[ 20%] Linking CXX executable ../../bin/quantize
[ 20%] Built target quantize
[ 20%] Linking CXX executable ../../bin/quantize-stats
[ 20%] Built target quantize-stats
/home/ggml/work/llama.cpp/examples/llava/clip.cpp: In function â€˜clip_ctx* clip_model_load(const char*, int)â€™:
/home/ggml/work/llama.cpp/examples/llava/clip.cpp:1106:31: warning: suggest parentheses around comparison in operand of â€˜&â€™ [-Wparentheses]
 1106 |             for (int i = 0; i < 32 & hparams.image_grid_pinpoints[i]!=0; ++i) {
      |                             ~~^~~~
[ 20%] Built target llava
[ 21%] Linking CXX static library libllava_static.a
[ 21%] Built target llava_static
[ 22%] Linking CXX static library libcommon.a
[ 22%] Built target common
[ 22%] Building CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o
[ 24%] Building CXX object tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o
[ 28%] Building CXX object tests/CMakeFiles/test-tokenizer-1-llama.dir/test-tokenizer-1-llama.cpp.o
[ 26%] Building CXX object examples/baby-llama/CMakeFiles/baby-llama.dir/baby-llama.cpp.o
[ 29%] Building CXX object tests/CMakeFiles/test-sampling.dir/get-model.cpp.o
[ 30%] Building CXX object tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o
[ 32%] Building CXX object tests/CMakeFiles/test-tokenizer-0-llama.dir/get-model.cpp.o
[ 34%] Building CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o
[ 35%] Building CXX object tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o
[ 37%] Building CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o
[ 37%] Building CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o
[ 26%] Building CXX object tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o
[ 26%] Building CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/get-model.cpp.o
[ 31%] Building CXX object tests/CMakeFiles/test-tokenizer-1-llama.dir/get-model.cpp.o
[ 26%] Building CXX object tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o
[ 26%] Building CXX object tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o
[ 34%] Building CXX object tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o
[ 26%] Building CXX object tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o
[ 26%] Building CXX object tests/CMakeFiles/test-tokenizer-0-falcon.dir/get-model.cpp.o
[ 44%] Building CXX object tests/CMakeFiles/test-grad0.dir/get-model.cpp.o
[ 44%] Building CXX object tests/CMakeFiles/test-grad0.dir/test-grad0.cpp.o
[ 46%] Building CXX object examples/batched/CMakeFiles/batched.dir/batched.cpp.o
[ 44%] Building CXX object tests/CMakeFiles/test-rope.dir/test-rope.cpp.o
[ 46%] Building CXX object examples/batched-bench/CMakeFiles/batched-bench.dir/batched-bench.cpp.o
[ 44%] Building CXX object tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o
[ 44%] Building CXX object tests/CMakeFiles/test-rope.dir/get-model.cpp.o
[ 46%] Building CXX object tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o
[ 44%] Building CXX object tests/CMakeFiles/test-tokenizer-0-llama.dir/test-tokenizer-0-llama.cpp.o
[ 44%] Building CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o
[ 44%] Building CXX object tests/CMakeFiles/test-tokenizer-0-falcon.dir/test-tokenizer-0-falcon.cpp.o
[ 46%] Building CXX object tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o
[ 47%] Building CXX object examples/convert-llama2c-to-ggml/CMakeFiles/convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o
[ 48%] Building CXX object examples/embedding/CMakeFiles/embedding.dir/embedding.cpp.o
[ 49%] Building CXX object examples/finetune/CMakeFiles/finetune.dir/finetune.cpp.o
[ 50%] Building CXX object examples/main/CMakeFiles/main.dir/main.cpp.o
[ 51%] Building CXX object examples/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o
[ 52%] Building CXX object examples/beam-search/CMakeFiles/beam-search.dir/beam-search.cpp.o
[ 53%] Building CXX object examples/infill/CMakeFiles/infill.dir/infill.cpp.o
[ 54%] Building CXX object examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o
[ 54%] Building CXX object examples/tokenize/CMakeFiles/tokenize.dir/tokenize.cpp.o
[ 54%] Building CXX object examples/parallel/CMakeFiles/parallel.dir/parallel.cpp.o
[ 55%] Building CXX object examples/perplexity/CMakeFiles/perplexity.dir/perplexity.cpp.o
[ 55%] Building CXX object examples/simple/CMakeFiles/simple.dir/simple.cpp.o
[ 56%] Building CXX object examples/save-load-state/CMakeFiles/save-load-state.dir/save-load-state.cpp.o
[ 57%] Building CXX object examples/passkey/CMakeFiles/passkey.dir/passkey.cpp.o
[ 58%] Building CXX object examples/speculative/CMakeFiles/speculative.dir/speculative.cpp.o
[ 59%] Building CXX object examples/lookahead/CMakeFiles/lookahead.dir/lookahead.cpp.o
[ 60%] Building CXX object examples/train-text-from-scratch/CMakeFiles/train-text-from-scratch.dir/train-text-from-scratch.cpp.o
[ 61%] Building CXX object examples/lookup/CMakeFiles/lookup.dir/lookup.cpp.o
[ 62%] Building CXX object examples/imatrix/CMakeFiles/imatrix.dir/imatrix.cpp.o
[ 63%] Building CXX object examples/server/CMakeFiles/server.dir/server.cpp.o
[ 64%] Building CXX object pocs/vdot/CMakeFiles/vdot.dir/vdot.cpp.o
[ 65%] Building CXX object examples/export-lora/CMakeFiles/export-lora.dir/export-lora.cpp.o
[ 66%] Building CXX object pocs/vdot/CMakeFiles/q8dot.dir/q8dot.cpp.o
[ 67%] Linking CXX executable ../bin/test-model-load-cancel
[ 68%] Linking CXX executable ../bin/test-grad0
[ 68%] Linking CXX executable ../bin/test-rope
[ 68%] Built target test-grad0
[ 69%] Linking CXX executable ../bin/test-autorelease
[ 70%] Linking CXX executable ../bin/test-quantize-fns
[ 70%] Built target test-rope
[ 70%] Built target test-model-load-cancel
[ 71%] Linking CXX executable ../bin/test-grammar-parser
[ 72%] Linking CXX executable ../bin/test-sampling
[ 72%] Built target test-quantize-fns
[ 73%] Linking CXX executable ../../bin/baby-llama
[ 74%] Linking CXX executable ../../bin/q8dot
[ 74%] Built target test-grammar-parser
[ 74%] Built target test-autorelease
[ 75%] Linking CXX executable ../../bin/vdot
[ 76%] Linking CXX executable ../../bin/tokenize
[ 76%] Built target q8dot
[ 76%] Built target vdot
[ 76%] Built target test-sampling
[ 77%] Linking CXX executable ../../bin/save-load-state
[ 78%] Linking CXX executable ../../bin/beam-search
[ 78%] Linking CXX executable ../../bin/batched-bench
[ 79%] Linking CXX executable ../../bin/simple
[ 80%] Linking CXX executable ../bin/test-tokenizer-0-falcon
[ 81%] Linking CXX executable ../bin/test-tokenizer-0-llama
[ 82%] Linking CXX executable ../../bin/batched
[ 83%] Linking CXX executable ../../bin/llava-cli
[ 84%] Linking CXX executable ../bin/test-quantize-perf
[ 85%] Linking CXX executable ../../bin/passkey
[ 85%] Built target baby-llama
[ 86%] Linking CXX executable ../../bin/parallel
[ 87%] Linking CXX executable ../../bin/lookup
[ 87%] Linking CXX executable ../../bin/embedding
[ 88%] Linking CXX executable ../../bin/export-lora
[ 89%] Linking CXX executable ../../bin/train-text-from-scratch
[ 90%] Linking CXX executable ../../bin/speculative
[ 90%] Linking CXX executable ../../bin/lookahead
[ 90%] Built target tokenize
[ 91%] Linking CXX executable ../../bin/finetune
[ 91%] Built target test-quantize-perf
[ 92%] Linking CXX executable ../../bin/convert-llama2c-to-ggml
[ 92%] Linking CXX executable ../../bin/infill
[ 92%] Built target export-lora
[ 93%] Linking CXX executable ../../bin/main
[ 93%] Built target convert-llama2c-to-ggml
[ 93%] Built target save-load-state
[ 93%] Built target beam-search
[ 93%] Built target simple
[ 93%] Built target test-tokenizer-0-llama
[ 93%] Built target batched-bench
[ 93%] Built target test-tokenizer-0-falcon
[ 93%] Built target passkey
[ 94%] Linking CXX executable ../../bin/imatrix
[ 94%] Built target lookup
[ 94%] Built target embedding
[ 94%] Built target batched
[ 94%] Built target parallel
[ 94%] Built target train-text-from-scratch
[ 95%] Linking CXX executable ../bin/test-tokenizer-1-llama
[ 95%] Built target llava-cli
[ 96%] Linking CXX executable ../bin/test-tokenizer-1-bpe
[ 96%] Built target finetune
[ 96%] Built target speculative
[ 96%] Built target lookahead
[ 97%] Linking CXX executable ../bin/test-backend-ops
[ 97%] Built target infill
[ 97%] Built target main
[ 97%] Built target test-backend-ops
[ 97%] Built target imatrix
[ 97%] Linking CXX executable ../../bin/perplexity
[ 97%] Built target test-tokenizer-1-llama
[ 97%] Built target test-tokenizer-1-bpe
[ 97%] Built target perplexity
[ 98%] Linking CXX executable ../../bin/llama-bench
[ 98%] Built target llama-bench
[ 99%] Linking CXX executable ../bin/test-llama-grammar
[ 99%] Built target test-llama-grammar
[100%] Linking CXX executable ../../bin/server
[100%] Built target server

real	1m55.117s
user	3m12.073s
sys	0m14.614s
+ tee -a /home/ggml/results/llama.cpp/97/d6a0cc0663d52248def278ee6472b9ede7742c/ggml-4-x86-cuda-v100/ctest_debug-ctest.log
+ ctest --output-on-failure -L main -E test-opt
Test project /home/ggml/work/llama.cpp/build-ci-debug
      Start  1: test-quantize-fns
 1/20 Test  #1: test-quantize-fns ...................   Passed    0.81 sec
      Start  2: test-quantize-perf
 2/20 Test  #2: test-quantize-perf ..................   Passed    1.22 sec
      Start  3: test-sampling
 3/20 Test  #3: test-sampling .......................   Passed    0.07 sec
      Start  4: test-tokenizer-0-llama
 4/20 Test  #4: test-tokenizer-0-llama ..............   Passed    0.71 sec
      Start  5: test-tokenizer-0-falcon
 5/20 Test  #5: test-tokenizer-0-falcon .............   Passed    1.77 sec
      Start  6: test-tokenizer-1-llama
 6/20 Test  #6: test-tokenizer-1-llama ..............   Passed    4.17 sec
      Start  7: test-tokenizer-1-baichuan
 7/20 Test  #7: test-tokenizer-1-baichuan ...........   Passed    4.56 sec
      Start  8: test-tokenizer-1-falcon
 8/20 Test  #8: test-tokenizer-1-falcon .............   Passed    8.32 sec
      Start  9: test-tokenizer-1-aquila
 9/20 Test  #9: test-tokenizer-1-aquila .............   Passed   11.50 sec
      Start 10: test-tokenizer-1-mpt
10/20 Test #10: test-tokenizer-1-mpt ................   Passed    6.92 sec
      Start 11: test-tokenizer-1-stablelm-3b-4e1t
11/20 Test #11: test-tokenizer-1-stablelm-3b-4e1t ...   Passed    6.87 sec
      Start 12: test-tokenizer-1-gpt-neox
12/20 Test #12: test-tokenizer-1-gpt-neox ...........   Passed    6.93 sec
      Start 13: test-tokenizer-1-refact
13/20 Test #13: test-tokenizer-1-refact .............   Passed    6.67 sec
      Start 14: test-tokenizer-1-starcoder
14/20 Test #14: test-tokenizer-1-starcoder ..........   Passed    6.60 sec
      Start 15: test-tokenizer-1-gpt2
15/20 Test #15: test-tokenizer-1-gpt2 ...............   Passed    6.97 sec
      Start 16: test-grammar-parser
16/20 Test #16: test-grammar-parser .................   Passed    0.00 sec
      Start 17: test-llama-grammar
17/20 Test #17: test-llama-grammar ..................   Passed    0.04 sec
      Start 18: test-grad0
18/20 Test #18: test-grad0 ..........................   Passed    4.72 sec
      Start 19: test-backend-ops
19/20 Test #19: test-backend-ops ....................***Failed  144.00 sec
ggml_backend_register: registered backend CPU
ggml_backend_register: registered backend CUDA0
ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no
ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes
ggml_init_cublas: found 1 CUDA devices:
  Device 0: Tesla V100-PCIE-16GB, compute capability 7.0, VMM: yes
Testing 2 backends

Backend 1/2 (CPU)
  Backend name: CPU
  ABS(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  SGN(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  NEG(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  STEP(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  TANH(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  ELU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  RELU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GELU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GELU_QUICK(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  SILU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  HARDSWISH(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  HARDSIGMOID(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GET_ROWS(type=f32,n=1,m=8,r=2,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=iq2_xxs,n=256,m=5,r=4,b=1,v=0): ================================================================= iq2xs_init_impl(grid_size = 256)
iq2xs_init_impl: 373964 neighbours in total
[1;32mOK[0m
  GET_ROWS(type=iq2_xxs,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=iq2_xxs,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=iq2_xxs,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=iq2_xs,n=256,m=5,r=4,b=1,v=0): ================================================================= iq2xs_init_impl(grid_size = 512)
iq2xs_init_impl: 508542 neighbours in total
[1;32mOK[0m
  GET_ROWS(type=iq2_xs,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=iq2_xs,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=iq2_xs,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=iq3_xxs,n=256,m=5,r=4,b=1,v=0): ================================================================= iq3xs_init_impl(grid_size = 256)
iq3xs_init_impl: 18985 neighbours in total
[1;32mOK[0m
  GET_ROWS(type=iq3_xxs,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=iq3_xxs,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=iq3_xxs,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=i32,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=i32,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=i32,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=i32,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  IM2COL(type_input=f32,type_kernel=f16,dst_type=f32,ne_input=[10,10,3,1],ne_kernel=[3,3,3,1],s0=1,s1=1,p0=1,p1=1,d0=1,d1=1,is_2D=1): [1;32mOK[0m
  IM2COL(type_input=f32,type_kernel=f16,dst_type=f16,ne_input=[10,10,3,1],ne_kernel=[3,3,3,1],s0=1,s1=1,p0=1,p1=1,d0=1,d1=1,is_2D=1): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  REPEAT(type=i32,ne=[10,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  REPEAT(type=i16,ne=[10,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  DUP(type=f32,ne=[10,10,10,1]): [1;32mOK[0m
  DUP(type=f16,ne=[10,10,10,1]): [1;32mOK[0m
  DUP(type=i32,ne=[10,10,10,1]): [1;32mOK[0m
  DUP(type=i16,ne=[10,10,10,1]): [1;32mOK[0m
  DUP(type=i16,ne=[10,8,3,1],permute=[0,2,1,3]): [1;32mOK[0m
  DUP(type=i16,ne=[10,8,3,1],permute=[1,2,0,3]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=f32,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=f16,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q4_0,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q4_1,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q5_0,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q5_1,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q8_0,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q2_K,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q3_K,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q4_K,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q5_K,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q6_K,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=iq2_xxs,ne=[256,4,4,4]): not supported [CPU] not supported [CPU] 
  CPY(type_src=f16,type_dst=iq2_xs,ne=[256,4,4,4]): not supported [CPU] not supported [CPU] 
  CPY(type_src=f16,type_dst=iq3_xxs,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=f32,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=f16,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q4_0,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q4_1,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q5_0,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q5_1,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q8_0,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q2_K,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q3_K,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q4_K,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q5_K,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q6_K,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=iq2_xxs,ne=[256,4,4,4]): not supported [CPU] not supported [CPU] 
  CPY(type_src=f32,type_dst=iq2_xs,ne=[256,4,4,4]): not supported [CPU] not supported [CPU] 
  CPY(type_src=f32,type_dst=iq3_xxs,ne=[256,4,4,4]): [1;32mOK[0m
  CONT(type=f32,ne=[10,10,10,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,8,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,8,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,8,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1,1],nr=[32,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1,1],nr=[32,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1,1],nr=[32,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,320,320],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,320,320],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,320,320],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,2,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,2,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,2,2]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,2,2,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,2,2,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,2,2,2]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[2,2,2,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[2,2,2,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[2,2,2,2]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,1,1,1],nr=[1,16,16,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,1,1,1],nr=[1,16,16,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,1,1,1],nr=[1,16,16,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,16,16,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,16,16,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,16,16,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1280,1],nr=[16,16,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1280,1],nr=[16,16,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1280,1],nr=[16,16,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,16,1280,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,16,1280,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,16,1280,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1920,1],nr=[16,16,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1920,1],nr=[16,16,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1920,1],nr=[16,16,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,2560,1],nr=[16,16,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,2560,1],nr=[16,16,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,2560,1],nr=[16,16,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1280,1],nr=[32,32,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1280,1],nr=[32,32,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1280,1],nr=[32,32,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1920,1],nr=[32,32,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1920,1],nr=[32,32,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1920,1],nr=[32,32,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,640,1],nr=[32,32,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,640,1],nr=[32,32,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,640,1],nr=[32,32,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[5120,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[5120,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[5120,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[640,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[640,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[640,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  SCALE(type=f32,ne=[10,10,10,10],scale=2.000000): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.000001): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.000001): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.000010): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.000010): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.001000): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.001000): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.100000): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.100000): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  SQR(type=f32,ne=[10,10,10,10]): [1;32mOK[0m
  CLAMP(type=f32,ne=[10,10,10,10],min=-0.500000,max=0.500000): [1;32mOK[0m
  DIAG_MASK_INF(type=f32,ne=[10,10,1,1],n_past=5): [1;32mOK[0m
  DIAG_MASK_INF(type=f32,ne=[10,10,10,1],n_past=5): [1;32mOK[0m
  DIAG_MASK_INF(type=f32,ne=[10,10,10,10],n_past=5): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1,7,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,23,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,11,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1,34,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,47,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1,26,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,2,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1,27,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,1,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1,4,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[3,35,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[3,47,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[4,27,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,33,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[3,36,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[4,39,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,3,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[4,17,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[3,38,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[4,19,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[5,50,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[7,38,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[7,4,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[7,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[5,22,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[7,24,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[5,14,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[5,9,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[6,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[8,4,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[16,26,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[12,16,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[16,25,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[10,5,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[16,4,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[12,20,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[10,46,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[12,24,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[16,3,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[14,39,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[30,7,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[16,35,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[30,32,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[28,37,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[32,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[19,16,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[21,26,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[26,43,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[23,43,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[20,21,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[49,24,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[41,9,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[37,29,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[58,2,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[49,25,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[63,38,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[50,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[52,43,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[37,11,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[55,7,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[69,14,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[64,21,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[65,36,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[124,12,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[75,16,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[121,33,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[73,35,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[89,20,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[96,8,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[102,43,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[204,48,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[199,8,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[254,21,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[146,29,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[160,25,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[187,49,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[144,10,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[169,32,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[144,33,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[208,41,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[319,24,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[356,11,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[263,46,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[365,8,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[499,21,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[289,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[279,9,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[274,19,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[321,7,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[457,23,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[691,23,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[926,47,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[846,11,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[860,46,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[640,44,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[753,26,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[820,41,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[899,24,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1000,32,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[737,42,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1730,36,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2035,48,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1896,15,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1574,26,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1130,21,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1615,44,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1475,37,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1914,36,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1844,36,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1784,1,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[3863,27,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2997,4,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[3509,25,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[3416,35,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2456,46,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[3822,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[3162,7,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2970,50,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2489,23,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2694,26,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[7707,22,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[6011,41,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[5592,11,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[8189,8,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[6679,31,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[4098,1,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[7264,37,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[5403,21,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[6892,35,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[4936,42,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[14000,42,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[8966,5,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[14451,32,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[9944,11,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[8856,20,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[15993,48,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[11386,14,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[13862,15,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[14556,40,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[11653,15,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[19562,1,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[19527,50,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[20382,41,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[18619,20,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[26231,9,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[29956,8,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[32571,13,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[20211,6,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[19979,32,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[27788,40,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[55583,38,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[54707,32,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[34617,30,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[40206,16,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[55701,6,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[57757,27,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[50919,30,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[43571,36,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[37455,9,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[48671,44,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[118835,28,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[113968,16,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[74405,27,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[85901,30,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[99490,22,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[82500,19,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[91293,23,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[96725,20,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[83840,4,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[89768,13,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[16,2,32,1],mask=0,scale=0.100000,max_bias=0.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[32,2,32,1],mask=1,scale=0.100000,max_bias=0.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[16,2,32,1],mask=0,scale=0.100000,max_bias=8.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[32,2,32,1],mask=1,scale=0.100000,max_bias=8.000000): [1;32mOK[0m
  ROPE(type=f32,ne=[128,32,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[128,40,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[128,52,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[128,64,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,1,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,71,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,8,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,128,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[80,32,10,1],n_dims=20,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[80,32,10,1],n_dims=32,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,32,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,40,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,52,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,64,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,1,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,71,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,8,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,128,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[80,32,10,1],n_dims=20,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[80,32,10,1],n_dims=32,mode=2,n_ctx=512): [1;32mOK[0m
  ALIBI(type=f32,ne=[10,10,10,10],n_past=512,n_head=10,bias_max=0.500000): [1;32mOK[0m
  CONCAT(type=f32,ne=[10,10,10,10],b_ne2=10): [1;32mOK[0m
  CONCAT(type=i32,ne=[10,10,10,10],b_ne2=10): [1;32mOK[0m
  ARGSORT(type=f32,ne=[8,1,1,1],order=0): [1;32mOK[0m
  ARGSORT(type=f32,ne=[16,10,10,10],order=0): [1;32mOK[0m
  ARGSORT(type=f32,ne=[8,1,1,1],order=1): [1;32mOK[0m
  ARGSORT(type=f32,ne=[16,10,10,10],order=1): [1;32mOK[0m
  SUM_ROWS(type=f32,ne=[10,10,10,10]): [1;32mOK[0m
  UPSCALE(type=f32,ne=[512,512,3,1],scale_factor=2): [1;32mOK[0m
  GROUP_NORM(type=f32,ne=[64,64,320,1],num_groups=32): [1;32mOK[0m
  ACC(type=f32,ne_a=[1024,577,1,1],ne_b=[1024,576,1,1]): [1;32mOK[0m
  PAD(type=f32,ne_a=[512,512,1,1],pad_0=1,pad_1=1): [1;32mOK[0m
  LEAKY_RELU(type=f32,ne_a=[10,10,10,10],negative_slope=0.100000): [1;32mOK[0m
  1390/1390 tests passed
  Backend CPU: [1;32mOK[0m

Backend 2/2 (CUDA0)
  Backend name: CUDA0
  ABS(type=f32,ne=[128,10,10,10]): not supported [CUDA0] 
  SGN(type=f32,ne=[128,10,10,10]): not supported [CUDA0] 
  NEG(type=f32,ne=[128,10,10,10]): not supported [CUDA0] 
  STEP(type=f32,ne=[128,10,10,10]): not supported [CUDA0] 
  TANH(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  ELU(type=f32,ne=[128,10,10,10]): not supported [CUDA0] 
  RELU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GELU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GELU_QUICK(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  SILU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  HARDSWISH(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  HARDSIGMOID(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GET_ROWS(type=f32,n=1,m=8,r=2,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=1,v=0): not supported [CUDA0] 
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=1,v=1): not supported [CUDA0] 
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=7,v=0): not supported [CUDA0] 
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=7,v=1): not supported [CUDA0] 
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=1,v=0): not supported [CUDA0] 
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=1,v=1): not supported [CUDA0] 
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=7,v=0): not supported [CUDA0] 
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=7,v=1): not supported [CUDA0] 
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=1,v=0): not supported [CUDA0] 
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=1,v=1): not supported [CUDA0] 
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=7,v=0): not supported [CUDA0] 
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=7,v=1): not supported [CUDA0] 
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=1,v=0): not supported [CUDA0] 
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=1,v=1): not supported [CUDA0] 
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=7,v=0): not supported [CUDA0] 
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=7,v=1): not supported [CUDA0] 
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=1,v=0): not supported [CUDA0] 
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=1,v=1): not supported [CUDA0] 
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=7,v=0): not supported [CUDA0] 
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=7,v=1): not supported [CUDA0] 
  GET_ROWS(type=iq2_xxs,n=256,m=5,r=4,b=1,v=0): not supported [CUDA0] 
  GET_ROWS(type=iq2_xxs,n=256,m=5,r=4,b=1,v=1): not supported [CUDA0] 
  GET_ROWS(type=iq2_xxs,n=256,m=5,r=4,b=7,v=0): not supported [CUDA0] 
  GET_ROWS(type=iq2_xxs,n=256,m=5,r=4,b=7,v=1): not supported [CUDA0] 
  GET_ROWS(type=iq2_xs,n=256,m=5,r=4,b=1,v=0): not supported [CUDA0] 
  GET_ROWS(type=iq2_xs,n=256,m=5,r=4,b=1,v=1): not supported [CUDA0] 
  GET_ROWS(type=iq2_xs,n=256,m=5,r=4,b=7,v=0): not supported [CUDA0] 
  GET_ROWS(type=iq2_xs,n=256,m=5,r=4,b=7,v=1): not supported [CUDA0] 
  GET_ROWS(type=iq3_xxs,n=256,m=5,r=4,b=1,v=0): not supported [CUDA0] 
  GET_ROWS(type=iq3_xxs,n=256,m=5,r=4,b=1,v=1): not supported [CUDA0] 
  GET_ROWS(type=iq3_xxs,n=256,m=5,r=4,b=7,v=0): not supported [CUDA0] 
  GET_ROWS(type=iq3_xxs,n=256,m=5,r=4,b=7,v=1): not supported [CUDA0] 
  GET_ROWS(type=i32,n=256,m=5,r=4,b=1,v=0): not supported [CUDA0] 
  GET_ROWS(type=i32,n=256,m=5,r=4,b=1,v=1): not supported [CUDA0] 
  GET_ROWS(type=i32,n=256,m=5,r=4,b=7,v=0): not supported [CUDA0] 
  GET_ROWS(type=i32,n=256,m=5,r=4,b=7,v=1): not supported [CUDA0] 
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=avg,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=1,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=1,k1=3,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=1,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=1,s1=2,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=1,p0=1,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=0,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=0,p1=1): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=1,p1=0): [1;32mOK[0m
  POOL_2D(pool_type=max,type_input=f32,ne_input=[10,10,3,1],k0=3,k1=3,s0=2,s1=2,p0=1,p1=1): [1;32mOK[0m
  IM2COL(type_input=f32,type_kernel=f16,dst_type=f32,ne_input=[10,10,3,1],ne_kernel=[3,3,3,1],s0=1,s1=1,p0=1,p1=1,d0=1,d1=1,is_2D=1): [1;32mOK[0m
  IM2COL(type_input=f32,type_kernel=f16,dst_type=f16,ne_input=[10,10,3,1],ne_kernel=[3,3,3,1],s0=1,s1=1,p0=1,p1=1,d0=1,d1=1,is_2D=1): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  REPEAT(type=i32,ne=[10,10,10,10],nr=[2,1,1,1]): not supported [CUDA0] 
  REPEAT(type=i16,ne=[10,10,10,10],nr=[1,1,1,2]): not supported [CUDA0] 
  DUP(type=f32,ne=[10,10,10,1]): [1;32mOK[0m
  DUP(type=f16,ne=[10,10,10,1]): [1;32mOK[0m
  DUP(type=i32,ne=[10,10,10,1]): not supported [CUDA0] 
  DUP(type=i16,ne=[10,10,10,1]): not supported [CUDA0] 
  DUP(type=i16,ne=[10,8,3,1],permute=[0,2,1,3]): not supported [CUDA0] 
  DUP(type=i16,ne=[10,8,3,1],permute=[1,2,0,3]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=f32,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=f16,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f16,type_dst=q4_0,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=q4_1,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=q5_0,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=q5_1,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=q8_0,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=q2_K,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=q3_K,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=q4_K,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=q5_K,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=q6_K,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f16,type_dst=iq2_xxs,ne=[256,4,4,4]): not supported [CUDA0] not supported [CPU] 
  CPY(type_src=f16,type_dst=iq2_xs,ne=[256,4,4,4]): not supported [CUDA0] not supported [CPU] 
  CPY(type_src=f16,type_dst=iq3_xxs,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f32,type_dst=f32,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=f16,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q4_0,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q4_1,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q5_0,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f32,type_dst=q5_1,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f32,type_dst=q8_0,ne=[256,4,4,4]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q2_K,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f32,type_dst=q3_K,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f32,type_dst=q4_K,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f32,type_dst=q5_K,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f32,type_dst=q6_K,ne=[256,4,4,4]): not supported [CUDA0] 
  CPY(type_src=f32,type_dst=iq2_xxs,ne=[256,4,4,4]): not supported [CUDA0] not supported [CPU] 
  CPY(type_src=f32,type_dst=iq2_xs,ne=[256,4,4,4]): not supported [CUDA0] not supported [CPU] 
  CPY(type_src=f32,type_dst=iq3_xxs,ne=[256,4,4,4]): not supported [CUDA0] 
  CONT(type=f32,ne=[10,10,10,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,8,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,8,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,8,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1,1],nr=[32,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1,1],nr=[32,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1,1],nr=[32,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,320,320],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,320,320],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,320,320],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,2,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,2,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,2,2]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,2,2,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,2,2,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,2,2,2]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[2,2,2,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[2,2,2,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[2,2,2,2]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,1,1,1],nr=[1,16,16,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,1,1,1],nr=[1,16,16,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,1,1,1],nr=[1,16,16,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,16,16,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,16,16,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,16,16,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1280,1],nr=[16,16,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1280,1],nr=[16,16,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1280,1],nr=[16,16,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,16,1280,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,16,1280,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,16,1280,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1920,1],nr=[16,16,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1920,1],nr=[16,16,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1920,1],nr=[16,16,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,2560,1],nr=[16,16,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,2560,1],nr=[16,16,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,2560,1],nr=[16,16,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1280,1],nr=[32,32,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1280,1],nr=[32,32,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1280,1],nr=[32,32,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1920,1],nr=[32,32,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1920,1],nr=[32,32,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1920,1],nr=[32,32,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,640,1],nr=[32,32,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,640,1],nr=[32,32,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,640,1],nr=[32,32,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[5120,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[5120,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[5120,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[640,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[640,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[640,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  SCALE(type=f32,ne=[10,10,10,10],scale=2.000000): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.000001): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.000001): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.000010): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.000010): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.001000): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.001000): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.100000): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.100000): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq2_xs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CUDA0] 
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq3_xxs,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT(type_a=iq3_xxs,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CUDA0] not supported [CPU] 
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xxs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq2_xs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=iq3_xxs,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  SQR(type=f32,ne=[10,10,10,10]): [1;32mOK[0m
  CLAMP(type=f32,ne=[10,10,10,10],min=-0.500000,max=0.500000): [1;32mOK[0m
  DIAG_MASK_INF(type=f32,ne=[10,10,1,1],n_past=5): [1;32mOK[0m
  DIAG_MASK_INF(type=f32,ne=[10,10,10,1],n_past=5): [1;32mOK[0m
  DIAG_MASK_INF(type=f32,ne=[10,10,10,10],n_past=5): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[1,7,1,1],mask=1,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,23,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.000686928 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[2,11,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.000966767 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1,34,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,47,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.000970133 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1,26,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,2,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.000980506 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1,27,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[2,1,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.000976861 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1,4,1,1],mask=0,scale=0.100000,max_bias=4.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[3,35,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.001827415 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[3,47,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.001984713 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[4,27,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.004794167 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[2,33,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.000971880 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[3,36,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.002568017 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[4,39,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.004846412 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[2,3,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.000978477 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[4,17,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.004896225 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[3,38,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.002588871 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[4,19,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.004909419 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[5,50,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.006819995 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[7,38,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.013126465 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[7,4,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.015467698 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[7,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.015614570 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[5,22,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.007834198 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[7,24,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.015543670 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[5,14,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.007928355 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[5,9,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.007889420 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[6,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.011377771 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[8,4,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.020560151 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[16,26,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.073709853 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[12,16,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.038751981 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[16,25,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.081524617 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[10,5,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.031571109 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[16,4,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.080965766 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[12,20,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.045978125 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[10,46,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.032108202 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[12,24,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.046121944 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[16,3,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.082550411 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[14,39,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.062831195 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[30,7,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.277489082 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[16,35,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.075707369 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[30,32,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.276565307 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[28,37,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.243100819 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[32,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.312802536 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[19,16,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.114353368 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[21,26,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.138994697 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[26,43,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.210227433 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[23,43,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.165969404 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[20,21,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.126145325 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[49,24,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.666044017 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[41,9,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.495837567 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[37,29,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.411311857 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[58,2,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.914087523 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[49,25,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.678565874 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[63,38,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1.048752215 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[50,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.704108114 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[52,43,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.756034736 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[37,11,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.404924409 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[55,7,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 0.833220105 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[69,14,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1.122130862 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[64,21,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1.144842074 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[65,36,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1.103360367 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[124,12,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 2.875036379 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[75,16,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1.392530144 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[121,33,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 2.788005696 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[73,35,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1.325881113 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[89,20,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1.795958511 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[96,8,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 2.027869446 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[102,43,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 2.197578695 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[204,48,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 5.239360364 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[199,8,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 4.801824273 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[254,21,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 6.930106879 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[146,29,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 3.570136877 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[160,25,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 3.982296308 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[187,49,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 4.842965877 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[144,10,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 3.506812419 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[169,32,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 4.290263809 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[144,33,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 3.484673472 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[208,41,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 5.516617441 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[319,24,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 8.832561875 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[356,11,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 10.044839108 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[263,46,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 7.234120792 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[365,8,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 10.427815414 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[499,21,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 14.669738165 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[289,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 8.023836784 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[279,9,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 7.694233062 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[274,19,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 7.549382446 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[321,7,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 9.106966122 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[457,23,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 13.297604888 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[691,23,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 20.979501125 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[926,47,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 26.998857481 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[846,11,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 25.385820944 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[860,46,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 25.904206259 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[640,44,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 18.931413836 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[753,26,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 22.492218959 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[820,41,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 24.581234091 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[899,24,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 27.171755956 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1000,32,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 30.138935537 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[737,42,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 22.045977571 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1730,36,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 52.233297138 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[2035,48,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 60.714193565 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1896,15,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 58.335716139 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1574,26,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 48.347391629 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1130,21,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 34.243743607 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1615,44,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 49.368498140 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1475,37,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 45.195929216 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1914,36,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 58.942192564 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1844,36,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 56.678365642 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[1784,1,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 55.131169654 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[3863,27,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 114.248071576 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[2997,4,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 97.197913485 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[3509,25,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 109.126479107 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[3416,35,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 105.778885047 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[2456,46,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 75.676975001 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[3822,45,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 118.314648446 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[3162,7,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 98.268940411 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[2970,50,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 91.804288072 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[2489,23,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 76.499744665 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[2694,26,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 83.202537902 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[7707,22,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 234.430136456 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[6011,41,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 183.339999650 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[5592,11,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 173.138377881 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[8189,8,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 255.598772012 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[6679,31,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 208.255511780 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[4098,1,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 126.023397491 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[7264,37,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 225.588182001 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[5403,21,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 167.960491303 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[6892,35,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 214.223366434 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[4936,42,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 152.992133336 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[14000,42,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 412.196989838 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[8966,5,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 272.820882904 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[14451,32,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 449.924538678 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[9944,11,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 310.207658341 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[8856,20,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 275.192257488 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[15993,48,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 497.913793810 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[11386,14,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 354.113062702 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[13862,15,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 431.694670686 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[14556,40,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 452.734512957 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[11653,15,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 363.840752835 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[19562,1,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 533.620367315 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[19527,50,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 613.924034017 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[20382,41,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 633.374930344 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[18619,20,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 584.709137649 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[26231,9,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 813.239548936 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[29956,8,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 936.166525748 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[32571,13,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1019.763474988 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[20211,6,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 633.182805142 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[19979,32,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 624.317854293 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[27788,40,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 864.792810034 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[55583,38,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1663.933807864 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[54707,32,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1651.844761311 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[34617,30,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1082.241052216 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[40206,16,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1252.909515969 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[55701,6,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1730.915101232 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[57757,27,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1798.375004300 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[50919,30,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1589.587084955 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[43571,36,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1361.879357343 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[37455,9,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1168.825395971 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[48671,44,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 1516.563602724 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[118835,28,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 3633.432169118 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[113968,16,1,1],mask=1,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 3387.687812329 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[74405,27,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 2325.265190300 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[85901,30,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 2674.466000212 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[99490,22,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 3103.360199408 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[82500,19,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 2593.326235393 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[91293,23,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 2855.872489703 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[96725,20,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 3018.639093923 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[83840,4,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 2631.032596748 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[89768,13,1,1],mask=0,scale=0.100000,max_bias=4.000000): [SOFT_MAX] NMSE = 2805.247691612 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[16,2,32,1],mask=0,scale=0.100000,max_bias=0.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[32,2,32,1],mask=1,scale=0.100000,max_bias=0.000000): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[16,2,32,1],mask=0,scale=0.100000,max_bias=8.000000): [SOFT_MAX] NMSE = 0.804296543 > 0.000000100 [1;31mFAIL[0m
  SOFT_MAX(type=f32,ne=[32,2,32,1],mask=1,scale=0.100000,max_bias=8.000000): [SOFT_MAX] NMSE = 1.713157877 > 0.000000100 [1;31mFAIL[0m
  ROPE(type=f32,ne=[128,32,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[128,40,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[128,52,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[128,64,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,1,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,71,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,8,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,128,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[80,32,10,1],n_dims=20,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[80,32,10,1],n_dims=32,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,32,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,40,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,52,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,64,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,1,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,71,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,8,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,128,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[80,32,10,1],n_dims=20,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[80,32,10,1],n_dims=32,mode=2,n_ctx=512): [1;32mOK[0m
  ALIBI(type=f32,ne=[10,10,10,10],n_past=512,n_head=10,bias_max=0.500000): [1;32mOK[0m
  CONCAT(type=f32,ne=[10,10,10,10],b_ne2=10): [1;32mOK[0m
  CONCAT(type=i32,ne=[10,10,10,10],b_ne2=10): not supported [CUDA0] 
  ARGSORT(type=f32,ne=[8,1,1,1],order=0): [1;32mOK[0m
  ARGSORT(type=f32,ne=[16,10,10,10],order=0): [1;32mOK[0m
  ARGSORT(type=f32,ne=[8,1,1,1],order=1): [1;32mOK[0m
  ARGSORT(type=f32,ne=[16,10,10,10],order=1): [1;32mOK[0m
  SUM_ROWS(type=f32,ne=[10,10,10,10]): [1;32mOK[0m
  UPSCALE(type=f32,ne=[512,512,3,1],scale_factor=2): [1;32mOK[0m
  GROUP_NORM(type=f32,ne=[64,64,320,1],num_groups=32): [1;32mOK[0m
  ACC(type=f32,ne_a=[1024,577,1,1],ne_b=[1024,576,1,1]): [1;32mOK[0m
  PAD(type=f32,ne_a=[512,512,1,1],pad_0=1,pad_1=1): [1;32mOK[0m
  LEAKY_RELU(type=f32,ne_a=[10,10,10,10],negative_slope=0.100000): [1;32mOK[0m
  1223/1390 tests passed
  Backend CUDA0: [1;31mFAIL[0m

1/2 backends passed
[1;31mFAIL[0m

      Start 20: test-rope
20/20 Test #20: test-rope ...........................   Passed    0.61 sec

95% tests passed, 1 tests failed out of 20

Label Time Summary:
main    = 223.44 sec*proc (20 tests)

Total Test time (real) = 223.46 sec

The following tests FAILED:
	 19 - test-backend-ops (Failed)
Errors while running CTest

real	3m43.492s
user	6m22.503s
sys	0m28.021s
+ cur=8
+ echo 8
+ set +x
