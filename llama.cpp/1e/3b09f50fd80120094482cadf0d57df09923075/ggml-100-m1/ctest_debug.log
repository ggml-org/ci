+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_FATAL_WARNINGS=ON -DLLAMA_METAL_SHADER_DEBUG=ON ..
-- The C compiler identification is AppleClang 15.0.0.15000100
-- The CXX compiler identification is AppleClang 15.0.0.15000100
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.39.3 (Apple Git-145)") 
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- Accelerate framework found
-- Metal framework found
-- ccache found, compilation results will be cached. Disable with LLAMA_CCACHE=OFF.
-- CMAKE_SYSTEM_PROCESSOR: arm64
-- ARM detected
-- Performing Test COMPILER_SUPPORTS_FP16_FORMAT_I3E
-- Performing Test COMPILER_SUPPORTS_FP16_FORMAT_I3E - Failed
-- Configuring done (0.6s)
-- Generating done (0.2s)
-- Build files have been written to: /Users/ggml/work/llama.cpp/build-ci-debug

real	0m0.850s
user	0m0.401s
sys	0m0.416s
+ make -j
[  1%] Generating build details from Git
[  2%] Building C object CMakeFiles/ggml.dir/ggml.c.o
[  3%] Building C object CMakeFiles/ggml.dir/ggml-quants.c.o
[  4%] Building C object CMakeFiles/ggml.dir/ggml-alloc.c.o
[  5%] Compiling Metal kernels
[  5%] Building C object CMakeFiles/ggml.dir/ggml-backend.c.o
[  6%] Building C object CMakeFiles/ggml.dir/ggml-metal.m.o
-- Found Git: /usr/bin/git (found version "2.39.3 (Apple Git-145)") 
[  6%] Built target ggml
[  7%] Building CXX object CMakeFiles/llama.dir/llama.cpp.o
[  8%] Building CXX object examples/gguf/CMakeFiles/gguf.dir/gguf.cpp.o
[  8%] Linking C static library libggml_static.a
[  9%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  9%] Built target ggml_static
[ 10%] Linking CXX executable ../../bin/gguf
[ 10%] Built target build_info
[ 10%] Built target gguf
[ 10%] Built target ggml-metal
/Users/ggml/work/llama.cpp/llama.cpp:8100:103: error: format specifies type 'int' but the argument has type 'int64_t' (aka 'long long') [-Werror,-Wformat]
                printf("reading: [%d, %d], embeddings_out.size() = %d, n_tokens = %d, n_embd = %d\n", (n_embd*i), n_embd, embeddings_out.size(), n_tokens, n_embd);
                                  ~~                                                                  ^~~~~~~~~~
                                  %lld
/Users/ggml/work/llama.cpp/llama.cpp:8100:115: error: format specifies type 'int' but the argument has type 'int64_t' (aka 'long long') [-Werror,-Wformat]
                printf("reading: [%d, %d], embeddings_out.size() = %d, n_tokens = %d, n_embd = %d\n", (n_embd*i), n_embd, embeddings_out.size(), n_tokens, n_embd);
                                      ~~                                                                          ^~~~~~
                                      %lld
/Users/ggml/work/llama.cpp/llama.cpp:8100:123: error: format specifies type 'int' but the argument has type 'size_type' (aka 'unsigned long') [-Werror,-Wformat]
                printf("reading: [%d, %d], embeddings_out.size() = %d, n_tokens = %d, n_embd = %d\n", (n_embd*i), n_embd, embeddings_out.size(), n_tokens, n_embd);
                                                                   ~~                                                     ^~~~~~~~~~~~~~~~~~~~~
                                                                   %zu
/Users/ggml/work/llama.cpp/llama.cpp:8100:156: error: format specifies type 'int' but the argument has type 'int64_t' (aka 'long long') [-Werror,-Wformat]
                printf("reading: [%d, %d], embeddings_out.size() = %d, n_tokens = %d, n_embd = %d\n", (n_embd*i), n_embd, embeddings_out.size(), n_tokens, n_embd);
                                                                                               ~~                                                          ^~~~~~
                                                                                               %lld
4 errors generated.
make[2]: *** [CMakeFiles/llama.dir/llama.cpp.o] Error 1
make[1]: *** [CMakeFiles/llama.dir/all] Error 2
make: *** [all] Error 2
