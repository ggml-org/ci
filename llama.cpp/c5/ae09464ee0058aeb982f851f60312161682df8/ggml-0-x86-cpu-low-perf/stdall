mkdir: cannot create directory ‘/mnt/llama.cpp’: Permission denied
+ gg_run_ctest_debug
+ cd /home/ggml/work/llama.cpp
+ rm -rf build-ci-debug
+ tee /home/ggml/results/llama.cpp/c5/ae09464ee0058aeb982f851f60312161682df8/ggml-0-x86-cpu-low-perf/ctest_debug.log
+ mkdir build-ci-debug
+ cd build-ci-debug
+ set -e
+ tee -a /home/ggml/results/llama.cpp/c5/ae09464ee0058aeb982f851f60312161682df8/ggml-0-x86-cpu-low-perf/ctest_debug-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_FATAL_WARNINGS=ON ..
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1") 
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with LLAMA_CCACHE=OFF
-- CMAKE_SYSTEM_PROCESSOR: x86_64
-- x86 detected
-- Configuring done
-- Generating done
-- Build files have been written to: /home/ggml/work/llama.cpp/build-ci-debug

real	0m0.452s
user	0m0.308s
sys	0m0.124s
+ tee -a /home/ggml/results/llama.cpp/c5/ae09464ee0058aeb982f851f60312161682df8/ggml-0-x86-cpu-low-perf/ctest_debug-make.log
+ make -j
[  0%] Generating build details from Git
[  1%] Building C object CMakeFiles/ggml.dir/ggml.c.o
[  2%] Building C object CMakeFiles/ggml.dir/ggml-alloc.c.o
[  3%] Building C object CMakeFiles/ggml.dir/ggml-quants.c.o
-- Found Git: /usr/bin/git (found version "2.34.1") 
[  4%] Building C object CMakeFiles/ggml.dir/ggml-backend.c.o
[  5%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  5%] Built target build_info
[  5%] Built target ggml
[  6%] Building CXX object CMakeFiles/llama.dir/llama.cpp.o
[  6%] Linking C static library libggml_static.a
[  7%] Building CXX object examples/gguf/CMakeFiles/gguf.dir/gguf.cpp.o
[  7%] Built target ggml_static
[  8%] Linking CXX executable ../../bin/gguf
[  8%] Built target gguf
/home/ggml/work/llama.cpp/llama.cpp:2660:14: error: explicit specialization in non-namespace scope ‘struct llama_model_loader’
 2660 |     template<>
      |              ^
/home/ggml/work/llama.cpp/llama.cpp: In instantiation of ‘class GGUFMeta::GKV<llama_pooling_type>’:
/home/ggml/work/llama.cpp/llama.cpp:2646:49:   required from ‘bool llama_model_loader::get_key(const string&, T&, bool) [with T = llama_pooling_type; std::string = std::__cxx11::basic_string<char>]’
/home/ggml/work/llama.cpp/llama.cpp:2657:23:   required from ‘bool llama_model_loader::get_key(llm_kv, T&, bool) [with T = llama_pooling_type]’
/home/ggml/work/llama.cpp/llama.cpp:3125:27:   required from here
/home/ggml/work/llama.cpp/llama.cpp:2334:11: error: invalid use of incomplete type ‘struct GGUFMeta::GKV_Base<llama_pooling_type>’
 2334 |     class GKV : public GKV_Base<T> {
      |           ^~~
/home/ggml/work/llama.cpp/llama.cpp:2292:33: note: declaration of ‘struct GGUFMeta::GKV_Base<llama_pooling_type>’
 2292 |     template<typename T> struct GKV_Base;
      |                                 ^~~~~~~~
make[2]: *** [CMakeFiles/llama.dir/build.make:76: CMakeFiles/llama.dir/llama.cpp.o] Error 1
make[1]: *** [CMakeFiles/Makefile2:792: CMakeFiles/llama.dir/all] Error 2
make: *** [Makefile:146: all] Error 2

real	0m3.506s
user	0m4.928s
sys	0m0.428s
+ cur=2
+ echo 2
+ set +x
cat: /home/ggml/results/llama.cpp/c5/ae09464ee0058aeb982f851f60312161682df8/ggml-0-x86-cpu-low-perf/ctest_debug-ctest.log: No such file or directory
