Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu
Requirement already satisfied: numpy~=1.26.4 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 1)) (1.26.4)
Requirement already satisfied: sentencepiece~=0.2.0 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 2)) (0.2.0)
Requirement already satisfied: transformers<5.0.0,>=4.45.1 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (4.45.1)
Requirement already satisfied: gguf>=0.1.0 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 4)) (0.15.0)
Requirement already satisfied: protobuf<5.0.0,>=4.21.0 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 5)) (4.25.3)
Requirement already satisfied: torch~=2.2.1 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from -r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2.2.2)
Requirement already satisfied: filelock in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.14.0)
Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.25.1)
Requirement already satisfied: packaging>=20.0 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (24.0)
Requirement already satisfied: regex!=2019.12.17 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2024.5.10)
Requirement already satisfied: safetensors>=0.4.1 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.4.3)
Requirement already satisfied: tqdm>=4.27 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (4.66.4)
Requirement already satisfied: requests in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2.31.0)
Requirement already satisfied: tokenizers<0.21,>=0.20 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.20.0)
Requirement already satisfied: pyyaml>=5.1 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (6.0.1)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (12.1.105)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (12.1.105)
Requirement already satisfied: jinja2 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.1.4)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (12.1.3.1)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (12.1.105)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (11.4.5.107)
Requirement already satisfied: triton==2.2.0 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2.2.0)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2.19.3)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (11.0.2.54)
Requirement already satisfied: networkx in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.3)
Requirement already satisfied: sympy in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (1.12)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (12.1.105)
Requirement already satisfied: fsspec in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2024.3.1)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (12.1.0.106)
Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (4.11.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (12.4.127)
Requirement already satisfied: MarkupSafe>=2.0 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from jinja2->torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2.1.5)
Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.3.2)
Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2024.2.2)
Requirement already satisfied: idna<4,>=2.5 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.45.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.7)
Requirement already satisfied: mpmath>=0.19 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from sympy->torch~=2.2.1->-r /home/ggml/work/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (1.3.0)
Obtaining file:///home/ggml/work/llama.cpp/gguf-py
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: pyyaml>=5.1 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from gguf==0.15.0) (6.0.1)
Requirement already satisfied: sentencepiece<=0.2.0,>=0.1.98 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from gguf==0.15.0) (0.2.0)
Requirement already satisfied: numpy>=1.17 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from gguf==0.15.0) (1.26.4)
Requirement already satisfied: tqdm>=4.27 in /mnt/llama.cpp/venv/lib/python3.10/site-packages (from gguf==0.15.0) (4.66.4)
Building wheels for collected packages: gguf
  Building editable for gguf (pyproject.toml): started
  Building editable for gguf (pyproject.toml): finished with status 'done'
  Created wheel for gguf: filename=gguf-0.15.0-py3-none-any.whl size=3463 sha256=10c32970a6e7e43d1565f30e5877134e711a09a1c8a63176f923d7cc41855163
  Stored in directory: /tmp/pip-ephem-wheel-cache-7k69tg2j/wheels/a3/4c/52/c5934ad001d1a70ca5434f11ddc622cad9c0a484e9bf6feda3
Successfully built gguf
Installing collected packages: gguf
  Attempting uninstall: gguf
    Found existing installation: gguf 0.15.0
    Uninstalling gguf-0.15.0:
      Successfully uninstalled gguf-0.15.0
Successfully installed gguf-0.15.0
+ gg_run_ctest_debug
+ cd /home/ggml/work/llama.cpp
+ tee /home/ggml/results/llama.cpp/9a/735ae6d84b4bf76a8444d72fabef8ad353abcf/ggml-2-x86-cpu/ctest_debug.log
+ rm -rf build-ci-debug
+ mkdir build-ci-debug
+ cd build-ci-debug
+ set -e
+ gg_check_build_requirements
+ command -v cmake
+ command -v make
+ command -v ctest
+ tee -a /home/ggml/results/llama.cpp/9a/735ae6d84b4bf76a8444d72fabef8ad353abcf/ggml-2-x86-cpu/ctest_debug-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_FATAL_WARNINGS=ON ..
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1")
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE
-- ccache found, compilation results will be cached. Disable with GGML_CCACHE=OFF.
-- CMAKE_SYSTEM_PROCESSOR: x86_64
-- Including CPU backend
-- Found OpenMP_C: -fopenmp (found version "4.5")
-- Found OpenMP_CXX: -fopenmp (found version "4.5")
-- Found OpenMP: TRUE (found version "4.5")
-- x86 detected
-- Adding CPU backend variant ggml-cpu: -march=native 
-- Configuring done (0.6s)
-- Generating done (0.1s)
-- Build files have been written to: /home/ggml/work/llama.cpp/build-ci-debug

real	0m0.765s
user	0m0.585s
sys	0m0.184s
+ tee -a /home/ggml/results/llama.cpp/9a/735ae6d84b4bf76a8444d72fabef8ad353abcf/ggml-2-x86-cpu/ctest_debug-make.log
++ nproc
+ make -j8
[  0%] Generating build details from Git
[  1%] Building C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o
[  2%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o
[  2%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o
[  2%] Building C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o
[  2%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o
[  3%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o
[  4%] Building C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o
-- Found Git: /usr/bin/git (found version "2.34.1")
[  4%] Built target sha1
[  4%] Built target sha256
[  4%] Built target xxhash
[  5%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o
[  5%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o
[  6%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o
[  6%] Linking CXX shared library libggml-base.so
[  7%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  7%] Built target build_info
[  7%] Built target ggml-base
[  8%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o
[  8%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o
[  9%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o
[  9%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o
[ 10%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o
[ 10%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o
[ 11%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o
[ 11%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o
[ 12%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o
[ 12%] Linking CXX shared library libggml-cpu.so
[ 12%] Built target ggml-cpu
[ 13%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o
[ 13%] Linking CXX shared library libggml.so
[ 13%] Built target ggml
[ 13%] Building CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o
[ 13%] Building CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o
[ 14%] Building CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o
[ 14%] Building CXX object src/CMakeFiles/llama.dir/llama.cpp.o
[ 15%] Building CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o
[ 15%] Building CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o
[ 16%] Building CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o
[ 16%] Building CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o
[ 17%] Linking CXX executable ../../bin/llama-gguf
[ 17%] Built target llama-gguf
[ 18%] Building CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o
In file included from /home/ggml/work/llama.cpp/ggml/src/../include/ggml-cpu.h:4,
                 from /home/ggml/work/llama.cpp/src/../include/llama.h:5,
                 from /home/ggml/work/llama.cpp/src/llama-batch.h:3,
                 from /home/ggml/work/llama.cpp/src/llama-batch.cpp:1:
/home/ggml/work/llama.cpp/ggml/src/../include/ggml-backend.h:334:119: error: ‘ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t, ggml_cgraph*)’ hides constructor for ‘struct ggml_backend_graph_copy’ [-Werror=shadow]
  334 |     GGML_API struct ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t backend, struct ggml_cgraph * graph);
      |                                                                                                                       ^
cc1plus: all warnings being treated as errors
make[2]: *** [src/CMakeFiles/llama.dir/build.make:118: src/CMakeFiles/llama.dir/llama-batch.cpp.o] Error 1
make[2]: *** Waiting for unfinished jobs....
[ 19%] Linking CXX executable ../../bin/llama-gguf-hash
In file included from /home/ggml/work/llama.cpp/ggml/src/../include/ggml-cpu.h:4,
                 from /home/ggml/work/llama.cpp/src/../include/llama.h:5,
                 from /home/ggml/work/llama.cpp/src/llama-chat.cpp:3:
/home/ggml/work/llama.cpp/ggml/src/../include/ggml-backend.h:334:119: error: ‘ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t, ggml_cgraph*)’ hides constructor for ‘struct ggml_backend_graph_copy’ [-Werror=shadow]
  334 |     GGML_API struct ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t backend, struct ggml_cgraph * graph);
      |                                                                                                                       ^
cc1plus: all warnings being treated as errors
make[2]: *** [src/CMakeFiles/llama.dir/build.make:132: src/CMakeFiles/llama.dir/llama-chat.cpp.o] Error 1
[ 19%] Built target llama-gguf-hash
In file included from /home/ggml/work/llama.cpp/ggml/src/../include/ggml-cpu.h:4,
                 from /home/ggml/work/llama.cpp/src/../include/llama.h:5,
                 from /home/ggml/work/llama.cpp/src/llama-adapter.h:3,
                 from /home/ggml/work/llama.cpp/src/llama-adapter.cpp:1:
/home/ggml/work/llama.cpp/ggml/src/../include/ggml-backend.h:334:119: error: ‘ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t, ggml_cgraph*)’ hides constructor for ‘struct ggml_backend_graph_copy’ [-Werror=shadow]
  334 |     GGML_API struct ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t backend, struct ggml_cgraph * graph);
      |                                                                                                                       ^
In file included from /home/ggml/work/llama.cpp/src/llama-adapter.cpp:1:
/home/ggml/work/llama.cpp/src/llama-adapter.h: In constructor ‘llama_adapter_lora_weight::llama_adapter_lora_weight(ggml_tensor*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:76: error: declaration of ‘b’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                                                       ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:48:26: note: shadowed declaration is here
   48 |     struct ggml_tensor * b = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:52: error: declaration of ‘a’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                               ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:47:26: note: shadowed declaration is here
   47 |     struct ggml_tensor * a = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h: In constructor ‘llama_adapter_lora_weight::llama_adapter_lora_weight(ggml_tensor*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:76: error: declaration of ‘b’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                                                       ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:48:26: note: shadowed declaration is here
   48 |     struct ggml_tensor * b = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:52: error: declaration of ‘a’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                               ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:47:26: note: shadowed declaration is here
   47 |     struct ggml_tensor * a = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h: In constructor ‘llama_adapter_lora_weight::llama_adapter_lora_weight(ggml_tensor*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:76: error: declaration of ‘b’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                                                       ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:48:26: note: shadowed declaration is here
   48 |     struct ggml_tensor * b = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:52: error: declaration of ‘a’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                               ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:47:26: note: shadowed declaration is here
   47 |     struct ggml_tensor * a = nullptr;
      |                          ^
In file included from /home/ggml/work/llama.cpp/src/llama-model.h:4,
                 from /home/ggml/work/llama.cpp/src/llama-adapter.cpp:5:
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
cc1plus: all warnings being treated as errors
make[2]: *** [src/CMakeFiles/llama.dir/build.make:90: src/CMakeFiles/llama.dir/llama-adapter.cpp.o] Error 1
In file included from /home/ggml/work/llama.cpp/src/llama-arch.cpp:1:
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.cpp: In constructor ‘LLM_KV::LLM_KV(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.cpp:1446:25: error: declaration of ‘arch’ shadows a member of ‘LLM_KV’ [-Werror=shadow]
 1446 | LLM_KV::LLM_KV(llm_arch arch) : arch(arch) {}
      |                ~~~~~~~~~^~~~
In file included from /home/ggml/work/llama.cpp/src/llama-arch.cpp:1:
/home/ggml/work/llama.cpp/src/llama-arch.h:340:14: note: shadowed declaration is here
  340 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.cpp: In constructor ‘LLM_KV::LLM_KV(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.cpp:1446:25: error: declaration of ‘arch’ shadows a member of ‘LLM_KV’ [-Werror=shadow]
 1446 | LLM_KV::LLM_KV(llm_arch arch) : arch(arch) {}
      |                ~~~~~~~~~^~~~
In file included from /home/ggml/work/llama.cpp/src/llama-arch.cpp:1:
/home/ggml/work/llama.cpp/src/llama-arch.h:340:14: note: shadowed declaration is here
  340 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.cpp: In constructor ‘LLM_KV::LLM_KV(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.cpp:1446:25: error: declaration of ‘arch’ shadows a member of ‘LLM_KV’ [-Werror=shadow]
 1446 | LLM_KV::LLM_KV(llm_arch arch) : arch(arch) {}
      |                ~~~~~~~~~^~~~
In file included from /home/ggml/work/llama.cpp/src/llama-arch.cpp:1:
/home/ggml/work/llama.cpp/src/llama-arch.h:340:14: note: shadowed declaration is here
  340 |     llm_arch arch;
      |              ^~~~
cc1plus: all warnings being treated as errors
make[2]: *** [src/CMakeFiles/llama.dir/build.make:104: src/CMakeFiles/llama.dir/llama-arch.cpp.o] Error 1
In file included from /home/ggml/work/llama.cpp/ggml/src/../include/ggml-cpu.h:4,
                 from /home/ggml/work/llama.cpp/src/../include/llama.h:5,
                 from /home/ggml/work/llama.cpp/src/llama-context.h:3,
                 from /home/ggml/work/llama.cpp/src/llama-context.cpp:1:
/home/ggml/work/llama.cpp/ggml/src/../include/ggml-backend.h:334:119: error: ‘ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t, ggml_cgraph*)’ hides constructor for ‘struct ggml_backend_graph_copy’ [-Werror=shadow]
  334 |     GGML_API struct ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t backend, struct ggml_cgraph * graph);
      |                                                                                                                       ^
In file included from /home/ggml/work/llama.cpp/src/llama-model.h:4,
                 from /home/ggml/work/llama.cpp/src/llama-context.h:6,
                 from /home/ggml/work/llama.cpp/src/llama-context.cpp:1:
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
In file included from /home/ggml/work/llama.cpp/src/llama-context.h:8,
                 from /home/ggml/work/llama.cpp/src/llama-context.cpp:1:
/home/ggml/work/llama.cpp/src/llama-adapter.h: In constructor ‘llama_adapter_lora_weight::llama_adapter_lora_weight(ggml_tensor*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:76: error: declaration of ‘b’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                                                       ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:48:26: note: shadowed declaration is here
   48 |     struct ggml_tensor * b = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:52: error: declaration of ‘a’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                               ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:47:26: note: shadowed declaration is here
   47 |     struct ggml_tensor * a = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h: In constructor ‘llama_adapter_lora_weight::llama_adapter_lora_weight(ggml_tensor*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:76: error: declaration of ‘b’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                                                       ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:48:26: note: shadowed declaration is here
   48 |     struct ggml_tensor * b = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:52: error: declaration of ‘a’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                               ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:47:26: note: shadowed declaration is here
   47 |     struct ggml_tensor * a = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h: In constructor ‘llama_adapter_lora_weight::llama_adapter_lora_weight(ggml_tensor*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:76: error: declaration of ‘b’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                                                       ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:48:26: note: shadowed declaration is here
   48 |     struct ggml_tensor * b = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:52: error: declaration of ‘a’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                               ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:47:26: note: shadowed declaration is here
   47 |     struct ggml_tensor * a = nullptr;
      |                          ^
In file included from /home/ggml/work/llama.cpp/src/llama-context.cpp:1:
/home/ggml/work/llama.cpp/src/llama-context.h: In constructor ‘llama_context::llama_context(const llama_model&)’:
/home/ggml/work/llama.cpp/src/llama-context.h:18:39: error: declaration of ‘model’ shadows a member of ‘llama_context’ [-Werror=shadow]
   18 |     llama_context(const llama_model & model)
      |                   ~~~~~~~~~~~~~~~~~~~~^~~~~
/home/ggml/work/llama.cpp/src/llama-context.h:23:32: note: shadowed declaration is here
   23 |     const struct llama_model & model;
      |                                ^~~~~
/home/ggml/work/llama.cpp/src/llama-context.h: In constructor ‘llama_context::llama_context(const llama_model&)’:
/home/ggml/work/llama.cpp/src/llama-context.h:18:39: error: declaration of ‘model’ shadows a member of ‘llama_context’ [-Werror=shadow]
   18 |     llama_context(const llama_model & model)
      |                   ~~~~~~~~~~~~~~~~~~~~^~~~~
/home/ggml/work/llama.cpp/src/llama-context.h:23:32: note: shadowed declaration is here
   23 |     const struct llama_model & model;
      |                                ^~~~~
/home/ggml/work/llama.cpp/src/llama-context.h: In constructor ‘llama_context::llama_context(const llama_model&)’:
/home/ggml/work/llama.cpp/src/llama-context.h:18:39: error: declaration of ‘model’ shadows a member of ‘llama_context’ [-Werror=shadow]
   18 |     llama_context(const llama_model & model)
      |                   ~~~~~~~~~~~~~~~~~~~~^~~~~
/home/ggml/work/llama.cpp/src/llama-context.h:23:32: note: shadowed declaration is here
   23 |     const struct llama_model & model;
      |                                ^~~~~
cc1plus: all warnings being treated as errors
make[2]: *** [src/CMakeFiles/llama.dir/build.make:146: src/CMakeFiles/llama.dir/llama-context.cpp.o] Error 1
In file included from /home/ggml/work/llama.cpp/ggml/src/../include/ggml-cpu.h:4,
                 from /home/ggml/work/llama.cpp/src/../include/llama.h:5,
                 from /home/ggml/work/llama.cpp/src/llama-grammar.h:3,
                 from /home/ggml/work/llama.cpp/src/llama-grammar.cpp:1:
/home/ggml/work/llama.cpp/ggml/src/../include/ggml-backend.h:334:119: error: ‘ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t, ggml_cgraph*)’ hides constructor for ‘struct ggml_backend_graph_copy’ [-Werror=shadow]
  334 |     GGML_API struct ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t backend, struct ggml_cgraph * graph);
      |                                                                                                                       ^
cc1plus: all warnings being treated as errors
make[2]: *** [src/CMakeFiles/llama.dir/build.make:160: src/CMakeFiles/llama.dir/llama-grammar.cpp.o] Error 1
In file included from /home/ggml/work/llama.cpp/ggml/src/../include/ggml-cpu.h:4,
                 from /home/ggml/work/llama.cpp/src/../include/llama.h:5,
                 from /home/ggml/work/llama.cpp/src/llama-context.h:3,
                 from /home/ggml/work/llama.cpp/src/llama.cpp:5:
/home/ggml/work/llama.cpp/ggml/src/../include/ggml-backend.h:334:119: error: ‘ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t, ggml_cgraph*)’ hides constructor for ‘struct ggml_backend_graph_copy’ [-Werror=shadow]
  334 |     GGML_API struct ggml_backend_graph_copy ggml_backend_graph_copy(ggml_backend_t backend, struct ggml_cgraph * graph);
      |                                                                                                                       ^
In file included from /home/ggml/work/llama.cpp/src/llama-model.h:4,
                 from /home/ggml/work/llama.cpp/src/llama-context.h:6,
                 from /home/ggml/work/llama.cpp/src/llama.cpp:5:
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h: In constructor ‘LLM_TN::LLM_TN(llm_arch)’:
/home/ggml/work/llama.cpp/src/llama-arch.h:377:21: error: declaration of ‘arch’ shadows a member of ‘LLM_TN’ [-Werror=shadow]
  377 |     LLM_TN(llm_arch arch) : arch(arch) {}
      |            ~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama-arch.h:379:14: note: shadowed declaration is here
  379 |     llm_arch arch;
      |              ^~~~
In file included from /home/ggml/work/llama.cpp/src/llama-context.h:8,
                 from /home/ggml/work/llama.cpp/src/llama.cpp:5:
/home/ggml/work/llama.cpp/src/llama-adapter.h: In constructor ‘llama_adapter_lora_weight::llama_adapter_lora_weight(ggml_tensor*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:76: error: declaration of ‘b’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                                                       ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:48:26: note: shadowed declaration is here
   48 |     struct ggml_tensor * b = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:52: error: declaration of ‘a’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                               ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:47:26: note: shadowed declaration is here
   47 |     struct ggml_tensor * a = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h: In constructor ‘llama_adapter_lora_weight::llama_adapter_lora_weight(ggml_tensor*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:76: error: declaration of ‘b’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                                                       ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:48:26: note: shadowed declaration is here
   48 |     struct ggml_tensor * b = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:52: error: declaration of ‘a’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                               ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:47:26: note: shadowed declaration is here
   47 |     struct ggml_tensor * a = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h: In constructor ‘llama_adapter_lora_weight::llama_adapter_lora_weight(ggml_tensor*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:76: error: declaration of ‘b’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                                                       ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:48:26: note: shadowed declaration is here
   48 |     struct ggml_tensor * b = nullptr;
      |                          ^
/home/ggml/work/llama.cpp/src/llama-adapter.h:58:52: error: declaration of ‘a’ shadows a member of ‘llama_adapter_lora_weight’ [-Werror=shadow]
   58 |     llama_adapter_lora_weight(struct ggml_tensor * a, struct ggml_tensor * b) : a(a), b(b) {}
      |                               ~~~~~~~~~~~~~~~~~~~~~^
/home/ggml/work/llama.cpp/src/llama-adapter.h:47:26: note: shadowed declaration is here
   47 |     struct ggml_tensor * a = nullptr;
      |                          ^
In file included from /home/ggml/work/llama.cpp/src/llama.cpp:5:
/home/ggml/work/llama.cpp/src/llama-context.h: In constructor ‘llama_context::llama_context(const llama_model&)’:
/home/ggml/work/llama.cpp/src/llama-context.h:18:39: error: declaration of ‘model’ shadows a member of ‘llama_context’ [-Werror=shadow]
   18 |     llama_context(const llama_model & model)
      |                   ~~~~~~~~~~~~~~~~~~~~^~~~~
/home/ggml/work/llama.cpp/src/llama-context.h:23:32: note: shadowed declaration is here
   23 |     const struct llama_model & model;
      |                                ^~~~~
/home/ggml/work/llama.cpp/src/llama-context.h: In constructor ‘llama_context::llama_context(const llama_model&)’:
/home/ggml/work/llama.cpp/src/llama-context.h:18:39: error: declaration of ‘model’ shadows a member of ‘llama_context’ [-Werror=shadow]
   18 |     llama_context(const llama_model & model)
      |                   ~~~~~~~~~~~~~~~~~~~~^~~~~
/home/ggml/work/llama.cpp/src/llama-context.h:23:32: note: shadowed declaration is here
   23 |     const struct llama_model & model;
      |                                ^~~~~
/home/ggml/work/llama.cpp/src/llama-context.h: In constructor ‘llama_context::llama_context(const llama_model&)’:
/home/ggml/work/llama.cpp/src/llama-context.h:18:39: error: declaration of ‘model’ shadows a member of ‘llama_context’ [-Werror=shadow]
   18 |     llama_context(const llama_model & model)
      |                   ~~~~~~~~~~~~~~~~~~~~^~~~~
/home/ggml/work/llama.cpp/src/llama-context.h:23:32: note: shadowed declaration is here
   23 |     const struct llama_model & model;
      |                                ^~~~~
In file included from /home/ggml/work/llama.cpp/src/llama.cpp:9:
/home/ggml/work/llama.cpp/src/llama-model-loader.h: In constructor ‘llama_model_loader::llama_tensor_weight::llama_tensor_weight(const llama_file*, uint16_t, const gguf_context*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-model-loader.h:34:120: error: declaration of ‘tensor’ shadows a member of ‘llama_model_loader::llama_tensor_weight’ [-Werror=shadow]
   34 |         llama_tensor_weight(const llama_file * file, uint16_t idx, const struct gguf_context * gguf_ctx, ggml_tensor * tensor) : idx(idx), tensor(tensor) {
      |                                                                                                          ~~~~~~~~~~~~~~^~~~~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h:32:23: note: shadowed declaration is here
   32 |         ggml_tensor * tensor;
      |                       ^~~~~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h:34:63: error: declaration of ‘idx’ shadows a member of ‘llama_model_loader::llama_tensor_weight’ [-Werror=shadow]
   34 |         llama_tensor_weight(const llama_file * file, uint16_t idx, const struct gguf_context * gguf_ctx, ggml_tensor * tensor) : idx(idx), tensor(tensor) {
      |                                                      ~~~~~~~~~^~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h:29:19: note: shadowed declaration is here
   29 |         uint16_t  idx; // source file index
      |                   ^~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h: In constructor ‘llama_model_loader::llama_tensor_weight::llama_tensor_weight(const llama_file*, uint16_t, const gguf_context*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-model-loader.h:34:120: error: declaration of ‘tensor’ shadows a member of ‘llama_model_loader::llama_tensor_weight’ [-Werror=shadow]
   34 |         llama_tensor_weight(const llama_file * file, uint16_t idx, const struct gguf_context * gguf_ctx, ggml_tensor * tensor) : idx(idx), tensor(tensor) {
      |                                                                                                          ~~~~~~~~~~~~~~^~~~~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h:32:23: note: shadowed declaration is here
   32 |         ggml_tensor * tensor;
      |                       ^~~~~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h:34:63: error: declaration of ‘idx’ shadows a member of ‘llama_model_loader::llama_tensor_weight’ [-Werror=shadow]
   34 |         llama_tensor_weight(const llama_file * file, uint16_t idx, const struct gguf_context * gguf_ctx, ggml_tensor * tensor) : idx(idx), tensor(tensor) {
      |                                                      ~~~~~~~~~^~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h:29:19: note: shadowed declaration is here
   29 |         uint16_t  idx; // source file index
      |                   ^~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h: In constructor ‘llama_model_loader::llama_tensor_weight::llama_tensor_weight(const llama_file*, uint16_t, const gguf_context*, ggml_tensor*)’:
/home/ggml/work/llama.cpp/src/llama-model-loader.h:34:120: error: declaration of ‘tensor’ shadows a member of ‘llama_model_loader::llama_tensor_weight’ [-Werror=shadow]
   34 |         llama_tensor_weight(const llama_file * file, uint16_t idx, const struct gguf_context * gguf_ctx, ggml_tensor * tensor) : idx(idx), tensor(tensor) {
      |                                                                                                          ~~~~~~~~~~~~~~^~~~~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h:32:23: note: shadowed declaration is here
   32 |         ggml_tensor * tensor;
      |                       ^~~~~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h:34:63: error: declaration of ‘idx’ shadows a member of ‘llama_model_loader::llama_tensor_weight’ [-Werror=shadow]
   34 |         llama_tensor_weight(const llama_file * file, uint16_t idx, const struct gguf_context * gguf_ctx, ggml_tensor * tensor) : idx(idx), tensor(tensor) {
      |                                                      ~~~~~~~~~^~~
/home/ggml/work/llama.cpp/src/llama-model-loader.h:29:19: note: shadowed declaration is here
   29 |         uint16_t  idx; // source file index
      |                   ^~~
/home/ggml/work/llama.cpp/src/llama.cpp: In constructor ‘llm_build_context::llm_build_context(llama_context&, const llama_ubatch&, const llm_build_cb&, bool)’:
/home/ggml/work/llama.cpp/src/llama.cpp:1094:26: error: declaration of ‘cb’ shadows a member of ‘llm_build_context’ [-Werror=shadow]
 1094 |     const llm_build_cb & cb,
      |     ~~~~~~~~~~~~~~~~~~~~~^~
/home/ggml/work/llama.cpp/src/llama.cpp:1084:26: note: shadowed declaration is here
 1084 |     const llm_build_cb & cb;
      |                          ^~
/home/ggml/work/llama.cpp/src/llama.cpp:1093:26: error: declaration of ‘ubatch’ shadows a member of ‘llm_build_context’ [-Werror=shadow]
 1093 |     const llama_ubatch & ubatch,
      |     ~~~~~~~~~~~~~~~~~~~~~^~~~~~
/home/ggml/work/llama.cpp/src/llama.cpp:1047:28: note: shadowed declaration is here
 1047 |     const llama_ubatch   & ubatch;
      |                            ^~~~~~
/home/ggml/work/llama.cpp/src/llama.cpp:1092:26: error: declaration of ‘lctx’ shadows a member of ‘llm_build_context’ [-Werror=shadow]
 1092 |         llama_context  & lctx,
      |         ~~~~~~~~~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama.cpp:1044:28: note: shadowed declaration is here
 1044 |           llama_context  & lctx;
      |                            ^~~~
/home/ggml/work/llama.cpp/src/llama.cpp: In constructor ‘llm_build_context::llm_build_context(llama_context&, const llama_ubatch&, const llm_build_cb&, bool)’:
/home/ggml/work/llama.cpp/src/llama.cpp:1094:26: error: declaration of ‘cb’ shadows a member of ‘llm_build_context’ [-Werror=shadow]
 1094 |     const llm_build_cb & cb,
      |     ~~~~~~~~~~~~~~~~~~~~~^~
/home/ggml/work/llama.cpp/src/llama.cpp:1084:26: note: shadowed declaration is here
 1084 |     const llm_build_cb & cb;
      |                          ^~
/home/ggml/work/llama.cpp/src/llama.cpp:1093:26: error: declaration of ‘ubatch’ shadows a member of ‘llm_build_context’ [-Werror=shadow]
 1093 |     const llama_ubatch & ubatch,
      |     ~~~~~~~~~~~~~~~~~~~~~^~~~~~
/home/ggml/work/llama.cpp/src/llama.cpp:1047:28: note: shadowed declaration is here
 1047 |     const llama_ubatch   & ubatch;
      |                            ^~~~~~
/home/ggml/work/llama.cpp/src/llama.cpp:1092:26: error: declaration of ‘lctx’ shadows a member of ‘llm_build_context’ [-Werror=shadow]
 1092 |         llama_context  & lctx,
      |         ~~~~~~~~~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama.cpp:1044:28: note: shadowed declaration is here
 1044 |           llama_context  & lctx;
      |                            ^~~~
/home/ggml/work/llama.cpp/src/llama.cpp: In constructor ‘llm_build_context::llm_build_context(llama_context&, const llama_ubatch&, const llm_build_cb&, bool)’:
/home/ggml/work/llama.cpp/src/llama.cpp:1094:26: error: declaration of ‘cb’ shadows a member of ‘llm_build_context’ [-Werror=shadow]
 1094 |     const llm_build_cb & cb,
      |     ~~~~~~~~~~~~~~~~~~~~~^~
/home/ggml/work/llama.cpp/src/llama.cpp:1084:26: note: shadowed declaration is here
 1084 |     const llm_build_cb & cb;
      |                          ^~
/home/ggml/work/llama.cpp/src/llama.cpp:1093:26: error: declaration of ‘ubatch’ shadows a member of ‘llm_build_context’ [-Werror=shadow]
 1093 |     const llama_ubatch & ubatch,
      |     ~~~~~~~~~~~~~~~~~~~~~^~~~~~
/home/ggml/work/llama.cpp/src/llama.cpp:1047:28: note: shadowed declaration is here
 1047 |     const llama_ubatch   & ubatch;
      |                            ^~~~~~
/home/ggml/work/llama.cpp/src/llama.cpp:1092:26: error: declaration of ‘lctx’ shadows a member of ‘llm_build_context’ [-Werror=shadow]
 1092 |         llama_context  & lctx,
      |         ~~~~~~~~~~~~~~~~~^~~~
/home/ggml/work/llama.cpp/src/llama.cpp:1044:28: note: shadowed declaration is here
 1044 |           llama_context  & lctx;
      |                            ^~~~
cc1plus: all warnings being treated as errors
make[2]: *** [src/CMakeFiles/llama.dir/build.make:76: src/CMakeFiles/llama.dir/llama.cpp.o] Error 1
make[1]: *** [CMakeFiles/Makefile2:1767: src/CMakeFiles/llama.dir/all] Error 2
make: *** [Makefile:146: all] Error 2

real	0m2.530s
user	0m9.945s
sys	0m1.036s
+ cur=2
+ echo 2
+ set +x
cat: /home/ggml/results/llama.cpp/9a/735ae6d84b4bf76a8444d72fabef8ad353abcf/ggml-2-x86-cpu/ctest_debug-ctest.log: No such file or directory
