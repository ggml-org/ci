rm: /Users/ggml/results/llama.cpp/75/c14f26086e8b0cf465845eae20d002a92495db/ggml-100-m1/*.log: No such file or directory
rm: /Users/ggml/results/llama.cpp/75/c14f26086e8b0cf465845eae20d002a92495db/ggml-100-m1/*.exit: No such file or directory
rm: /Users/ggml/results/llama.cpp/75/c14f26086e8b0cf465845eae20d002a92495db/ggml-100-m1/*.md: No such file or directory
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: numpy~=1.24.4 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 1)) (1.24.4)
Requirement already satisfied: sentencepiece~=0.1.98 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 2)) (0.1.98)
Requirement already satisfied: transformers<5.0.0,>=4.35.2 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.36.2)
Requirement already satisfied: gguf>=0.1.0 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 4)) (0.4.5)
Requirement already satisfied: protobuf<5.0.0,>=4.21.0 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 5)) (4.25.1)
Requirement already satisfied: torch~=2.1.1 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from -r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.2)
Requirement already satisfied: requests in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.31.0)
Requirement already satisfied: pyyaml>=5.1 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (6.0.1)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.15.0)
Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.19.4)
Requirement already satisfied: safetensors>=0.3.1 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.4.1)
Requirement already satisfied: filelock in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.12.4)
Requirement already satisfied: tqdm>=4.27 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.66.1)
Requirement already satisfied: regex!=2019.12.17 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.10.3)
Requirement already satisfied: packaging>=20.0 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (23.2)
Requirement already satisfied: typing-extensions in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (4.8.0)
Requirement already satisfied: networkx in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1)
Requirement already satisfied: sympy in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.12)
Requirement already satisfied: jinja2 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1.2)
Requirement already satisfied: fsspec in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2023.9.2)
Requirement already satisfied: MarkupSafe>=2.0 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from jinja2->torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.3)
Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.3.0)
Requirement already satisfied: idna<4,>=2.5 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.0.6)
Requirement already satisfied: certifi>=2017.4.17 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from requests->transformers<5.0.0,>=4.35.2->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.7.22)
Requirement already satisfied: mpmath>=0.19 in /Users/ggml/Library/Python/3.9/lib/python/site-packages (from sympy->torch~=2.1.1->-r /Users/ggml/work/llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.3.0)
WARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.
Defaulting to user installation because normal site-packages is not writeable
ERROR: File "setup.py" or "setup.cfg" not found. Directory cannot be installed in editable mode: /Users/ggml/work/llama.cpp/gguf-py
(A "pyproject.toml" file was found, but editable mode currently requires a setuptools-based build.)
WARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.
+ gg_run_ctest_debug
+ cd /Users/ggml/work/llama.cpp
+ tee /Users/ggml/results/llama.cpp/75/c14f26086e8b0cf465845eae20d002a92495db/ggml-100-m1/ctest_debug.log
+ rm -rf build-ci-debug
+ mkdir build-ci-debug
+ cd build-ci-debug
+ set -e
+ tee -a /Users/ggml/results/llama.cpp/75/c14f26086e8b0cf465845eae20d002a92495db/ggml-100-m1/ctest_debug-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=Debug -DLLAMA_METAL_NO_FAST_MATH=ON ..
-- The C compiler identification is AppleClang 14.0.3.14030022
-- The CXX compiler identification is AppleClang 14.0.3.14030022
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.39.2 (Apple Git-143)") 
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- Accelerate framework found
-- Metal framework found
-- CMAKE_SYSTEM_PROCESSOR: arm64
-- ARM detected
-- Performing Test COMPILER_SUPPORTS_FP16_FORMAT_I3E
-- Performing Test COMPILER_SUPPORTS_FP16_FORMAT_I3E - Failed
-- Configuring done (0.6s)
-- Generating done (0.1s)
-- Build files have been written to: /Users/ggml/work/llama.cpp/build-ci-debug

real	0m0.760s
user	0m0.340s
sys	0m0.353s
+ tee -a /Users/ggml/results/llama.cpp/75/c14f26086e8b0cf465845eae20d002a92495db/ggml-100-m1/ctest_debug-make.log
+ make -j
[  1%] Generating build details from Git
[  2%] Building C object CMakeFiles/ggml.dir/ggml-alloc.c.o
[  3%] Building C object CMakeFiles/ggml.dir/ggml-backend.c.o
[  4%] Compiling Metal kernels
[  5%] Building C object CMakeFiles/ggml.dir/ggml-metal.m.o
[  6%] Building C object CMakeFiles/ggml.dir/ggml-quants.c.o
[  7%] Building C object CMakeFiles/ggml.dir/ggml.c.o
xcrun: error: unable to find utility "metal", not a developer tool or in PATH
make[2]: *** [bin/ggml.metallib] Error 72
make[1]: *** [CMakeFiles/ggml-metal.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
-- Found Git: /usr/bin/git (found version "2.39.2 (Apple Git-143)") 
[  8%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
[  8%] Built target build_info
/Users/ggml/work/llama.cpp/ggml.c:9670:17: warning: 'cblas_sgemm' is only available on macOS 13.3 or newer [-Wunguarded-availability-new]
                cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasTrans,
                ^~~~~~~~~~~
/Library/Developer/CommandLineTools/SDKs/MacOSX13.3.sdk/System/Library/Frameworks/vecLib.framework/Headers/cblas_new.h:891:6: note: 'cblas_sgemm' has been marked as being introduced in macOS 13.3 here, but the deployment target is macOS 13.0.0
void cblas_sgemm(const enum CBLAS_ORDER ORDER,
     ^
/Users/ggml/work/llama.cpp/ggml.c:9670:17: note: enclose 'cblas_sgemm' in a __builtin_available check to silence this warning
                cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasTrans,
                ^~~~~~~~~~~
/Users/ggml/work/llama.cpp/ggml.c:10080:9: warning: 'cblas_sgemm' is only available on macOS 13.3 or newer [-Wunguarded-availability-new]
        cblas_sgemm(CblasRowMajor, transposeA, CblasNoTrans, m, n, k, 1.0, a, lda, b, n, 0.0, c, n);
        ^~~~~~~~~~~
/Library/Developer/CommandLineTools/SDKs/MacOSX13.3.sdk/System/Library/Frameworks/vecLib.framework/Headers/cblas_new.h:891:6: note: 'cblas_sgemm' has been marked as being introduced in macOS 13.3 here, but the deployment target is macOS 13.0.0
void cblas_sgemm(const enum CBLAS_ORDER ORDER,
     ^
/Users/ggml/work/llama.cpp/ggml.c:10080:9: note: enclose 'cblas_sgemm' in a __builtin_available check to silence this warning
        cblas_sgemm(CblasRowMajor, transposeA, CblasNoTrans, m, n, k, 1.0, a, lda, b, n, 0.0, c, n);
        ^~~~~~~~~~~
2 warnings generated.
[  8%] Built target ggml
make: *** [all] Error 2
+ cur=2
+ echo 2
+ set +x
cat: /Users/ggml/results/llama.cpp/75/c14f26086e8b0cf465845eae20d002a92495db/ggml-100-m1/ctest_debug-ctest.log: No such file or directory
