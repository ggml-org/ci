+ ctest --output-on-failure -L main -E test-opt
Test project /home/ggml/work/llama.cpp/build-ci-debug
      Start  1: test-tokenizer-0-bert-bge
 1/28 Test  #1: test-tokenizer-0-bert-bge .........   Passed    0.73 sec
      Start  2: test-tokenizer-0-command-r
 2/28 Test  #2: test-tokenizer-0-command-r ........   Passed    3.90 sec
      Start  3: test-tokenizer-0-deepseek-coder
 3/28 Test  #3: test-tokenizer-0-deepseek-coder ...   Passed    0.96 sec
      Start  4: test-tokenizer-0-deepseek-llm
 4/28 Test  #4: test-tokenizer-0-deepseek-llm .....   Passed    1.80 sec
      Start  5: test-tokenizer-0-falcon
 5/28 Test  #5: test-tokenizer-0-falcon ...........   Passed    1.33 sec
      Start  6: test-tokenizer-0-gpt-2
 6/28 Test  #6: test-tokenizer-0-gpt-2 ............   Passed    1.12 sec
      Start  7: test-tokenizer-0-llama-bpe
 7/28 Test  #7: test-tokenizer-0-llama-bpe ........   Passed    2.94 sec
      Start  8: test-tokenizer-0-llama-spm
 8/28 Test  #8: test-tokenizer-0-llama-spm ........   Passed    0.74 sec
      Start  9: test-tokenizer-0-mpt
 9/28 Test  #9: test-tokenizer-0-mpt ..............   Passed    1.14 sec
      Start 10: test-tokenizer-0-phi-3
10/28 Test #10: test-tokenizer-0-phi-3 ............   Passed    0.73 sec
      Start 11: test-tokenizer-0-qwen2
11/28 Test #11: test-tokenizer-0-qwen2 ............   Passed    2.56 sec
      Start 12: test-tokenizer-0-refact
12/28 Test #12: test-tokenizer-0-refact ...........   Passed    1.13 sec
      Start 13: test-tokenizer-0-starcoder
13/28 Test #13: test-tokenizer-0-starcoder ........   Passed    1.12 sec
      Start 14: test-sampling
14/28 Test #14: test-sampling .....................   Passed    8.22 sec
      Start 15: test-grammar-parser
15/28 Test #15: test-grammar-parser ...............   Passed    0.05 sec
      Start 16: test-grammar-integration
16/28 Test #16: test-grammar-integration ..........   Passed    0.08 sec
      Start 17: test-llama-grammar
17/28 Test #17: test-llama-grammar ................   Passed    0.05 sec
      Start 18: test-json-schema-to-grammar
18/28 Test #18: test-json-schema-to-grammar .......   Passed    5.97 sec
      Start 19: test-tokenizer-1-llama-spm
19/28 Test #19: test-tokenizer-1-llama-spm ........   Passed    2.63 sec
      Start 20: test-log
20/28 Test #20: test-log ..........................   Passed    0.03 sec
      Start 21: test-arg-parser
21/28 Test #21: test-arg-parser ...................   Passed    0.37 sec
      Start 22: test-chat-template
22/28 Test #22: test-chat-template ................   Passed    0.05 sec
      Start 23: test-gguf
23/28 Test #23: test-gguf .........................***Failed    1.15 sec
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Tesla V100-PCIE-16GB, compute capability 7.0, VMM: yes
register_backend: registered backend CUDA (1 devices)
register_device: registered device CUDA0 (Tesla V100-PCIE-16GB)
register_backend: registered backend CPU (1 devices)
register_device: registered device CPU (Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz)

gguf_init_from_file_impl: invalid magic characters: 'FUGG', expected 'GGUF'
gguf_init_from_file_impl: GGUFv1 is no longer supported, please use a more up-to-date version
gguf_init_from_file_impl: failed to read header
gguf_init_from_file_impl: this GGUF file is version 4 but this software only supports up to version 3
gguf_init_from_file_impl: failed to read header
gguf_init_from_file_impl: number of key value pairs is -1 but must be in [0, 209622091746699450]
gguf_init_from_file_impl: failed to read header
gguf_init_from_file_impl: number of tensors is -1 but must be in [0, 53624256028225440]
gguf_init_from_file_impl: failed to read header
gguf_init_from_file_impl: encountered length_error while reading key 0
gguf_init_from_file_impl: failed to read key-value pairs
gguf_init_from_file_impl: key 'my_key_0' has invalid GGUF type 13
gguf_init_from_file_impl: failed to read key-value pairs
gguf_init_from_file_impl: duplicate key 'my_key_0' for tensors 0 and 1 
gguf_init_from_file_impl: failed to read key-value pairs
gguf_init_from_file_impl: alignment 13 is not a power of 2
gguf_init_from_file_impl: tensor name 0 is too long: 87 >= 64
gguf_init_from_file_impl: failed to read tensor info
gguf_init_from_file_impl: tensor 'my_tensor_0' has invalid number of dimensions: 5 > 4
gguf_init_from_file_impl: failed to read tensor info
gguf_init_from_file_impl: tensor 'my_tensor_0' dimension 0 has invalid number of elements: -1 < 0
gguf_init_from_file_impl: failed to read tensor info
gguf_init_from_file_impl: total number of elements in tensor 'my_tensor_0' with shape (8589934588, 8589934588, 1, 1) is >= 9223372036854775807
gguf_init_from_file_impl: failed to read tensor info
gguf_init_from_file_impl: tensor 'my_tensor_0' has invalid ggml type 39 (NONE)
gguf_init_from_file_impl: failed to read tensor info
gguf_init_from_file_impl: tensor 'my_tensor_0' has offset 18446744073709551615, expected 0
gguf_init_from_file_impl: failed to read tensor data
gguf_init_from_file_impl: duplicate tensor name 'my_tensor' for tensors 0 and 1
gguf_init_from_file_impl: failed to read tensor info
gguf_init_from_file_impl: alignment 13 is not a power of 2
gguf_init_from_file_impl: tensor 'my_tensor_1' has offset 8, expected 32
gguf_init_from_file_impl: failed to read tensor data
gguf_init_from_file_impl: failed to read tensor data binary blob
gguf_init_from_file_impl: alignment 13 is not a power of 2
gguf_init_from_file_impl: tensor 'my_tensor_1' has offset 8, expected 32
gguf_init_from_file_impl: failed to read tensor data
test_handcrafted_file: handcrafted_file_type=HEADER_BAD_MAGIC
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=HEADER_BAD_VERSION_1
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=HEADER_BAD_VERSION_FUTURE
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=HEADER_BAD_N_KV
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=HEADER_BAD_N_TENSORS
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=HEADER_EMPTY
test_handcrafted_file:   - context_not_null: [1;32mOK[0m
test_handcrafted_file:   - check_header: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=KV_BAD_KEY_SIZE
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=KV_BAD_TYPE
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=KV_DUPLICATE_KEY
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=KV_BAD_ALIGN
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=KV_RANDOM_KV
test_handcrafted_file:   - context_not_null: [1;32mOK[0m
test_handcrafted_file:   - check_header: [1;32mOK[0m
test_handcrafted_file:   - check_kv: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_BAD_NAME_SIZE
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_BAD_N_DIMS
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_BAD_SHAPE
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_NE_TOO_BIG
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_BAD_TYPE
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_BAD_OFFSET
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_DUPLICATE_NAME
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_BAD_ALIGN
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_INCONSISTENT_ALIGN
test_handcrafted_file:   - context_null: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_SUCCESS
test_handcrafted_file:   - context_not_null: [1;32mOK[0m
test_handcrafted_file:   - check_header: [1;32mOK[0m
test_handcrafted_file:   - check_kv: [1;32mOK[0m
test_handcrafted_file:   - check_tensors: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=TENSORS_CUSTOM_ALIGN
test_handcrafted_file:   - context_not_null: [1;32mOK[0m
test_handcrafted_file:   - check_header: [1;32mOK[0m
test_handcrafted_file:   - check_kv: [1;32mOK[0m
test_handcrafted_file:   - check_tensors: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=DATA_NOT_ENOUGH_DATA
test_handcrafted_file:   - context_null: [1;32mOK[0m
test_handcrafted_file:   - no_dangling_ggml_context_pointer: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=DATA_BAD_ALIGN
test_handcrafted_file:   - context_null: [1;32mOK[0m
test_handcrafted_file:   - no_dangling_ggml_context_pointer: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=DATA_INCONSISTENT_ALIGN
test_handcrafted_file:   - context_null: [1;32mOK[0m
test_handcrafted_file:   - no_dangling_ggml_context_pointer: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=DATA_SUCCESS
test_handcrafted_file:   - context_not_null: [1;32mOK[0m
test_handcrafted_file:   - check_header: [1;32mOK[0m
test_handcrafted_file:   - check_kv: [1;32mOK[0m
test_handcrafted_file:   - check_tensors: [1;32mOK[0m
test_handcrafted_file:   - check_tensor_data: [1;32mOK[0m

test_handcrafted_file: handcrafted_file_type=DATA_CUSTOM_ALIGN
test_handcrafted_file:   - context_not_null: [1;32mOK[0m
test_handcrafted_file:   - check_header: [1;32mOK[0m
test_handcrafted_file:   - check_kv: [1;32mOK[0m
test_handcrafted_file:   - check_tensors: [1;32mOK[0m
test_handcrafted_file:   - check_tensor_data: [1;32mOK[0m

test_roundtrip: device=Tesla V100-PCIE-16GB, backend=CUDA0, only_meta=yes
test_roundtrip: same_version: [1;32mOK[0m
test_roundtrip: same_n_kv: [1;32mOK[0m
test_roundtrip: same_n_tensors: [1;32mOK[0m
test_roundtrip: all_orig_kv_in_read: [1;32mOK[0m
test_roundtrip: all_read_kv_in_orig: [1;32mOK[0m
test_roundtrip: all_orig_tensors_in_read: [1;32mOK[0m
test_roundtrip: all_read_tensors_in_orig: [1;32mOK[0m

test_roundtrip: device=Tesla V100-PCIE-16GB, backend=CUDA0, only_meta=no
test_roundtrip: same_version: [1;32mOK[0m
test_roundtrip: same_n_kv: [1;32mOK[0m
test_roundtrip: same_n_tensors: [1;32mOK[0m
test_roundtrip: all_orig_kv_in_read: [1;32mOK[0m
test_roundtrip: all_read_kv_in_orig: [1;32mOK[0m
test_roundtrip: all_orig_tensors_in_read: [1;32mOK[0m
test_roundtrip: all_read_tensors_in_orig: [1;32mOK[0m
test_roundtrip: same_tensor_data: [1;31mFAIL[0m

test_gguf_set_kv: device=Tesla V100-PCIE-16GB, backend=CUDA0
test_gguf_set_kv: same_n_kv: [1;32mOK[0m
test_gguf_set_kv: all_kv_0_in_1: [1;32mOK[0m
test_gguf_set_kv: all_kv_0_in_2: [1;32mOK[0m
test_gguf_set_kv: same_n_kv_after_double_copy: [1;32mOK[0m
test_gguf_set_kv: all_kv_1_in_0_after_double_copy: [1;32mOK[0m

test_roundtrip: device=Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz, backend=CPU, only_meta=yes
test_roundtrip: same_version: [1;32mOK[0m
test_roundtrip: same_n_kv: [1;32mOK[0m
test_roundtrip: same_n_tensors: [1;32mOK[0m
test_roundtrip: all_orig_kv_in_read: [1;32mOK[0m
test_roundtrip: all_read_kv_in_orig: [1;32mOK[0m
test_roundtrip: all_orig_tensors_in_read: [1;32mOK[0m
test_roundtrip: all_read_tensors_in_orig: [1;32mOK[0m

test_roundtrip: device=Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz, backend=CPU, only_meta=no
test_roundtrip: same_version: [1;32mOK[0m
test_roundtrip: same_n_kv: [1;32mOK[0m
test_roundtrip: same_n_tensors: [1;32mOK[0m
test_roundtrip: all_orig_kv_in_read: [1;32mOK[0m
test_roundtrip: all_read_kv_in_orig: [1;32mOK[0m
test_roundtrip: all_orig_tensors_in_read: [1;32mOK[0m
test_roundtrip: all_read_tensors_in_orig: [1;32mOK[0m
test_roundtrip: same_tensor_data: [1;31mFAIL[0m

test_gguf_set_kv: device=Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz, backend=CPU
test_gguf_set_kv: same_n_kv: [1;32mOK[0m
test_gguf_set_kv: all_kv_0_in_1: [1;32mOK[0m
test_gguf_set_kv: all_kv_0_in_2: [1;32mOK[0m
test_gguf_set_kv: same_n_kv_after_double_copy: [1;32mOK[0m
test_gguf_set_kv: all_kv_1_in_0_after_double_copy: [1;32mOK[0m

85/87 tests passed
[1;31mFAIL[0m

      Start 24: test-backend-ops
24/28 Test #24: test-backend-ops ..................   Passed  230.95 sec
      Start 27: test-barrier
25/28 Test #27: test-barrier ......................   Passed    2.66 sec
      Start 28: test-quantize-fns
26/28 Test #28: test-quantize-fns .................   Passed   35.82 sec
      Start 29: test-quantize-perf
27/28 Test #29: test-quantize-perf ................   Passed    0.37 sec
      Start 30: test-rope
28/28 Test #30: test-rope .........................   Passed    0.13 sec

96% tests passed, 1 tests failed out of 28

Label Time Summary:
main    = 308.73 sec*proc (28 tests)

Total Test time (real) = 308.74 sec

The following tests FAILED:
	 23 - test-gguf (Failed)
Errors while running CTest

real	5m8.779s
user	15m5.530s
sys	0m14.579s
