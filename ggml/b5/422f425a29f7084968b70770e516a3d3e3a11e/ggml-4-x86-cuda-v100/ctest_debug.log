+ cmake -DCMAKE_BUILD_TYPE=Debug -DGGML_CUBLAS=ON ..
CMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):
  Compatibility with CMake < 3.5 will be removed from a future version of
  CMake.

  Update the VERSION argument <min> value or use a ...<max> suffix to tell
  CMake that the project does not need compatibility with older versions.


-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1") 
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- CMAKE_SYSTEM_PROCESSOR: x86_64
GNU ld (GNU Binutils for Ubuntu) 2.38
-- x86 detected
-- Linux detected
-- Found CUDAToolkit: /usr/local/cuda-12.2/include (found version "12.2.140") 
-- cuBLAS found
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda-12.2/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- GGML CUDA sources found
-- GGML Configuring CUDA architectures 52;61;70
-- x86 detected
-- Linux detected
-- Configuring done (3.0s)
-- Generating done (0.1s)
-- Build files have been written to: /home/ggml/work/ggml/build-ci-debug

real	0m3.215s
user	0m2.421s
sys	0m0.792s
+ make -j
[  1%] Building C object src/CMakeFiles/ggml.dir/ggml.c.o
[  1%] Building CXX object examples/CMakeFiles/common.dir/common.cpp.o
[  2%] Building C object src/CMakeFiles/ggml.dir/ggml-alloc.c.o
[  2%] Building C object src/CMakeFiles/ggml.dir/ggml-backend.c.o
[  3%] Building C object src/CMakeFiles/ggml.dir/ggml-quants.c.o
[  4%] Building CUDA object src/CMakeFiles/ggml.dir/ggml-cuda.cu.o
[  5%] Linking CXX static library libcommon.a
[  5%] Built target common
[  6%] Linking CUDA shared library libggml.so
[  6%] Built target ggml
[  7%] Building C object tests/CMakeFiles/test-vec0.dir/test-vec0.c.o
[  8%] Building CXX object tests/CMakeFiles/test-opt.dir/test-opt.cpp.o
[  8%] Building CXX object tests/CMakeFiles/test-grad0.dir/test-grad0.cpp.o
[  8%] Building C object tests/CMakeFiles/test-vec1.dir/test-vec1.c.o
[  9%] Building C object tests/CMakeFiles/test-mul-mat0.dir/test-mul-mat0.c.o
[ 10%] Building CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o
[ 11%] Building CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o
[ 12%] Building C object tests/CMakeFiles/test-mul-mat2.dir/test-mul-mat2.c.o
[ 13%] Building C object tests/CMakeFiles/test0.dir/test0.c.o
[ 14%] Building C object tests/CMakeFiles/test1.dir/test1.c.o
[ 15%] Linking C executable ../bin/test-vec0
[ 16%] Building C object tests/CMakeFiles/test2.dir/test2.c.o
[ 16%] Building C object tests/CMakeFiles/test3.dir/test3.c.o
[ 16%] Building C object tests/CMakeFiles/test-pool.dir/test-pool.c.o
[ 16%] Building C object tests/CMakeFiles/test-conv-transpose.dir/test-conv-transpose.c.o
[ 17%] Building C object tests/CMakeFiles/test-rel-pos.dir/test-rel-pos.c.o
[ 18%] Building C object tests/CMakeFiles/test-dup.dir/test-dup.c.o
[ 19%] Building C object tests/CMakeFiles/test-xpos.dir/test-xpos.c.o
[ 20%] Building C object tests/CMakeFiles/test-customop.dir/test-customop.c.o
[ 21%] Linking CXX executable ../bin/test-opt
[ 22%] Linking C executable ../bin/test0
[ 23%] Linking C executable ../bin/test2
[ 24%] Linking C executable ../bin/test3
[ 25%] Building CXX object tests/CMakeFiles/test-conv1d.dir/test-conv1d.cpp.o
[ 26%] Building CXX object tests/CMakeFiles/test-conv2d.dir/test-conv2d.cpp.o
[ 27%] Building CXX object tests/CMakeFiles/test-mul-mat.dir/test-mul-mat.cpp.o
[ 28%] Linking C executable ../bin/test-mul-mat0
[ 28%] Built target test-vec0
[ 29%] Building CXX object tests/CMakeFiles/test-backend-buffer.dir/test-backend-buffer.cpp.o
[ 30%] Linking C executable ../bin/test-pool
[ 31%] Building CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o
[ 32%] Linking C executable ../bin/test-conv-transpose
[ 33%] Linking C executable ../bin/test-rel-pos
[ 34%] Building CXX object examples/CMakeFiles/common-ggml.dir/common-ggml.cpp.o
[ 35%] Linking C executable ../bin/test-dup
[ 36%] Linking C executable ../bin/test1
[ 37%] Building CXX object examples/whisper/CMakeFiles/whisper-cpp.dir/whisper.cpp.o
[ 38%] Building CXX object examples/mnist/CMakeFiles/mnist.dir/main.cpp.o
[ 39%] Building CXX object examples/mnist/CMakeFiles/mnist-cnn.dir/main-cnn.cpp.o
[ 40%] Building CXX object examples/sam/CMakeFiles/sam.dir/main.cpp.o
[ 41%] Building CXX object examples/mnist/CMakeFiles/mnist-cpu.dir/main-cpu.cpp.o
[ 42%] Building CXX object examples/yolo/CMakeFiles/yolov3-tiny.dir/yolov3-tiny.cpp.o
[ 43%] Linking C executable ../bin/test-customop
[ 44%] Building CXX object examples/yolo/CMakeFiles/yolov3-tiny.dir/yolo-image.cpp.o
[ 45%] Linking C executable ../bin/test-xpos
[ 45%] Built target test3
[ 46%] Linking CXX executable ../bin/test-backend-buffer
[ 46%] Built target test0
[ 47%] Linking CXX executable ../bin/test-grad0
[ 47%] Built target test2
[ 47%] Built target test-opt
[ 47%] Built target test-mul-mat0
[ 47%] Built target test-conv-transpose
[ 47%] Built target test-dup
[ 47%] Built target test-pool
[ 47%] Built target test1
[ 47%] Built target test-rel-pos
[ 47%] Built target test-xpos
[ 47%] Built target test-customop
[ 47%] Built target test-backend-buffer
[ 47%] Built target test-grad0
[ 48%] Linking CXX executable ../bin/test-quantize-fns
[ 48%] Built target test-quantize-fns
[ 49%] Linking C executable ../bin/test-vec1
[ 49%] Built target test-vec1
/home/ggml/work/ggml/tests/test-mul-mat.cpp:24:13: warning: ‘void ggml_log_callback_default(ggml_log_level, const char*, void*)’ defined but not used [-Wunused-function]
   24 | static void ggml_log_callback_default(ggml_log_level level, const char * text, void * user_data) {
      |             ^~~~~~~~~~~~~~~~~~~~~~~~~
[ 50%] Linking C executable ../bin/test-mul-mat2
[ 50%] Built target test-mul-mat2
/home/ggml/work/ggml/tests/test-conv1d.cpp:24:13: warning: ‘void ggml_log_callback_default(ggml_log_level, const char*, void*)’ defined but not used [-Wunused-function]
   24 | static void ggml_log_callback_default(ggml_log_level level, const char * text, void * user_data) {
      |             ^~~~~~~~~~~~~~~~~~~~~~~~~
/home/ggml/work/ggml/tests/test-conv2d.cpp:24:13: warning: ‘void ggml_log_callback_default(ggml_log_level, const char*, void*)’ defined but not used [-Wunused-function]
   24 | static void ggml_log_callback_default(ggml_log_level level, const char * text, void * user_data) {
      |             ^~~~~~~~~~~~~~~~~~~~~~~~~
[ 51%] Linking CXX executable ../bin/test-mul-mat
[ 52%] Linking CXX executable ../../bin/mnist-cpu
[ 52%] Built target mnist-cpu
[ 53%] Linking CXX executable ../bin/test-conv1d
[ 54%] Linking CXX executable ../bin/test-conv2d
[ 54%] Built target test-mul-mat
[ 54%] Built target test-conv1d
[ 54%] Built target test-conv2d
[ 55%] Linking CXX executable ../../bin/mnist-cnn
[ 56%] Linking CXX executable ../bin/test-quantize-perf
[ 57%] Linking CXX executable ../../bin/mnist
[ 57%] Built target mnist-cnn
[ 57%] Built target mnist
[ 57%] Built target test-quantize-perf
[ 58%] Linking CXX executable ../../bin/yolov3-tiny
[ 58%] Built target yolov3-tiny
[ 59%] Linking CXX executable ../bin/test-backend-ops
[ 59%] Built target test-backend-ops
[ 60%] Linking CXX executable ../../bin/sam
[ 60%] Built target sam
[ 61%] Linking CXX static library libcommon-ggml.a
[ 61%] Built target common-ggml
[ 62%] Building CXX object examples/gpt-2/CMakeFiles/gpt-2-ctx.dir/main-ctx.cpp.o
[ 63%] Building CXX object examples/gpt-2/CMakeFiles/gpt-2-alloc.dir/main-alloc.cpp.o
[ 64%] Building CXX object examples/gpt-2/CMakeFiles/gpt-2-backend.dir/main-backend.cpp.o
[ 65%] Building CXX object examples/gpt-2/CMakeFiles/gpt-2-backend2.dir/main.cpp.o
[ 66%] Building CXX object examples/gpt-2/CMakeFiles/gpt-2-quantize.dir/quantize.cpp.o
[ 66%] Building CXX object examples/gpt-2/CMakeFiles/gpt-2-batched.dir/main-batched.cpp.o
[ 67%] Building CXX object examples/gpt-j/CMakeFiles/gpt-j-quantize.dir/quantize.cpp.o
[ 68%] Building CXX object examples/gpt-j/CMakeFiles/gpt-j.dir/main.cpp.o
[ 69%] Building CXX object examples/whisper/CMakeFiles/whisper-quantize.dir/quantize.cpp.o
[ 69%] Building CXX object examples/gpt-neox/CMakeFiles/gpt-neox.dir/main.cpp.o
[ 70%] Building CXX object examples/gpt-neox/CMakeFiles/gpt-neox-quantize.dir/quantize.cpp.o
[ 71%] Building CXX object examples/dolly-v2/CMakeFiles/dollyv2.dir/main.cpp.o
[ 72%] Building CXX object examples/dolly-v2/CMakeFiles/dollyv2-quantize.dir/quantize.cpp.o
[ 73%] Building CXX object examples/replit/CMakeFiles/replit.dir/main.cpp.o
[ 74%] Building CXX object examples/replit/CMakeFiles/replit-quantize.dir/quantize.cpp.o
[ 74%] Building CXX object examples/mpt/CMakeFiles/mpt.dir/main.cpp.o
[ 74%] Building CXX object examples/starcoder/CMakeFiles/starcoder.dir/main.cpp.o
[ 75%] Building CXX object examples/mpt/CMakeFiles/mpt-quantize.dir/quantize.cpp.o
[ 76%] Building CXX object examples/starcoder/CMakeFiles/starcoder-mmap.dir/starcoder-mmap.cpp.o
[ 77%] Building CXX object examples/starcoder/CMakeFiles/starcoder-quantize.dir/quantize.cpp.o
[ 78%] Linking CXX executable ../../bin/mpt-quantize
[ 79%] Linking CXX executable ../../bin/gpt-2-quantize
[ 80%] Linking CXX executable ../../bin/replit-quantize
[ 81%] Linking CXX executable ../../bin/gpt-j-quantize
[ 81%] Built target mpt-quantize
[ 82%] Linking CXX executable ../../bin/dollyv2-quantize
[ 82%] Built target gpt-2-quantize
[ 83%] Linking CXX executable ../../bin/starcoder-quantize
[ 84%] Linking CXX executable ../../bin/gpt-2-ctx
[ 85%] Linking CXX executable ../../bin/gpt-neox-quantize
[ 85%] Built target gpt-j-quantize
[ 85%] Built target replit-quantize
[ 86%] Linking CXX executable ../../bin/gpt-j
[ 86%] Built target dollyv2-quantize
[ 87%] Linking CXX executable ../../bin/dollyv2
[ 88%] Linking CXX executable ../../bin/whisper-quantize
[ 89%] Linking CXX executable ../../bin/starcoder
[ 90%] Linking CXX executable ../../bin/gpt-neox
[ 90%] Built target starcoder-quantize
[ 91%] Linking CXX executable ../../bin/gpt-2-backend
[ 92%] Linking CXX executable ../../bin/gpt-2-alloc
[ 92%] Built target whisper-quantize
[ 92%] Built target gpt-neox-quantize
[ 93%] Linking CXX executable ../../bin/mpt
[ 94%] Linking CXX executable ../../bin/starcoder-mmap
[ 94%] Built target starcoder
[ 94%] Built target gpt-2-ctx
[ 94%] Built target gpt-j
[ 95%] Linking CXX executable ../../bin/gpt-2-batched
[ 95%] Built target gpt-neox
[ 95%] Built target dollyv2
[ 95%] Built target mpt
[ 96%] Linking CXX executable ../../bin/replit
[ 96%] Built target gpt-2-backend
[ 96%] Built target gpt-2-alloc
[ 97%] Linking CXX executable ../../bin/gpt-2-backend2
[ 97%] Built target starcoder-mmap
[ 97%] Built target gpt-2-batched
[ 97%] Built target replit
[ 97%] Built target gpt-2-backend2
[ 98%] Linking CXX static library libwhisper-cpp.a
[ 98%] Built target whisper-cpp
[ 99%] Building CXX object examples/whisper/CMakeFiles/whisper.dir/main.cpp.o
[100%] Linking CXX executable ../../bin/whisper
[100%] Built target whisper

real	0m41.440s
user	1m23.021s
sys	0m7.817s
+ ctest --output-on-failure -E test-opt
Test project /home/ggml/work/ggml/build-ci-debug
      Start  1: test-grad0
 1/20 Test  #1: test-grad0 .......................   Passed    6.71 sec
      Start  2: test-quantize-fns
 2/20 Test  #2: test-quantize-fns ................   Passed    0.57 sec
      Start  3: test-quantize-perf
 3/20 Test  #3: test-quantize-perf ...............   Passed    0.77 sec
      Start  4: test-mul-mat0
 4/20 Test  #4: test-mul-mat0 ....................   Passed    1.08 sec
      Start  5: test-mul-mat2
 5/20 Test  #5: test-mul-mat2 ....................   Passed    7.89 sec
      Start  6: test0
 6/20 Test  #6: test0 ............................   Passed    0.55 sec
      Start  7: test1
 7/20 Test  #7: test1 ............................   Passed    0.54 sec
      Start  8: test2
 8/20 Test  #8: test2 ............................   Passed    7.92 sec
      Start  9: test3
 9/20 Test  #9: test3 ............................   Passed    1.11 sec
      Start 10: test-pool
10/20 Test #10: test-pool ........................   Passed    0.55 sec
      Start 11: test-conv-transpose
11/20 Test #11: test-conv-transpose ..............   Passed    0.55 sec
      Start 12: test-dup
12/20 Test #12: test-dup .........................   Passed    0.53 sec
      Start 13: test-rel-pos
13/20 Test #13: test-rel-pos .....................   Passed    0.54 sec
      Start 14: test-customop
14/20 Test #14: test-customop ....................   Passed    0.53 sec
      Start 15: test-xpos
15/20 Test #15: test-xpos ........................   Passed    0.54 sec
      Start 16: test-conv1d
16/20 Test #16: test-conv1d ......................   Passed    0.57 sec
      Start 17: test-conv2d
17/20 Test #17: test-conv2d ......................   Passed    0.57 sec
      Start 18: test-mul-mat
18/20 Test #18: test-mul-mat .....................   Passed    0.55 sec
      Start 19: test-backend-buffer
19/20 Test #19: test-backend-buffer ..............   Passed    0.54 sec
      Start 20: test-backend-ops
20/20 Test #20: test-backend-ops .................Subprocess aborted***Exception:  35.92 sec
ggml_backend_register: registered backend CPU
ggml_backend_register: registered backend CUDA0
ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no
ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes
ggml_init_cublas: found 1 CUDA devices:
  Device 0: Tesla V100-PCIE-16GB, compute capability 7.0, VMM: yes
Testing 2 backends

Backend 1/2 (CPU)
  Backend name: CPU
  ABS(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  SGN(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  NEG(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  STEP(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  TANH(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  ELU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  RELU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GELU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GELU_QUICK(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  SILU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GET_ROWS(type=f32,n=1,m=8,r=2,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=i32,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=i32,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=i32,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=i32,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  REPEAT(type=i32,ne=[10,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  REPEAT(type=i16,ne=[10,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  DUP(type=f32,ne=[10,10,10,1]): [1;32mOK[0m
  DUP(type=f16,ne=[10,10,10,1]): [1;32mOK[0m
  DUP(type=i32,ne=[10,10,10,1]): [1;32mOK[0m
  DUP(type=i16,ne=[10,10,10,1]): [1;32mOK[0m
  DUP(type=i16,ne=[10,8,3,1],permute=[0,2,1,3]): [1;32mOK[0m
  DUP(type=i16,ne=[10,8,3,1],permute=[1,2,0,3]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=f32,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=f16,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q4_0,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q4_1,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q5_0,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q5_1,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q8_0,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q2_K,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q3_K,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q4_K,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q5_K,ne=[256,10,10,1]): [1;32mOK[0m
  CPY(type_src=f32,type_dst=q6_K,ne=[256,10,10,1]): [1;32mOK[0m
  CONT(type=f32,ne=[10,10,10,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,8,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,8,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,8,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1,1],nr=[32,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1,1],nr=[32,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1,1],nr=[32,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,320,320],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,320,320],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,320,320],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,1,2,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,1,2,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,1,2,2]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[1,2,2,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[1,2,2,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[1,2,2,2]): [1;32mOK[0m
  ADD(type=f32,ne=[16,10,10,10],nr=[2,2,2,2]): [1;32mOK[0m
  MUL(type=f32,ne=[16,10,10,10],nr=[2,2,2,2]): [1;32mOK[0m
  DIV(type=f32,ne=[16,10,10,10],nr=[2,2,2,2]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,1,1,1],nr=[1,16,16,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,1,1,1],nr=[1,16,16,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,1,1,1],nr=[1,16,16,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,16,16,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,16,16,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,16,16,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1280,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1280,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1280,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1280,1],nr=[16,16,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1280,1],nr=[16,16,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1280,1],nr=[16,16,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[16,16,1280,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[16,16,1280,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[16,16,1280,1],nr=[1,1,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1920,1],nr=[16,16,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1920,1],nr=[16,16,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1920,1],nr=[16,16,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,2560,1],nr=[16,16,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,2560,1],nr=[16,16,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,2560,1],nr=[16,16,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1280,1],nr=[32,32,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1280,1],nr=[32,32,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1280,1],nr=[32,32,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,1920,1],nr=[32,32,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,1920,1],nr=[32,32,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,1920,1],nr=[32,32,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[1,1,640,1],nr=[32,32,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[1,1,640,1],nr=[32,32,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[1,1,640,1],nr=[32,32,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[5120,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[5120,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[5120,1,1,1],nr=[1,256,1,1]): [1;32mOK[0m
  ADD(type=f32,ne=[640,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  MUL(type=f32,ne=[640,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  DIV(type=f32,ne=[640,1,1,1],nr=[1,1,1,1]): [1;32mOK[0m
  SCALE(type=f32,ne=[10,10,10,10],scale=2.000000): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.000001): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.000001): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.000010): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.000010): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.001000): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.001000): [1;32mOK[0m
  NORM(type=f32,ne=[64,10,10,10],eps=0.100000): [1;32mOK[0m
  RMS_NORM(type=f32,ne=[64,10,10,10],eps=0.100000): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f32,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=f16,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_1,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q8_0,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q2_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q3_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q4_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q5_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): [1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f32,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
ggml_cuda_compute_forward: cannot compute node_0: src0->ne[3] = 10, src1->ne[3] = 20 - fallback to CPU
[1;32mOK[0m
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=1,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[1,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,1],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,1]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[1,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT(type_a=q6_K,type_b=f16,m=16,n=16,k=256,bs=[10,10],nr=[2,2]): not supported [CPU] not supported [CPU] 
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f32,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=f16,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_1,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q8_0,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q2_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q3_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q4_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q5_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=2,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=4,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=0,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=1,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=2,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=3,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=4,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=5,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=6,m=16,n=16,k=256,v=1): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=0): [1;32mOK[0m
  MUL_MAT_ID(type_a=q6_K,type_b=f32,n_mats=8,id=7,m=16,n=16,k=256,v=1): [1;32mOK[0m
  SQR(type=f32,ne=[10,10,10,10]): [1;32mOK[0m
  CLAMP(type=f32,ne=[10,10,10,10],min=-0.500000,max=0.500000): [1;32mOK[0m
  DIAG_MASK_INF(type=f32,ne=[10,10,1,1],n_past=5): [1;32mOK[0m
  DIAG_MASK_INF(type=f32,ne=[10,10,10,1],n_past=5): [1;32mOK[0m
  DIAG_MASK_INF(type=f32,ne=[10,10,10,10],n_past=5): [1;32mOK[0m
  SOFT_MAX(type=f32,ne=[10,10,10,10]): [1;32mOK[0m
  ROPE(type=f32,ne=[128,32,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[128,40,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[128,52,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[128,64,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,1,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,71,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,8,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[64,128,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[80,32,10,1],n_dims=20,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f32,ne=[80,32,10,1],n_dims=32,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,32,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,40,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,52,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[128,64,10,1],n_dims=128,mode=0,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,1,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,71,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,8,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[64,128,10,1],n_dims=64,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[80,32,10,1],n_dims=20,mode=2,n_ctx=512): [1;32mOK[0m
  ROPE(type=f16,ne=[80,32,10,1],n_dims=32,mode=2,n_ctx=512): [1;32mOK[0m
  ALIBI(type=f32,ne=[10,10,10,10],n_past=512,n_head=10,bias_max=0.500000): [1;32mOK[0m
  IM2COL(type_input=f32,type_kernel=f16,ne_input=[10,10,3,1],ne_kernel=[3,3,3,1],s0=1,s1=1,p0=1,p1=1,d0=1,d1=1,is_2D=1): [1;32mOK[0m
  CONCAT(type=f32,ne=[10,10,10,10],b_ne2=10): [1;32mOK[0m
  CONCAT(type=i32,ne=[10,10,10,10],b_ne2=10): [1;32mOK[0m
  ARGSORT(type=f32,ne=[8,1,1,1],order=0): [1;32mOK[0m
  ARGSORT(type=f32,ne=[16,10,10,10],order=0): [1;32mOK[0m
  ARGSORT(type=f32,ne=[8,1,1,1],order=1): [1;32mOK[0m
  ARGSORT(type=f32,ne=[16,10,10,10],order=1): [1;32mOK[0m
  SUM_ROWS(type=f32,ne=[10,10,10,10]): [1;32mOK[0m
  UPSCALE(type=f32,ne=[512,512,3,1],scale_factor=2): [1;32mOK[0m
  GROUP_NORM(type=f32,ne=[64,64,320,1],num_groups=32): [1;32mOK[0m
  ACC(type=f32,ne_a=[1024,577,1,1],ne_b=[1024,576,1,1]): [1;32mOK[0m
  PAD(type=f32,ne_a=[512,512,1,1],pad_0=1,pad_1=1): [1;32mOK[0m
  LEAKY_RELU(type=f32,ne_a=[10,10,10,10],negative_slope=0.100000): [1;32mOK[0m
  MOE(n_experts=8,n_experts_per_tok=2,n_tokens=1,n_embd=4096,n_ff=8192): [1;32mOK[0m
  889/889 tests passed
  Backend CPU: [1;32mOK[0m

Backend 2/2 (CUDA0)
  Backend name: CUDA
  ABS(type=f32,ne=[128,10,10,10]): not supported [CUDA] 
  SGN(type=f32,ne=[128,10,10,10]): not supported [CUDA] 
  NEG(type=f32,ne=[128,10,10,10]): not supported [CUDA] 
  STEP(type=f32,ne=[128,10,10,10]): not supported [CUDA] 
  TANH(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  ELU(type=f32,ne=[128,10,10,10]): not supported [CUDA] 
  RELU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GELU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GELU_QUICK(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  SILU(type=f32,ne=[128,10,10,10]): [1;32mOK[0m
  GET_ROWS(type=f32,n=1,m=8,r=2,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=f32,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=f16,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q4_1,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q5_1,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=1,v=0): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=1,v=1): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=7,v=0): [1;32mOK[0m
  GET_ROWS(type=q8_0,n=256,m=5,r=4,b=7,v=1): [1;32mOK[0m
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=1,v=0): not supported [CUDA] 
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=1,v=1): not supported [CUDA] 
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=7,v=0): not supported [CUDA] 
  GET_ROWS(type=q2_K,n=256,m=5,r=4,b=7,v=1): not supported [CUDA] 
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=1,v=0): not supported [CUDA] 
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=1,v=1): not supported [CUDA] 
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=7,v=0): not supported [CUDA] 
  GET_ROWS(type=q3_K,n=256,m=5,r=4,b=7,v=1): not supported [CUDA] 
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=1,v=0): not supported [CUDA] 
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=1,v=1): not supported [CUDA] 
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=7,v=0): not supported [CUDA] 
  GET_ROWS(type=q4_K,n=256,m=5,r=4,b=7,v=1): not supported [CUDA] 
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=1,v=0): not supported [CUDA] 
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=1,v=1): not supported [CUDA] 
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=7,v=0): not supported [CUDA] 
  GET_ROWS(type=q5_K,n=256,m=5,r=4,b=7,v=1): not supported [CUDA] 
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=1,v=0): not supported [CUDA] 
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=1,v=1): not supported [CUDA] 
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=7,v=0): not supported [CUDA] 
  GET_ROWS(type=q6_K,n=256,m=5,r=4,b=7,v=1): not supported [CUDA] 
  GET_ROWS(type=i32,n=256,m=5,r=4,b=1,v=0): not supported [CUDA] 
  GET_ROWS(type=i32,n=256,m=5,r=4,b=1,v=1): not supported [CUDA] 
  GET_ROWS(type=i32,n=256,m=5,r=4,b=7,v=0): not supported [CUDA] 
  GET_ROWS(type=i32,n=256,m=5,r=4,b=7,v=1): not supported [CUDA] 
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[2,1,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,2,1,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,2,1]): [1;32mOK[0m
  REPEAT(type=f32,ne=[10,10,10,10],nr=[1,1,1,2]): [1;32mOK[0m
  REPEAT(type=i32,ne=[10,10,10,10],nr=[2,1,1,1]): GGML_ASSERT: /home/ggml/work/ggml/src/ggml-cuda.cu:7033: src1->type == GGML_TYPE_F32
Could not attach to process.  If your uid matches the uid of the target
process, check the setting of /proc/sys/kernel/yama/ptrace_scope, or try
again as the root user.  For more details, see /etc/sysctl.d/10-ptrace.conf
ptrace: Inappropriate ioctl for device.
No stack.
The program is not being run.


95% tests passed, 1 tests failed out of 20

Total Test time (real) =  68.55 sec

The following tests FAILED:
	 20 - test-backend-ops (Subprocess aborted)
Errors while running CTest

real	1m8.586s
user	2m20.402s
sys	0m27.006s
