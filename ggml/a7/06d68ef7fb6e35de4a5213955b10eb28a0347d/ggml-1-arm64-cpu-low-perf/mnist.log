OrderedDict([('fc1.weight', tensor([[ 0.0130,  0.0034, -0.0287,  ..., -0.0268, -0.0352, -0.0056],
        [-0.0134,  0.0077, -0.0028,  ...,  0.0356,  0.0143, -0.0107],
        [-0.0329,  0.0154, -0.0167,  ...,  0.0155,  0.0127, -0.0309],
        ...,
        [-0.0216, -0.0302,  0.0085,  ...,  0.0301,  0.0073,  0.0153],
        [ 0.0289,  0.0181,  0.0326,  ...,  0.0107, -0.0314, -0.0349],
        [ 0.0273,  0.0127,  0.0105,  ...,  0.0090, -0.0007,  0.0190]])), ('fc1.bias', tensor([ 1.9317e-01, -7.4255e-02,  8.3417e-02,  1.1681e-01,  7.5499e-03,
         8.7627e-02, -7.9260e-03,  6.8504e-02,  2.2217e-02,  9.7918e-02,
         1.5195e-01,  8.3765e-02,  1.4237e-02,  1.0847e-02,  9.6959e-02,
        -1.2500e-01,  4.2406e-02, -2.4611e-02,  5.9198e-03,  8.9767e-02,
         3.5963e-04,  1.1448e-01,  2.7162e-02,  9.8151e-02, -1.0574e-01,
        -4.7501e-02, -1.8855e-02,  1.4828e-01,  7.3383e-02, -5.0084e-02,
         1.1321e-02,  9.7192e-02,  6.6980e-02, -6.6790e-03, -7.4828e-03,
        -2.0603e-02, -1.7421e-03, -2.8327e-03,  4.6305e-02,  1.2651e-01,
         9.0978e-03,  1.5167e-02, -4.1175e-02, -1.0905e-02,  4.0514e-02,
         3.0814e-02,  1.5702e-01,  2.7832e-02,  5.8472e-02,  3.5972e-02,
         1.7916e-01, -4.3105e-02, -1.7082e-02, -5.2126e-03, -4.1784e-02,
         1.1404e-01, -5.0527e-02, -4.8803e-02,  1.0759e-01, -1.8853e-02,
         8.7972e-02,  3.3843e-02, -7.4491e-02,  5.6366e-03, -7.5576e-02,
        -5.8457e-02,  6.9509e-02, -3.1362e-02,  5.7510e-03,  1.0784e-01,
         6.0208e-02, -6.2943e-02, -3.7130e-02, -1.1367e-02, -4.8353e-02,
        -1.2652e-01,  5.3056e-02, -1.0053e-01, -5.5123e-02,  9.8219e-02,
        -1.2520e-02,  1.9294e-02,  1.1413e-02,  1.2417e-02,  9.6171e-02,
        -1.2128e-03, -7.8359e-03,  8.1921e-03,  1.9765e-02,  6.0942e-02,
         1.9182e-02, -2.1397e-01, -5.9098e-02,  6.7606e-02,  4.1798e-02,
        -1.0778e-01, -1.9013e-02, -7.3817e-02,  1.1149e-02, -4.3826e-02,
         4.3050e-02,  7.4291e-02, -7.3924e-02, -1.2008e-01,  4.2609e-02,
         2.8011e-02,  5.3789e-04, -3.5241e-02, -2.7747e-02,  2.6758e-01,
         7.2402e-02, -5.6779e-02,  3.6441e-02, -7.7990e-03, -7.0027e-02,
         1.8026e-02, -4.7864e-02,  9.2981e-03, -8.9104e-02,  1.3290e-02,
         9.3724e-02,  3.6516e-02,  7.8024e-02,  3.9051e-02,  6.6369e-02,
         9.3561e-02,  9.3315e-02, -1.2276e-02, -8.5847e-03,  2.6596e-02,
        -5.1777e-02, -5.5102e-02,  9.0947e-02,  7.4931e-02, -8.0890e-02,
        -9.3666e-02,  4.7153e-02,  1.6889e-01, -1.1111e-01, -3.2880e-02,
         1.3847e-01, -2.6739e-02,  7.0351e-02,  2.5748e-02, -3.6002e-03,
         2.4659e-03,  5.9467e-02, -4.8250e-02,  6.5768e-02,  1.0420e-01,
         6.1534e-02, -3.5487e-04,  1.5595e-01, -1.1216e-02,  7.8150e-02,
         1.8550e-03, -7.1334e-02, -2.9336e-04,  1.5430e-01, -6.3242e-02,
         9.8106e-02,  5.8418e-02,  1.6629e-01,  7.1821e-02,  4.8526e-02,
        -3.1961e-02,  3.0926e-02,  7.5814e-02, -6.5827e-02,  1.7851e-01,
         3.0468e-03,  8.6447e-02,  1.7473e-02, -9.4829e-02, -6.1466e-02,
        -6.3003e-02,  4.8369e-02,  9.5913e-02, -4.6304e-02,  7.1307e-02,
        -3.3903e-02,  1.5327e-01,  5.1545e-02,  3.7808e-02, -5.6322e-03,
         7.3130e-02,  8.5853e-02,  6.3011e-02,  4.0304e-02,  1.6091e-02,
        -2.7871e-02, -1.0020e-02,  8.4927e-02, -5.3667e-02, -1.6221e-02,
        -3.8087e-02,  4.8109e-02, -3.4104e-02,  7.7286e-02,  2.7389e-02,
        -7.0247e-02, -1.5941e-02,  2.6554e-02, -1.5721e-01,  6.4786e-02,
         7.0505e-02,  5.5438e-02, -1.0179e-01,  9.4973e-02,  6.6274e-02,
         1.3084e-03, -4.3031e-02, -5.4748e-02,  1.5126e-02, -1.0184e-01,
         9.9117e-02,  1.7919e-02, -1.6770e-01,  8.4542e-02,  1.0089e-02,
        -7.4221e-03,  1.4658e-02, -4.0602e-02, -4.5417e-02, -5.5099e-02,
         4.2408e-03,  8.3749e-02, -3.7903e-02,  6.5656e-02,  3.3746e-03,
         9.9799e-02,  1.2375e-01,  6.5785e-02, -1.1259e-02, -8.3755e-02,
         7.4011e-02,  4.7979e-02,  1.4373e-01,  1.8299e-02,  9.2427e-02,
         3.3909e-02,  5.9706e-02, -7.3059e-02, -2.7105e-02, -6.0949e-02,
         8.7469e-03,  8.2445e-02, -5.9749e-02,  5.3806e-02,  8.2410e-02,
         2.5894e-02,  2.4970e-02, -6.4516e-03, -2.5115e-02, -1.0195e-02,
         1.3246e-01,  9.7611e-02,  2.1784e-01, -5.2291e-02, -1.1350e-01,
        -6.8753e-02,  1.7376e-01,  8.1040e-03,  7.1944e-02,  5.2249e-02,
         5.7644e-03, -4.2879e-03, -3.8557e-02, -8.1798e-02, -7.5228e-02,
         1.9737e-02, -6.6011e-02,  8.0348e-02,  2.8754e-02, -6.0763e-03,
         9.2671e-02,  1.2203e-01, -9.7457e-03,  6.0036e-02,  6.0099e-02,
        -5.6023e-02, -3.4615e-02, -1.5133e-01,  1.0515e-01,  2.8275e-02,
        -1.6321e-02,  1.1701e-02, -4.7803e-02,  7.0108e-02,  7.9019e-02,
        -1.3242e-01, -9.1464e-02,  5.5436e-02,  9.7633e-03,  1.8069e-01,
        -3.8319e-02,  1.9952e-02,  1.4226e-01,  3.0626e-02,  4.6252e-02,
        -4.5848e-02,  5.6336e-02, -5.3623e-02,  1.8202e-01,  1.6366e-01,
         4.0488e-02,  2.1676e-01,  4.3886e-02, -1.1467e-02, -3.1695e-02,
        -5.4311e-02, -2.6617e-02,  1.3621e-01,  3.4700e-02,  2.8478e-01,
        -1.7229e-03,  5.8891e-02, -1.0146e-01, -1.7464e-01, -2.0803e-02,
         6.1669e-03,  1.2665e-01,  1.2941e-01,  1.0335e-01, -6.7001e-02,
        -5.7529e-03,  1.9951e-02,  5.9042e-02,  1.8523e-02,  3.6751e-02,
         9.0150e-02,  2.5625e-02, -3.9484e-02, -8.2280e-02,  2.8302e-02,
        -6.1950e-02, -6.7991e-02,  1.0584e-02, -5.6041e-02,  1.6504e-01,
         8.2254e-02, -5.9937e-02,  1.0087e-01,  1.8909e-02, -8.3000e-03,
         1.5011e-01, -2.9652e-02, -1.2037e-01, -4.3391e-02,  5.7723e-02,
        -1.4874e-01, -6.8135e-02,  1.9435e-01,  1.8232e-01,  1.2073e-01,
         1.7815e-01, -2.4839e-03, -5.3879e-02, -7.4915e-02,  1.8398e-02,
         3.4604e-02,  1.0305e-01, -5.7372e-02,  2.8880e-02,  1.3427e-02,
         7.3237e-02,  1.6446e-02, -7.2767e-02, -7.2457e-02,  2.3540e-02,
         9.8579e-03,  1.4812e-02,  4.8572e-02,  1.0986e-01, -2.1687e-02,
        -1.3674e-02,  3.0553e-02,  1.1311e-01, -7.7532e-02,  9.5242e-03,
         3.1989e-02,  1.3954e-01,  7.6355e-02, -8.3985e-02,  2.9510e-02,
         3.3249e-02,  3.0003e-02, -5.8277e-02,  6.4603e-02, -6.2552e-03,
        -7.6575e-02, -3.0844e-02,  2.0078e-02,  2.0452e-04, -4.5928e-02,
        -1.1960e-01, -2.4405e-02,  2.7843e-02,  6.3721e-02,  1.7469e-01,
        -4.3107e-02,  7.9162e-02,  2.3302e-02, -1.1298e-01, -5.8873e-04,
         9.8547e-03, -4.3217e-02, -7.5400e-03,  6.6855e-02, -7.1937e-02,
        -2.7345e-02, -1.3329e-05,  4.2499e-03,  1.1353e-01, -5.2075e-03,
         2.5824e-02, -2.1712e-02,  3.8229e-02,  2.3977e-02, -5.1870e-02,
        -8.2421e-02, -5.1141e-02,  1.6162e-01,  5.8406e-02,  2.5226e-02,
         1.5409e-02,  4.4830e-02,  2.3117e-02, -4.3385e-02, -1.0457e-02,
        -7.3958e-02,  3.2129e-02, -3.5418e-02, -7.2025e-03, -4.7776e-02,
        -7.8562e-02,  4.9909e-02,  1.0058e-01,  8.1659e-02,  3.9191e-02,
        -3.1025e-02, -2.1352e-02,  1.5456e-01, -6.6637e-02, -3.7400e-02,
         3.5746e-02,  6.2833e-02, -7.6059e-02, -5.5529e-02,  8.8754e-03,
        -1.0564e-01,  4.9764e-03,  5.3494e-02, -3.3878e-02, -2.8971e-02,
        -3.1976e-02,  7.2087e-02,  9.4409e-02,  1.7479e-02, -4.2583e-02,
        -4.0873e-02,  3.3767e-02,  2.3605e-01, -2.2578e-02,  1.3606e-01,
         7.8564e-02, -9.7805e-02,  1.7535e-01,  5.0798e-02,  5.2249e-02,
        -5.6300e-02, -4.8412e-02,  5.0029e-02, -9.9129e-03,  9.5412e-02,
        -2.4891e-02,  2.4017e-02,  6.6159e-02, -1.0241e-01, -5.3050e-03,
         8.1643e-02, -2.4088e-02,  1.6531e-01, -1.0297e-02,  1.1206e-01,
        -5.2723e-02,  5.7517e-02, -1.1523e-01,  7.8528e-02, -7.4035e-02,
        -2.4339e-02, -9.1259e-03, -8.7602e-02,  5.8612e-02, -1.1615e-01,
         1.3460e-03,  2.9106e-02, -4.0620e-02,  9.7568e-02,  8.5670e-02])), ('fc2.weight', tensor([[-0.0197, -0.0814, -0.3992,  ...,  0.2697,  0.0386, -0.5380],
        [-0.4174,  0.0572, -0.1331,  ..., -0.2564, -0.3926, -0.0514],
        [ 0.2142,  0.0905, -0.1375,  ..., -0.0562, -0.0810, -0.2633],
        ...,
        [-0.1198,  0.0820, -0.2549,  ..., -0.1121,  0.0577,  0.0070],
        [ 0.0348,  0.2938,  0.2289,  ...,  0.0492,  0.0734, -0.0034],
        [-0.2988, -0.1119,  0.0517,  ...,  0.3296,  0.0800,  0.0651]])), ('fc2.bias', tensor([-0.1008, -0.1179, -0.0558, -0.0626,  0.0385, -0.0222,  0.0188, -0.1296,
         0.1507,  0.0033]))])
Processing variable: fc1.weight with shape:  (500, 784)
Processing variable: fc1.bias with shape:  (500,)
Processing variable: fc2.weight with shape:  (10, 500)
Processing variable: fc2.bias with shape:  (10,)
Done. Output file: models/mnist/ggml-model-f32.bin

+ ./bin/mnist ./models/mnist/ggml-model-f32.bin ../examples/mnist/models/mnist/t10k-images.idx3-ubyte
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * * * * * _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * * _ _ * * _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * _ _ _ _ * * _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * _ _ _ * * _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * _ _ * * _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * * * * _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

mnist_model_load: loading model from './models/mnist/ggml-model-f32.bin'
mnist_model_load: ggml ctx size =   1.52 MB
main: loaded model in     4.01 ms
ggml_graph_dump_dot: dot -Tpng mnist.dot -o mnist.dot.png && open mnist.dot.png

magic            67676d6c
version                 1
leafs                   5
nodes                   6
eval             6144

TYPE   OP              NDIMS      NE0      NE1      NE2      NE3              NB0              NB1              NB2              NB3             DATA             NAME
f32    NONE                2 500 10 1 1                4             2000            20000            20000   0xffffab7aa8d0                       fc2_weight
f32    NONE                2 784 500 1 1                4             3136          1568000          1568000   0xffffab62b160                       fc1_weight
f32    NONE                1 784 1 1 1                4             3136             3136             3136   0xaaaafd3ffac0                            input
f32    NONE                1 500 1 1 1                4             2000             2000             2000   0xffffab7a9fb0                         fc1_bias
f32    NONE                1 10 1 1 1                4               40               40               40   0xffffab7af840                         fc2_bias

ARG    TYPE   OP              NDIMS      NE0      NE1      NE2      NE3              NB0              NB1              NB2              NB3   NTASKS             DATA             NAME
DST    f32    MUL_MAT             2 500 1 1 1                4             2000             2000             2000   0xaaaafd400850                           node_0
SRC    f32    NONE                2 784 500 1 1                4             3136          1568000          1568000   0xffffab62b160                       fc1_weight
SRC    f32    NONE                1 784 1 1 1                4             3136             3136             3136   0xaaaafd3ffac0                            input

DST    f32    ADD                 2 500 1 1 1                4             2000             2000             2000   0xaaaafd401170                           node_1
SRC    f32    MUL_MAT             2 500 1 1 1                4             2000             2000             2000   0xaaaafd400850                           node_0
SRC    f32    NONE                1 500 1 1 1                4             2000             2000             2000   0xffffab7a9fb0                         fc1_bias

DST    f32    UNARY               2 500 1 1 1                4             2000             2000             2000   0xaaaafd401a90                           node_2
SRC    f32    ADD                 2 500 1 1 1                4             2000             2000             2000   0xaaaafd401170                           node_1

DST    f32    MUL_MAT             2 10 1 1 1                4               40               40               40   0xaaaafd4023b0                           node_3
SRC    f32    NONE                2 500 10 1 1                4             2000            20000            20000   0xffffab7aa8d0                       fc2_weight
SRC    f32    UNARY               2 500 1 1 1                4             2000             2000             2000   0xaaaafd401a90                           node_2

DST    f32    ADD                 2 10 1 1 1                4               40               40               40   0xaaaafd402530                           node_4
SRC    f32    MUL_MAT             2 10 1 1 1                4               40               40               40   0xaaaafd4023b0                           node_3
SRC    f32    NONE                1 10 1 1 1                4               40               40               40   0xffffab7af840                         fc2_bias

DST    f32    SOFT_MAX            2 10 1 1 1                4               40               40               40   0xaaaafd4026b0                            probs
SRC    f32    ADD                 2 10 1 1 1                4               40               40               40   0xaaaafd402530       mnist_eval: exported compute graph to 'mnist.ggml'
                    node_4


main: predicted digit is 6

real	0m0.012s
user	0m0.006s
sys	0m0.003s
+ ./bin/mnist-cpu ./mnist.ggml ../examples/mnist/models/mnist/t10k-images.idx3-ubyte
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * * * * * _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * * _ _ * * _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * _ _ _ _ * * _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ * * _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * _ _ _ _ _ * _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * _ _ _ * * _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * _ _ * * _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ * * * * * _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ggml_graph_import: loaded leaf 0: '      fc2_weight',   2 dims,     20000 bytes
ggml_graph_import: loaded leaf 1: '      fc1_weight',   2 dims,   1568000 bytes
ggml_graph_import: loaded leaf 2: '           input',   1 dims,      3136 bytes
ggml_graph_import: loaded leaf 3: '        fc1_bias',   1 dims,      2000 bytes
ggml_graph_import: loaded leaf 4: '        fc2_bias',   1 dims,        40 bytes
ggml_graph_import: loaded node 0: '          node_0',   2 dims,      2000 bytes
ggml_graph_import: loaded node 1: '          node_1',   2 dims,      2000 bytes
ggml_graph_import: loaded node 2: '          node_2',   2 dims,      2000 bytes
ggml_graph_import: loaded node 3: '          node_3',   2 dims,        40 bytes
ggml_graph_import: loaded node 4: '          node_4',   2 dims,        40 bytes
ggml_graph_import: loaded node 5: '           probs',   2 dims,        40 bytes
main: predicted digit is 6

real	0m0.007s
user	0m0.004s
sys	0m0.003s
