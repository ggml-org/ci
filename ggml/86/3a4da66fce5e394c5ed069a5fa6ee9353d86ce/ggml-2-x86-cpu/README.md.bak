### ctest_debug

Runs ctest in debug mode
- status: 0
```
+ ctest --output-on-failure -E test-opt
Test project /home/ggml/work/ggml/build-ci-debug
      Start  1: test-quantize-fns
 1/19 Test  #1: test-quantize-fns ................   Passed   30.59 sec
      Start  2: test-quantize-perf
 2/19 Test  #2: test-quantize-perf ...............   Passed    0.62 sec
      Start  3: test-mul-mat0
 3/19 Test  #3: test-mul-mat0 ....................   Passed    0.56 sec
      Start  4: test-mul-mat2
 4/19 Test  #4: test-mul-mat2 ....................   Passed    6.58 sec
      Start  5: test0
 5/19 Test  #5: test0 ............................   Passed    0.00 sec
      Start  6: test-pool
 6/19 Test  #6: test-pool ........................   Passed    0.01 sec
      Start  7: test-arange
 7/19 Test  #7: test-arange ......................   Passed    0.01 sec
      Start  8: test-timestep_embedding
 8/19 Test  #8: test-timestep_embedding ..........   Passed    0.00 sec
      Start  9: test-pad-reflect-1d
 9/19 Test  #9: test-pad-reflect-1d ..............   Passed    0.00 sec
      Start 10: test-conv-transpose
10/19 Test #10: test-conv-transpose ..............   Passed    0.00 sec
      Start 11: test-conv-transpose-1d
11/19 Test #11: test-conv-transpose-1d ...........   Passed    0.02 sec
      Start 12: test-dup
12/19 Test #12: test-dup .........................   Passed    0.01 sec
      Start 13: test-rel-pos
13/19 Test #13: test-rel-pos .....................   Passed    0.00 sec
      Start 14: test-customop
14/19 Test #14: test-customop ....................   Passed    0.00 sec
      Start 15: test-conv1d
15/19 Test #15: test-conv1d ......................   Passed    0.00 sec
      Start 16: test-conv2d
16/19 Test #16: test-conv2d ......................   Passed    0.01 sec
      Start 17: test-mul-mat
17/19 Test #17: test-mul-mat .....................   Passed    0.01 sec
      Start 18: test-backend-ops
18/19 Test #18: test-backend-ops .................   Passed    0.01 sec
      Start 19: test-cont
19/19 Test #19: test-cont ........................   Passed    0.00 sec

100% tests passed, 0 tests failed out of 19

Total Test time (real) =  38.44 sec

real	0m38.507s
user	0m38.059s
sys	0m0.176s
```

### ctest_release

Runs ctest in release mode
- status: 0
```
+ ctest --output-on-failure
Test project /home/ggml/work/ggml/build-ci-release
      Start  1: test-opt
 1/20 Test  #1: test-opt .........................   Passed    0.01 sec
      Start  2: test-quantize-fns
 2/20 Test  #2: test-quantize-fns ................   Passed   16.82 sec
      Start  3: test-quantize-perf
 3/20 Test  #3: test-quantize-perf ...............   Passed    0.08 sec
      Start  4: test-mul-mat0
 4/20 Test  #4: test-mul-mat0 ....................   Passed    0.63 sec
      Start  5: test-mul-mat2
 5/20 Test  #5: test-mul-mat2 ....................   Passed    2.81 sec
      Start  6: test0
 6/20 Test  #6: test0 ............................   Passed    0.00 sec
      Start  7: test-pool
 7/20 Test  #7: test-pool ........................   Passed    0.00 sec
      Start  8: test-arange
 8/20 Test  #8: test-arange ......................   Passed    0.00 sec
      Start  9: test-timestep_embedding
 9/20 Test  #9: test-timestep_embedding ..........   Passed    0.00 sec
      Start 10: test-pad-reflect-1d
10/20 Test #10: test-pad-reflect-1d ..............   Passed    0.00 sec
      Start 11: test-conv-transpose
11/20 Test #11: test-conv-transpose ..............   Passed    0.00 sec
      Start 12: test-conv-transpose-1d
12/20 Test #12: test-conv-transpose-1d ...........   Passed    0.01 sec
      Start 13: test-dup
13/20 Test #13: test-dup .........................   Passed    0.00 sec
      Start 14: test-rel-pos
14/20 Test #14: test-rel-pos .....................   Passed    0.00 sec
      Start 15: test-customop
15/20 Test #15: test-customop ....................   Passed    0.00 sec
      Start 16: test-conv1d
16/20 Test #16: test-conv1d ......................   Passed    0.00 sec
      Start 17: test-conv2d
17/20 Test #17: test-conv2d ......................   Passed    0.00 sec
      Start 18: test-mul-mat
18/20 Test #18: test-mul-mat .....................   Passed    0.00 sec
      Start 19: test-backend-ops
19/20 Test #19: test-backend-ops .................   Passed    0.00 sec
      Start 20: test-cont
20/20 Test #20: test-cont ........................   Passed    0.00 sec

100% tests passed, 0 tests failed out of 20

Total Test time (real) =  20.40 sec

real	0m20.469s
user	0m19.904s
sys	0m0.175s
```
### gpt_2

Runs short GPT-2 text generation
- status: 0
```
+ ./bin/gpt-2-backend --model ../models-mnt/gpt-2/ggml-model-gpt-2-117M.bin -s 1234 -n 64 -tt ../examples/prompts/gpt-2.txt
gpt2_model_load: using CPU backend
test_gpt_tokenizer : failed test: 'I l0ve t0 tr@vel @r0und the w0rld.'
test_gpt_tokenizer : tokens in hf:   I(40),  l(300), 0(15), ve(303),  t(256), 0(15),  tr(491), @(31), vel(626),  @(2488), r(81), 0(15), und(917),  the(262),  w(266), 0(15), r(81), ld(335), .(13), 
test_gpt_tokenizer : tokens in ggml: I(40),  l(300), 0(15), ve(303),  t(256), 0(15),  tr(491), @(31), vel(626),  @(2488), r(81), 0(15), und(917),  the(262),  w(266), 0(15), rl(45895), d(67), .(13), 
test_gpt_tokenizer : failed test: 'She danced gracefully on the stage.'
test_gpt_tokenizer : tokens in hf:   She(3347),  danced(39480),  grace(11542), fully(2759),  on(319),  the(262),  stage(3800), .(13), 
test_gpt_tokenizer : tokens in ggml: She(3347),  danced(39480),  graceful(44363), ly(306),  on(319),  the(262),  stage(3800), .(13), 
test_gpt_tokenizer : failed test: 'She dances gracefully to the music.'
test_gpt_tokenizer : tokens in hf:   She(3347),  dances(38207),  grace(11542), fully(2759),  to(284),  the(262),  music(2647), .(13), 
test_gpt_tokenizer : tokens in ggml: She(3347),  dances(38207),  graceful(44363), ly(306),  to(284),  the(262),  music(2647), .(13), 
test_gpt_tokenizer : failed test: 'The birds are chirping in the trees.'
test_gpt_tokenizer : tokens in hf:   The(464),  birds(10087),  are(389),  ch(442), ir(343), ping(13886),  in(287),  the(262),  trees(7150), .(13), 
test_gpt_tokenizer : tokens in ggml: The(464),  birds(10087),  are(389),  chi(33166), r(81), ping(13886),  in(287),  the(262),  trees(7150), .(13), 
test_gpt_tokenizer : failed test: 'The flowers are blooming in the garden.'
test_gpt_tokenizer : tokens in hf:   The(464),  flowers(12734),  are(389),  blo(24924), oming(3383),  in(287),  the(262),  garden(11376), .(13), 
test_gpt_tokenizer : tokens in ggml: The(464),  flowers(12734),  are(389),  bloom(29955), ing(278),  in(287),  the(262),  garden(11376), .(13), 
test_gpt_tokenizer : failed test: 'The flowers in the garden are blooming.'
test_gpt_tokenizer : tokens in hf:   The(464),  flowers(12734),  in(287),  the(262),  garden(11376),  are(389),  blo(24924), oming(3383), .(13), 
test_gpt_tokenizer : tokens in ggml: The(464),  flowers(12734),  in(287),  the(262),  garden(11376),  are(389),  bloom(29955), ing(278), .(13), 
test_gpt_tokenizer : failed test: 'Wh@t's y0ur f@v0rite m0vie?'
test_gpt_tokenizer : tokens in hf:   Wh(1199), @(31), t(83), 's(338),  y(331), 0(15), ur(333),  f(277), @(31), v(85), 0(15), rite(6525),  m(285), 0(15), v(85), ie(494), ?(30), 
test_gpt_tokenizer : tokens in ggml: Wh(1199), @(31), t(83), 's(338),  y(331), 0(15), ur(333),  f(277), @(31), v(85), 0(15), rite(6525),  m(285), 0(15), vi(8903), e(68), ?(30), 
test_gpt_tokenizer : 7 tests failed out of 100 tests.
main: compute buffer size: 9.47 MB
main: seed = 1234
gpt2_model_load: loading model from '../models-mnt/gpt-2/ggml-model-gpt-2-117M.bin'
gpt2_model_load: n_vocab = 50257
gpt2_model_load: n_ctx   = 1024
gpt2_model_load: n_embd  = 768
gpt2_model_load: n_head  = 12
gpt2_model_load: n_layer = 12
gpt2_model_load: ftype   = 1
gpt2_model_load: qntvr   = 0
gpt2_model_load: ggml tensor size    = 336 bytes
gpt2_model_load: backend buffer size = 312.70 MB
gpt2_model_load: memory size =   144.00 MB, n_mem = 24576
gpt2_model_load: model size  =   239.08 MB
main: prompt: 'If'
main: number of tokens in prompt = 1, first 8 tokens: 1532 

If we look at what we're talking about and then look at the evidence and the evidence of the United States, what we're dealing with, we've got a huge problem in the world of terrorism."

Asked about the possibility that ISIS may have used the United States as a vehicle to recruit followers and commit violence in

main:     load time =   106.21 ms
main:   sample time =    26.36 ms
main:  predict time =   452.56 ms / 7.07 ms per token
main:    total time =   597.70 ms

real	0m0.607s
user	0m1.933s
sys	0m0.124s
+ ./bin/gpt-2-backend --model ../models-mnt/gpt-2/ggml-model-gpt-2-117M.bin -s 1234 -n 64 -p 'I believe the meaning of life is'
gpt2_model_load: using CPU backend
extract_tests_from_file : No test file found.
test_gpt_tokenizer : 0 tests failed out of 0 tests.
main: compute buffer size: 9.47 MB
main: seed = 1234
gpt2_model_load: loading model from '../models-mnt/gpt-2/ggml-model-gpt-2-117M.bin'
gpt2_model_load: n_vocab = 50257
gpt2_model_load: n_ctx   = 1024
gpt2_model_load: n_embd  = 768
gpt2_model_load: n_head  = 12
gpt2_model_load: n_layer = 12
gpt2_model_load: ftype   = 1
gpt2_model_load: qntvr   = 0
gpt2_model_load: ggml tensor size    = 336 bytes
gpt2_model_load: backend buffer size = 312.70 MB
gpt2_model_load: memory size =   144.00 MB, n_mem = 24576
gpt2_model_load: model size  =   239.08 MB
main: prompt: 'I believe the meaning of life is'
main: number of tokens in prompt = 7, first 8 tokens: 40 1975 262 3616 286 1204 318 

I believe the meaning of life is not one that you must be able to answer for.

If you do not believe in God, then why does his word make you feel better? Why do he make you feel better? It's because I don't think the gospel is true. It's because it's not true.

The gospel tells

main:     load time =   105.69 ms
main:   sample time =    26.88 ms
main:  predict time =   475.05 ms / 6.79 ms per token
main:    total time =   609.37 ms

real	0m0.618s
user	0m2.029s
sys	0m0.108s
+ ./bin/gpt-2-sched --model ../models-mnt/gpt-2/ggml-model-gpt-2-117M.bin -s 1234 -n 64 -p 'I believe the meaning of life is'
extract_tests_from_file : No test file found.
test_gpt_tokenizer : 0 tests failed out of 0 tests.
main: seed = 1234
gpt2_model_load: loading model from '../models-mnt/gpt-2/ggml-model-gpt-2-117M.bin'
gpt2_model_load: n_vocab = 50257
gpt2_model_load: n_ctx   = 1024
gpt2_model_load: n_embd  = 768
gpt2_model_load: n_head  = 12
gpt2_model_load: n_layer = 12
gpt2_model_load: ftype   = 1
gpt2_model_load: qntvr   = 0
gpt2_model_load:      CPU buffer size =   312.77 MB
gpt2_model_load: memory size =    72.00 MB, n_mem = 12288
gpt2_model_load: backend_kv = CPU
gpt2_model_load: model size  =   312.70 MB
gpt2_model_load: backend_in = CPU (8192 bytes)
main:      CPU compute buffer size =     6.32 MB
main: total compute buffer size: 6.32 MB
main: prompt: 'I believe the meaning of life is'
main: number of tokens in prompt = 7, first 8 tokens: 40 1975 262 3616 286 1204 318 

I believe the meaning of life is not one that you must be able to answer for.

If you do not believe in God, then why does his word make you feel better? Why do he make you feel better? It's because I don't think the gospel is true. It's because it's not true.

The gospel tells

main:     load time =   125.22 ms
main:   sample time =    27.03 ms
main:  predict time =   478.98 ms / 6.84 ms per token
main:    total time =   633.15 ms

real	0m0.642s
user	0m2.053s
sys	0m0.120s
+ ./bin/gpt-2-batched --model ../models-mnt/gpt-2/ggml-model-gpt-2-117M.bin -s 1234 -n 64 -np 8 -p 'I believe the meaning of life is'
gpt2_model_load: using CPU backend
extract_tests_from_file : No test file found.
test_gpt_tokenizer : 0 tests failed out of 0 tests.
main: compute buffer size: 6.93 MB
main: seed = 1234
gpt2_model_load: loading model from '../models-mnt/gpt-2/ggml-model-gpt-2-117M.bin'
gpt2_model_load: n_vocab = 50257
gpt2_model_load: n_ctx   = 1024
gpt2_model_load: n_embd  = 768
gpt2_model_load: n_head  = 12
gpt2_model_load: n_layer = 12
gpt2_model_load: ftype   = 1
gpt2_model_load: qntvr   = 0
gpt2_model_load: ggml tensor size    = 336 bytes
gpt2_model_load: backend buffer size = 312.82 MB
gpt2_model_load: memory size =   144.00 MB, n_mem = 24576
gpt2_model_load: model size  =   239.08 MB


main: generating 8 sequences ...
main: prompt: 'I believe the meaning of life is'
main: number of tokens in prompt = 7, first 8 tokens: 40 1975 262 3616 286 1204 318 


main: stream 0 finished at n_cur = 70
main: stream 1 finished at n_cur = 70
main: stream 2 finished at n_cur = 70
main: stream 3 finished at n_cur = 70
main: stream 4 finished at n_cur = 70
main: stream 5 finished at n_cur = 70
main: stream 6 finished at n_cur = 70
main: stream 7 finished at n_cur = 70
sequence 0:

I believe the meaning of life is not to be confused with life. It is to be understood as a system of thought. It is to be understood as a society. It is to be understood as a community. It is to be understood as a society in the sense that the idea of life, as something unique in itself, is central to our

sequence 1:

I believe the meaning of life is a matter of personal satisfaction.

A great philosopher, who was a well-known philosopher of the early part of the nineteenth century, believed that the meaning of life was a matter of personal satisfaction. His book, The Meaning of Life: A Guide to the Meaning of Life, came out in 1867,

sequence 2:

I believe the meaning of life is that it is not a complete mystery. The key is the understanding that life is not just a "time" but a continuous and interconnected experience.

This is an excerpt from a piece by Professor James Hansen and his team at the University of North Carolina at Chapel Hill in their article 'The Universe, Beyond the

sequence 3:

I believe the meaning of life is in the way we are going about it. The key is to be free, to be able to live free from fear."

That, as I saw it, was the ultimate message from the heart of my mother, a mother who came from a family of great people who had survived poverty and had been blessed

sequence 4:

I believe the meaning of life is one of love. We don't know who is love. And this is a paradox, because love is a thing of which you cannot be conscious. Love is a world. The world is your body. We don't know who is love. But we do know that a body can be one of us. And

sequence 5:

I believe the meaning of life is to die and die and die, and we must learn how to live. That is what we should do. We need to live in this world because it is a place that you don't have to live in and die in and die in.

I am going to say this to you, but I am

sequence 6:

I believe the meaning of life is to live without fear, so that you may be free from all thoughts, fears, thoughts, prejudices, and opinions, and be free from all thoughts, fears, thoughts, prejudices, and opinions.

I believe that people are not free from their own minds, but that they must be free from the ideas

sequence 7:

I believe the meaning of life is a gift for life." In a recent interview with The New York Times, I spoke to the author of the book, the former National Security Advisor to Donald Trump. (She is a Trump supporter.)

I spoke with her about her book, the Trump administration's decision to withdraw the United States from the Paris



main:     n_decoded =      504
main:     load time =   107.94 ms
main:   sample time =   184.28 ms
main:  predict time =  1567.15 ms
main:    total time =  1892.21 ms

real	0m1.901s
user	0m7.121s
sys	0m0.132s
```
### sam

Run SAM
- status: 0
```
+ ./bin/sam -m ../models-mnt/sam//ggml-model-f16.bin -i ../models-mnt/sam//img.jpg
main: seed = 1734074459
main: loaded image '../models-mnt/sam//img.jpg' (680 x 453)
sam_image_preprocess: scale = 0.664062
main: preprocessed image (1024 x 1024)
sam_model_load: loading model from '../models-mnt/sam//ggml-model-f16.bin' - please wait ...
operator(): ggml ctx size = 202.33 MB
sam_model_load: .sam_model_load: n_enc_state      = 768
sam_model_load: n_enc_layer      = 12
sam_model_load: n_enc_head       = 12
sam_model_load: n_enc_out_chans  = 256
sam_model_load: n_pt_embd        = 4
sam_model_load: ftype            = 1
sam_model_load: qntvr            = 0
..................................... done
sam_model_load: model size =   185.05 MB / num tensors = 304
prompt: (414.375000, 162.796875)


main:     load time =    65.88 ms
main:    total time = 10265.44 ms
embd_img
dims:  64  64  256  1 f32
First & Last 10 elements:
-0.05100 -0.06348 -0.07115 -0.06840 -0.06826 -0.06972 -0.07147 -0.07087 -0.06775 -0.05427 
0.01573 0.01768 0.02244 0.01667 0.01752 0.01667 0.01798 0.02048 0.02101 0.03391 
sum:  12757.182094

Skipping mask 0 with iou 0.705708 below threshold 0.880000
Skipping mask 1 with iou 0.762148 below threshold 0.880000
Mask 2: iou = 0.946984, stability_score = 0.956250, bbox (371, 436), (144, 168)

real	0m10.269s
user	0m40.160s
sys	0m0.532s
```
### yolo

Run YOLO
- status: 0
```
+ ./bin/yolov3-tiny -m yolov3-tiny.gguf -i ../models-mnt/yolo//dog.jpg
Layer  0 output shape:  416 x 416 x   16 x   1
Layer  1 output shape:  208 x 208 x   16 x   1
Layer  2 output shape:  208 x 208 x   32 x   1
Layer  3 output shape:  104 x 104 x   32 x   1
Layer  4 output shape:  104 x 104 x   64 x   1
Layer  5 output shape:   52 x  52 x   64 x   1
Layer  6 output shape:   52 x  52 x  128 x   1
Layer  7 output shape:   26 x  26 x  128 x   1
Layer  8 output shape:   26 x  26 x  256 x   1
Layer  9 output shape:   13 x  13 x  256 x   1
Layer 10 output shape:   13 x  13 x  512 x   1
Layer 11 output shape:   13 x  13 x  512 x   1
Layer 12 output shape:   13 x  13 x 1024 x   1
Layer 13 output shape:   13 x  13 x  256 x   1
Layer 14 output shape:   13 x  13 x  512 x   1
Layer 15 output shape:   13 x  13 x  255 x   1
Layer 18 output shape:   13 x  13 x  128 x   1
Layer 19 output shape:   26 x  26 x  128 x   1
Layer 20 output shape:   26 x  26 x  384 x   1
Layer 21 output shape:   26 x  26 x  256 x   1
Layer 22 output shape:   26 x  26 x  255 x   1
dog: 57%
car: 52%
truck: 56%
car: 62%
bicycle: 59%
Detected objects saved in 'predictions.jpg' (time: 0.174000 sec.)

real	0m0.227s
user	0m0.688s
sys	0m0.020s
```
