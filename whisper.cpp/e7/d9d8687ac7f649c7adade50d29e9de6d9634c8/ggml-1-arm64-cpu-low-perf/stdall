+ gg_run_ctest ctest debug
+ mode=debug
+ cd /home/ggml/work/whisper.cpp
+ rm -rf build-ci-debug
+ tee /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/ctest_debug.log
+ mkdir build-ci-debug
+ cd build-ci-debug
+ set -e
+ gg_check_build_requirements
+ command -v cmake
+ command -v make
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/ctest_debug-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=debug -DWHISPER_FATAL_WARNINGS=ON ..
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1") 
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- ccache found, compilation results will be cached. Disable with GGML_CCACHE=OFF.
-- CMAKE_SYSTEM_PROCESSOR: aarch64
-- Including CPU backend
-- Found OpenMP_C: -fopenmp (found version "4.5") 
-- Found OpenMP_CXX: -fopenmp (found version "4.5") 
-- Found OpenMP: TRUE (found version "4.5")  
-- ARM detected
-- Performing Test GGML_COMPILER_SUPPORTS_FP16_FORMAT_I3E
-- Performing Test GGML_COMPILER_SUPPORTS_FP16_FORMAT_I3E - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_dotprod
-- Performing Test GGML_MACHINE_SUPPORTS_dotprod - Success
-- Performing Test GGML_MACHINE_SUPPORTS_i8mm
-- Performing Test GGML_MACHINE_SUPPORTS_i8mm - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_noi8mm
-- Performing Test GGML_MACHINE_SUPPORTS_noi8mm - Success
-- Performing Test GGML_MACHINE_SUPPORTS_sve
-- Performing Test GGML_MACHINE_SUPPORTS_sve - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_nosve
-- Performing Test GGML_MACHINE_SUPPORTS_nosve - Success
-- Performing Test GGML_MACHINE_SUPPORTS_sme
-- Performing Test GGML_MACHINE_SUPPORTS_sme - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_nosme
-- Performing Test GGML_MACHINE_SUPPORTS_nosme - Failed
-- ARM feature DOTPROD enabled
-- ARM feature FMA enabled
-- ARM feature FP16_VECTOR_ARITHMETIC enabled
-- Adding CPU backend variant ggml-cpu: -mcpu=ares+crypto+noprofile+dotprod+noi8mm+nosve 
-- Configuring done
-- Generating done
-- Build files have been written to: /home/ggml/work/whisper.cpp/build-ci-debug

real	0m2.138s
user	0m1.378s
sys	0m0.559s
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/ctest_debug-make.log
++ nproc
+ make -j4
[  7%] Building CXX object examples/deprecation-warning/CMakeFiles/main.dir/deprecation-warning.cpp.o
[  7%] Building CXX object examples/deprecation-warning/CMakeFiles/stream.dir/deprecation-warning.cpp.o
[  7%] Building CXX object examples/deprecation-warning/CMakeFiles/bench.dir/deprecation-warning.cpp.o
[  9%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o
[ 16%] Linking CXX executable ../../bin/stream
[ 16%] Linking CXX executable ../../bin/main
[ 16%] Linking CXX executable ../../bin/bench
[ 19%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o
[ 21%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o
[ 23%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o
[ 26%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o
[ 26%] Built target main
[ 26%] Built target bench
[ 26%] Built target stream
[ 30%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o
[ 30%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o
[ 33%] Building CXX object examples/deprecation-warning/CMakeFiles/command.dir/deprecation-warning.cpp.o
[ 35%] Linking CXX shared library libggml-base.so
[ 38%] Linking CXX executable ../../bin/command
[ 38%] Built target command
[ 38%] Built target ggml-base
[ 47%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o
[ 47%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o
[ 47%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o
[ 47%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o
[ 50%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o
[ 52%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o
[ 57%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o
[ 57%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o
[ 59%] Linking CXX shared library libggml-cpu.so
[ 59%] Built target ggml-cpu
[ 61%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o
[ 64%] Linking CXX shared library libggml.so
[ 64%] Built target ggml
[ 66%] Building CXX object src/CMakeFiles/whisper.dir/whisper.cpp.o
[ 69%] Linking CXX shared library libwhisper.so
[ 69%] Built target whisper
[ 76%] Building CXX object examples/CMakeFiles/common.dir/common.cpp.o
[ 76%] Building CXX object examples/bench/CMakeFiles/whisper-bench.dir/bench.cpp.o
[ 76%] Building CXX object examples/CMakeFiles/common.dir/common-ggml.cpp.o
[ 78%] Building CXX object examples/CMakeFiles/common.dir/common-whisper.cpp.o
[ 80%] Linking CXX executable ../../bin/whisper-bench
[ 83%] Building CXX object examples/CMakeFiles/common.dir/grammar-parser.cpp.o
[ 85%] Linking CXX static library libcommon.a
[ 85%] Built target whisper-bench
[ 85%] Built target common
[ 92%] Building CXX object examples/quantize/CMakeFiles/quantize.dir/quantize.cpp.o
[ 92%] Building CXX object examples/server/CMakeFiles/whisper-server.dir/server.cpp.o
[ 92%] Building CXX object examples/cli/CMakeFiles/whisper-cli.dir/cli.cpp.o
[ 95%] Linking CXX executable ../../bin/whisper-cli
[ 97%] Linking CXX executable ../../bin/quantize
[100%] Linking CXX executable ../../bin/whisper-server
[100%] Built target quantize
[100%] Built target whisper-cli
[100%] Built target whisper-server

real	0m1.727s
user	0m2.086s
sys	0m0.952s
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/ctest_debug-ctest.log
+ ctest --output-on-failure -L main -E test-opt
Test project /home/ggml/work/whisper.cpp/build-ci-debug
No tests were found!!!

real	0m0.009s
user	0m0.005s
sys	0m0.004s
+ set +e
+ cur=0
+ echo 0
+ set +x
+ gg_run_ctest ctest release
+ mode=release
+ cd /home/ggml/work/whisper.cpp
+ rm -rf build-ci-release
+ tee /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/ctest_release.log
+ mkdir build-ci-release
+ cd build-ci-release
+ set -e
+ gg_check_build_requirements
+ command -v cmake
+ command -v make
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/ctest_release-cmake.log
+ cmake -DCMAKE_BUILD_TYPE=release -DWHISPER_FATAL_WARNINGS=ON ..
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1") 
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- ccache found, compilation results will be cached. Disable with GGML_CCACHE=OFF.
-- CMAKE_SYSTEM_PROCESSOR: aarch64
-- Including CPU backend
-- Found OpenMP_C: -fopenmp (found version "4.5") 
-- Found OpenMP_CXX: -fopenmp (found version "4.5") 
-- Found OpenMP: TRUE (found version "4.5")  
-- ARM detected
-- Performing Test GGML_COMPILER_SUPPORTS_FP16_FORMAT_I3E
-- Performing Test GGML_COMPILER_SUPPORTS_FP16_FORMAT_I3E - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_dotprod
-- Performing Test GGML_MACHINE_SUPPORTS_dotprod - Success
-- Performing Test GGML_MACHINE_SUPPORTS_i8mm
-- Performing Test GGML_MACHINE_SUPPORTS_i8mm - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_noi8mm
-- Performing Test GGML_MACHINE_SUPPORTS_noi8mm - Success
-- Performing Test GGML_MACHINE_SUPPORTS_sve
-- Performing Test GGML_MACHINE_SUPPORTS_sve - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_nosve
-- Performing Test GGML_MACHINE_SUPPORTS_nosve - Success
-- Performing Test GGML_MACHINE_SUPPORTS_sme
-- Performing Test GGML_MACHINE_SUPPORTS_sme - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_nosme
-- Performing Test GGML_MACHINE_SUPPORTS_nosme - Failed
-- ARM feature DOTPROD enabled
-- ARM feature FMA enabled
-- ARM feature FP16_VECTOR_ARITHMETIC enabled
-- Adding CPU backend variant ggml-cpu: -mcpu=ares+crypto+noprofile+dotprod+noi8mm+nosve 
-- Configuring done
-- Generating done
-- Build files have been written to: /home/ggml/work/whisper.cpp/build-ci-release

real	0m2.164s
user	0m1.323s
sys	0m0.612s
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/ctest_release-make.log
++ nproc
+ make -j4
[  9%] Building CXX object examples/deprecation-warning/CMakeFiles/main.dir/deprecation-warning.cpp.o
[  9%] Building CXX object examples/deprecation-warning/CMakeFiles/stream.dir/deprecation-warning.cpp.o
[  9%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o
[  9%] Building CXX object examples/deprecation-warning/CMakeFiles/bench.dir/deprecation-warning.cpp.o
[ 16%] Linking CXX executable ../../bin/stream
[ 16%] Linking CXX executable ../../bin/main
[ 16%] Linking CXX executable ../../bin/bench
[ 19%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o
[ 21%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o
[ 23%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o
[ 26%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o
[ 26%] Built target stream
[ 26%] Built target main
[ 26%] Built target bench
[ 28%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o
[ 30%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o
[ 33%] Building CXX object examples/deprecation-warning/CMakeFiles/command.dir/deprecation-warning.cpp.o
[ 35%] Linking CXX shared library libggml-base.so
[ 38%] Linking CXX executable ../../bin/command
[ 38%] Built target command
[ 38%] Built target ggml-base
[ 42%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o
[ 42%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o
[ 45%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o
[ 47%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o
[ 50%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o
[ 54%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o
[ 54%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o
[ 57%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o
[ 59%] Linking CXX shared library libggml-cpu.so
[ 59%] Built target ggml-cpu
[ 61%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o
[ 64%] Linking CXX shared library libggml.so
[ 64%] Built target ggml
[ 66%] Building CXX object src/CMakeFiles/whisper.dir/whisper.cpp.o
[ 69%] Linking CXX shared library libwhisper.so
[ 69%] Built target whisper
[ 76%] Building CXX object examples/CMakeFiles/common.dir/common-ggml.cpp.o
[ 76%] Building CXX object examples/CMakeFiles/common.dir/common-whisper.cpp.o
[ 76%] Building CXX object examples/CMakeFiles/common.dir/common.cpp.o
[ 78%] Building CXX object examples/bench/CMakeFiles/whisper-bench.dir/bench.cpp.o
[ 80%] Linking CXX executable ../../bin/whisper-bench
[ 83%] Building CXX object examples/CMakeFiles/common.dir/grammar-parser.cpp.o
[ 85%] Linking CXX static library libcommon.a
[ 85%] Built target common
[ 85%] Built target whisper-bench
[ 90%] Building CXX object examples/cli/CMakeFiles/whisper-cli.dir/cli.cpp.o
[ 90%] Building CXX object examples/server/CMakeFiles/whisper-server.dir/server.cpp.o
[ 92%] Building CXX object examples/quantize/CMakeFiles/quantize.dir/quantize.cpp.o
[ 95%] Linking CXX executable ../../bin/whisper-cli
[ 97%] Linking CXX executable ../../bin/quantize
[100%] Linking CXX executable ../../bin/whisper-server
[100%] Built target quantize
[100%] Built target whisper-cli
[100%] Built target whisper-server

real	0m0.979s
user	0m1.280s
sys	0m0.760s
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/ctest_release-ctest.log
+ ctest --output-on-failure -L main -E test-opt
Test project /home/ggml/work/whisper.cpp/build-ci-release
No tests were found!!!

real	0m0.010s
user	0m0.005s
sys	0m0.005s
+ set +e
+ cur=0
+ echo 0
+ set +x
+ gg_run_bench bench
+ tee /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench.log
+ cd /home/ggml/work/whisper.cpp
+ fattn=
+ '[' 0 -eq 1 ']'
+ '[' 0 -eq 0 ']'
+ echo 'Running memcpy benchmark'
+ ./build-ci-release/bin/whisper-bench -w 1 -t 4
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench-memcpy.log
Running memcpy benchmark
memcpy:   11.65 GB/s (heat-up)
memcpy:   11.60 GB/s ( 1 thread)
memcpy:   11.53 GB/s ( 1 thread)
memcpy:   21.94 GB/s ( 2 thread)
memcpy:   29.65 GB/s ( 3 thread)
memcpy:   35.54 GB/s ( 4 thread)
sum:    783359998994.000000

real	0m19.382s
user	0m19.499s
sys	0m3.832s
+ gg_check_last_command_status /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench-memcpy.exit 'memcpy benchmark'
+ local exit_file=/home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench-memcpy.exit
+ local 'command_name=memcpy benchmark'
+ local exit_status=0
+ echo 0
+ '[' 0 -ne 0 ']'
+ return 0
+ echo 'Running ggml_mul_mat benchmark with 4 threads'
Running ggml_mul_mat benchmark with 4 threads
+ ./build-ci-release/bin/whisper-bench -w 2 -t 4
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench-mul_mat.log
  64 x   64: Q4_0    28.6 GFLOPS (128 runs) | Q4_1    27.9 GFLOPS (128 runs)
  64 x   64: Q5_0    21.3 GFLOPS (128 runs) | Q5_1    20.4 GFLOPS (128 runs) | Q8_0    29.7 GFLOPS (128 runs)
  64 x   64: F16     31.7 GFLOPS (128 runs) | F32     34.3 GFLOPS (128 runs)
 128 x  128: Q4_0    55.8 GFLOPS (128 runs) | Q4_1    51.9 GFLOPS (128 runs)
 128 x  128: Q5_0    37.6 GFLOPS (128 runs) | Q5_1    34.3 GFLOPS (128 runs) | Q8_0    59.4 GFLOPS (128 runs)
 128 x  128: F16     66.0 GFLOPS (128 runs) | F32     55.4 GFLOPS (128 runs)
 256 x  256: Q4_0    72.6 GFLOPS (128 runs) | Q4_1    65.9 GFLOPS (128 runs)
 256 x  256: Q5_0    48.4 GFLOPS (128 runs) | Q5_1    43.4 GFLOPS (128 runs) | Q8_0    80.1 GFLOPS (128 runs)
 256 x  256: F16     97.1 GFLOPS (128 runs) | F32     65.5 GFLOPS (128 runs)
 512 x  512: Q4_0    81.0 GFLOPS (128 runs) | Q4_1    73.1 GFLOPS (128 runs)
 512 x  512: Q5_0    54.4 GFLOPS (128 runs) | Q5_1    48.8 GFLOPS (128 runs) | Q8_0    91.0 GFLOPS (128 runs)
 512 x  512: F16    107.9 GFLOPS (128 runs) | F32     65.9 GFLOPS (128 runs)
1024 x 1024: Q4_0    86.4 GFLOPS ( 41 runs) | Q4_1    77.1 GFLOPS ( 37 runs)
1024 x 1024: Q5_0    58.6 GFLOPS ( 28 runs) | Q5_1    52.0 GFLOPS ( 25 runs) | Q8_0    96.9 GFLOPS ( 46 runs)
1024 x 1024: F16    121.4 GFLOPS ( 57 runs) | F32     63.1 GFLOPS ( 30 runs)
2048 x 2048: Q4_0    89.6 GFLOPS (  6 runs) | Q4_1    80.3 GFLOPS (  5 runs)
2048 x 2048: Q5_0    60.8 GFLOPS (  4 runs) | Q5_1    53.7 GFLOPS (  4 runs) | Q8_0   101.5 GFLOPS (  6 runs)
2048 x 2048: F16    120.7 GFLOPS (  8 runs) | F32     54.9 GFLOPS (  4 runs)
4096 x 4096: Q4_0    90.8 GFLOPS (  3 runs) | Q4_1    81.3 GFLOPS (  3 runs)
4096 x 4096: Q5_0    60.9 GFLOPS (  3 runs) | Q5_1    53.6 GFLOPS (  3 runs) | Q8_0   100.1 GFLOPS (  3 runs)
4096 x 4096: F16    105.6 GFLOPS (  3 runs) | F32     49.5 GFLOPS (  3 runs)

real	1m15.165s
user	4m59.577s
sys	0m0.324s
+ gg_check_last_command_status /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench-mul_mat.exit 'ggml_mul_mat benchmark'
+ local exit_file=/home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench-mul_mat.exit
+ local 'command_name=ggml_mul_mat benchmark'
+ local exit_status=0
+ echo 0
+ '[' 0 -ne 0 ']'
+ return 0
+ echo 'Running benchmark for all models'
Running benchmark for all models
+ printf '| %16s | %13s | %3s | %3s | %7s | %7s | %7s | %7s | %7s |\n' Config Model Th FA Enc. Dec. Bch5 PP Commit
+ printf '| %16s | %13s | %3s | %3s | %7s | %7s | %7s | %7s | %7s |\n' --- --- --- --- --- --- --- --- ---
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench-models-table.log
|           Config |         Model |  Th |  FA |    Enc. |    Dec. |    Bch5 |      PP |  Commit |
|              --- |           --- | --- | --- |     --- |     --- |     --- |     --- |     --- |
+ for model in "${MODELS[@]}"
+ echo 'Benchmarking model: tiny'
Benchmarking model: tiny
++ ./build-ci-release/bin/whisper-bench -m /mnt/whisper.cpp/models/ggml-tiny.bin -t 4
+ output='whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-tiny.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.19 MB
whisper_init_state: compute buffer (encode) =   64.79 MB
whisper_init_state: compute buffer (cross)  =    3.88 MB
whisper_init_state: compute buffer (decode) =   95.89 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =    73.81 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =   553.89 ms /     1 runs (  553.89 ms per run)
whisper_print_timings:   decode time =   554.74 ms /   256 runs (    2.17 ms per run)
whisper_print_timings:   batchd time =   345.40 ms /   320 runs (    1.08 ms per run)
whisper_print_timings:   prompt time =  3283.30 ms /  4096 runs (    0.80 ms per run)
whisper_print_timings:    total time =  4738.64 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
+ ret=0
+ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-tiny.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.19 MB
whisper_init_state: compute buffer (encode) =   64.79 MB
whisper_init_state: compute buffer (cross)  =    3.88 MB
whisper_init_state: compute buffer (decode) =   95.89 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =    73.81 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =   553.89 ms /     1 runs (  553.89 ms per run)
whisper_print_timings:   decode time =   554.74 ms /   256 runs (    2.17 ms per run)
whisper_print_timings:   batchd time =   345.40 ms /   320 runs (    1.08 ms per run)
whisper_print_timings:   prompt time =  3283.30 ms /  4096 runs (    0.80 ms per run)
whisper_print_timings:    total time =  4738.64 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
+ '[' 0 -eq 0 ']'
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-tiny.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.19 MB
whisper_init_state: compute buffer (encode) =   64.79 MB
whisper_init_state: compute buffer (cross)  =    3.88 MB
whisper_init_state: compute buffer (decode) =   95.89 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =    73.81 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =   553.89 ms /     1 runs (  553.89 ms per run)
whisper_print_timings:   decode time =   554.74 ms /   256 runs (    2.17 ms per run)
whisper_print_timings:   batchd time =   345.40 ms /   320 runs (    1.08 ms per run)
whisper_print_timings:   prompt time =  3283.30 ms /  4096 runs (    0.80 ms per run)
whisper_print_timings:    total time =  4738.64 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'encode time'
++ awk '{print $11}'
+ encode_time=553.89
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-tiny.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.19 MB
whisper_init_state: compute buffer (encode) =   64.79 MB
whisper_init_state: compute buffer (cross)  =    3.88 MB
whisper_init_state: compute buffer (decode) =   95.89 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =    73.81 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =   553.89 ms /     1 runs (  553.89 ms per run)
whisper_print_timings:   decode time =   554.74 ms /   256 runs (    2.17 ms per run)
whisper_print_timings:   batchd time =   345.40 ms /   320 runs (    1.08 ms per run)
whisper_print_timings:   prompt time =  3283.30 ms /  4096 runs (    0.80 ms per run)
whisper_print_timings:    total time =  4738.64 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'decode time'
++ awk '{print $11}'
+ decode_time=2.17
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-tiny.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.19 MB
whisper_init_state: compute buffer (encode) =   64.79 MB
whisper_init_state: compute buffer (cross)  =    3.88 MB
whisper_init_state: compute buffer (decode) =   95.89 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =    73.81 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =   553.89 ms /     1 runs (  553.89 ms per run)
whisper_print_timings:   decode time =   554.74 ms /   256 runs (    2.17 ms per run)
whisper_print_timings:   batchd time =   345.40 ms /   320 runs (    1.08 ms per run)
whisper_print_timings:   prompt time =  3283.30 ms /  4096 runs (    0.80 ms per run)
whisper_print_timings:    total time =  4738.64 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'batchd time'
++ awk '{print $11}'
+ batchd_time=1.08
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-tiny.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.19 MB
whisper_init_state: compute buffer (encode) =   64.79 MB
whisper_init_state: compute buffer (cross)  =    3.88 MB
whisper_init_state: compute buffer (decode) =   95.89 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =    73.81 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =   553.89 ms /     1 runs (  553.89 ms per run)
whisper_print_timings:   decode time =   554.74 ms /   256 runs (    2.17 ms per run)
whisper_print_timings:   batchd time =   345.40 ms /   320 runs (    1.08 ms per run)
whisper_print_timings:   prompt time =  3283.30 ms /  4096 runs (    0.80 ms per run)
whisper_print_timings:    total time =  4738.64 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'prompt time'
++ awk '{print $11}'
+ prompt_time=0.80
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-tiny.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.19 MB
whisper_init_state: compute buffer (encode) =   64.79 MB
whisper_init_state: compute buffer (cross)  =    3.88 MB
whisper_init_state: compute buffer (decode) =   95.89 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =    73.81 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =   553.89 ms /     1 runs (  553.89 ms per run)
whisper_print_timings:   decode time =   554.74 ms /   256 runs (    2.17 ms per run)
whisper_print_timings:   batchd time =   345.40 ms /   320 runs (    1.08 ms per run)
whisper_print_timings:   prompt time =  3283.30 ms /  4096 runs (    0.80 ms per run)
whisper_print_timings:    total time =  4738.64 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep system_info
+ system_info='system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | '
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-tiny.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.19 MB
whisper_init_state: compute buffer (encode) =   64.79 MB
whisper_init_state: compute buffer (cross)  =    3.88 MB
whisper_init_state: compute buffer (decode) =   95.89 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =    73.81 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =   553.89 ms /     1 runs (  553.89 ms per run)
whisper_print_timings:   decode time =   554.74 ms /   256 runs (    2.17 ms per run)
whisper_print_timings:   batchd time =   345.40 ms /   320 runs (    1.08 ms per run)
whisper_print_timings:   prompt time =  3283.30 ms /  4096 runs (    0.80 ms per run)
whisper_print_timings:    total time =  4738.64 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep system_info
++ awk '{print $4}'
+ actual_threads=4
+ config=
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\A\V\X\2\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\N\E\O\N\ \=\ \1* ]]
+ config=' NEON'
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\B\L\A\S\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\C\O\R\E\M\L\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\C\U\D\A\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\M\E\T\A\L\ \=\ \1* ]]
++ git rev-parse --short HEAD
+ commit=e7d9d86
+ printf '| %16s | %13s | %3s | %3s | %7s | %7s | %7s | %7s | %7s |\n' ' NEON' tiny 4 0 553.89 2.17 1.08 0.80 e7d9d86
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench-models-table.log
|             NEON |          tiny |   4 |   0 |  553.89 |    2.17 |    1.08 |    0.80 | e7d9d86 |
+ for model in "${MODELS[@]}"
+ echo 'Benchmarking model: base'
Benchmarking model: base
++ ./build-ci-release/bin/whisper-bench -m /mnt/whisper.cpp/models/ggml-base.bin -t 4
+ output='whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-base.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.26 MB
whisper_init_state: compute buffer (encode) =   85.86 MB
whisper_init_state: compute buffer (cross)  =    4.65 MB
whisper_init_state: compute buffer (decode) =   96.35 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   103.90 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  1248.32 ms /     1 runs ( 1248.32 ms per run)
whisper_print_timings:   decode time =  1134.14 ms /   256 runs (    4.43 ms per run)
whisper_print_timings:   batchd time =   629.13 ms /   320 runs (    1.97 ms per run)
whisper_print_timings:   prompt time =  5735.60 ms /  4096 runs (    1.40 ms per run)
whisper_print_timings:    total time =  8748.74 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
+ ret=0
+ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-base.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.26 MB
whisper_init_state: compute buffer (encode) =   85.86 MB
whisper_init_state: compute buffer (cross)  =    4.65 MB
whisper_init_state: compute buffer (decode) =   96.35 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   103.90 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  1248.32 ms /     1 runs ( 1248.32 ms per run)
whisper_print_timings:   decode time =  1134.14 ms /   256 runs (    4.43 ms per run)
whisper_print_timings:   batchd time =   629.13 ms /   320 runs (    1.97 ms per run)
whisper_print_timings:   prompt time =  5735.60 ms /  4096 runs (    1.40 ms per run)
whisper_print_timings:    total time =  8748.74 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
+ '[' 0 -eq 0 ']'
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-base.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.26 MB
whisper_init_state: compute buffer (encode) =   85.86 MB
whisper_init_state: compute buffer (cross)  =    4.65 MB
whisper_init_state: compute buffer (decode) =   96.35 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   103.90 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  1248.32 ms /     1 runs ( 1248.32 ms per run)
whisper_print_timings:   decode time =  1134.14 ms /   256 runs (    4.43 ms per run)
whisper_print_timings:   batchd time =   629.13 ms /   320 runs (    1.97 ms per run)
whisper_print_timings:   prompt time =  5735.60 ms /  4096 runs (    1.40 ms per run)
whisper_print_timings:    total time =  8748.74 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'encode time'
++ awk '{print $11}'
+ encode_time=1248.32
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-base.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.26 MB
whisper_init_state: compute buffer (encode) =   85.86 MB
whisper_init_state: compute buffer (cross)  =    4.65 MB
whisper_init_state: compute buffer (decode) =   96.35 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   103.90 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  1248.32 ms /     1 runs ( 1248.32 ms per run)
whisper_print_timings:   decode time =  1134.14 ms /   256 runs (    4.43 ms per run)
whisper_print_timings:   batchd time =   629.13 ms /   320 runs (    1.97 ms per run)
whisper_print_timings:   prompt time =  5735.60 ms /  4096 runs (    1.40 ms per run)
whisper_print_timings:    total time =  8748.74 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'decode time'
++ awk '{print $11}'
+ decode_time=4.43
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-base.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.26 MB
whisper_init_state: compute buffer (encode) =   85.86 MB
whisper_init_state: compute buffer (cross)  =    4.65 MB
whisper_init_state: compute buffer (decode) =   96.35 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   103.90 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  1248.32 ms /     1 runs ( 1248.32 ms per run)
whisper_print_timings:   decode time =  1134.14 ms /   256 runs (    4.43 ms per run)
whisper_print_timings:   batchd time =   629.13 ms /   320 runs (    1.97 ms per run)
whisper_print_timings:   prompt time =  5735.60 ms /  4096 runs (    1.40 ms per run)
whisper_print_timings:    total time =  8748.74 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'batchd time'
++ awk '{print $11}'
+ batchd_time=1.97
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-base.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.26 MB
whisper_init_state: compute buffer (encode) =   85.86 MB
whisper_init_state: compute buffer (cross)  =    4.65 MB
whisper_init_state: compute buffer (decode) =   96.35 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   103.90 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  1248.32 ms /     1 runs ( 1248.32 ms per run)
whisper_print_timings:   decode time =  1134.14 ms /   256 runs (    4.43 ms per run)
whisper_print_timings:   batchd time =   629.13 ms /   320 runs (    1.97 ms per run)
whisper_print_timings:   prompt time =  5735.60 ms /  4096 runs (    1.40 ms per run)
whisper_print_timings:    total time =  8748.74 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'prompt time'
++ awk '{print $11}'
+ prompt_time=1.40
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-base.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.26 MB
whisper_init_state: compute buffer (encode) =   85.86 MB
whisper_init_state: compute buffer (cross)  =    4.65 MB
whisper_init_state: compute buffer (decode) =   96.35 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   103.90 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  1248.32 ms /     1 runs ( 1248.32 ms per run)
whisper_print_timings:   decode time =  1134.14 ms /   256 runs (    4.43 ms per run)
whisper_print_timings:   batchd time =   629.13 ms /   320 runs (    1.97 ms per run)
whisper_print_timings:   prompt time =  5735.60 ms /  4096 runs (    1.40 ms per run)
whisper_print_timings:    total time =  8748.74 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep system_info
+ system_info='system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | '
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-base.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.26 MB
whisper_init_state: compute buffer (encode) =   85.86 MB
whisper_init_state: compute buffer (cross)  =    4.65 MB
whisper_init_state: compute buffer (decode) =   96.35 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   103.90 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  1248.32 ms /     1 runs ( 1248.32 ms per run)
whisper_print_timings:   decode time =  1134.14 ms /   256 runs (    4.43 ms per run)
whisper_print_timings:   batchd time =   629.13 ms /   320 runs (    1.97 ms per run)
whisper_print_timings:   prompt time =  5735.60 ms /  4096 runs (    1.40 ms per run)
whisper_print_timings:    total time =  8748.74 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep system_info
++ awk '{print $4}'
+ actual_threads=4
+ config=
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\A\V\X\2\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\N\E\O\N\ \=\ \1* ]]
+ config=' NEON'
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\B\L\A\S\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\C\O\R\E\M\L\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\C\U\D\A\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\M\E\T\A\L\ \=\ \1* ]]
++ git rev-parse --short HEAD
+ commit=e7d9d86
+ printf '| %16s | %13s | %3s | %3s | %7s | %7s | %7s | %7s | %7s |\n' ' NEON' base 4 0 1248.32 4.43 1.97 1.40 e7d9d86
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench-models-table.log
|             NEON |          base |   4 |   0 | 1248.32 |    4.43 |    1.97 |    1.40 | e7d9d86 |
+ for model in "${MODELS[@]}"
+ echo 'Benchmarking model: small'
Benchmarking model: small
++ ./build-ci-release/bin/whisper-bench -m /mnt/whisper.cpp/models/ggml-small.bin -t 4
+ output='whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-small.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.41 MB
whisper_init_state: compute buffer (encode) =  128.01 MB
whisper_init_state: compute buffer (cross)  =    6.18 MB
whisper_init_state: compute buffer (decode) =   97.27 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   255.08 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  4464.80 ms /     1 runs ( 4464.80 ms per run)
whisper_print_timings:   decode time =  3250.95 ms /   256 runs (   12.70 ms per run)
whisper_print_timings:   batchd time =  1779.74 ms /   320 runs (    5.56 ms per run)
whisper_print_timings:   prompt time = 15746.24 ms /  4096 runs (    3.84 ms per run)
whisper_print_timings:    total time = 25243.34 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
+ ret=0
+ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-small.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.41 MB
whisper_init_state: compute buffer (encode) =  128.01 MB
whisper_init_state: compute buffer (cross)  =    6.18 MB
whisper_init_state: compute buffer (decode) =   97.27 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   255.08 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  4464.80 ms /     1 runs ( 4464.80 ms per run)
whisper_print_timings:   decode time =  3250.95 ms /   256 runs (   12.70 ms per run)
whisper_print_timings:   batchd time =  1779.74 ms /   320 runs (    5.56 ms per run)
whisper_print_timings:   prompt time = 15746.24 ms /  4096 runs (    3.84 ms per run)
whisper_print_timings:    total time = 25243.34 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
+ '[' 0 -eq 0 ']'
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-small.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.41 MB
whisper_init_state: compute buffer (encode) =  128.01 MB
whisper_init_state: compute buffer (cross)  =    6.18 MB
whisper_init_state: compute buffer (decode) =   97.27 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   255.08 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  4464.80 ms /     1 runs ( 4464.80 ms per run)
whisper_print_timings:   decode time =  3250.95 ms /   256 runs (   12.70 ms per run)
whisper_print_timings:   batchd time =  1779.74 ms /   320 runs (    5.56 ms per run)
whisper_print_timings:   prompt time = 15746.24 ms /  4096 runs (    3.84 ms per run)
whisper_print_timings:    total time = 25243.34 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'encode time'
++ awk '{print $11}'
+ encode_time=4464.80
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-small.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.41 MB
whisper_init_state: compute buffer (encode) =  128.01 MB
whisper_init_state: compute buffer (cross)  =    6.18 MB
whisper_init_state: compute buffer (decode) =   97.27 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   255.08 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  4464.80 ms /     1 runs ( 4464.80 ms per run)
whisper_print_timings:   decode time =  3250.95 ms /   256 runs (   12.70 ms per run)
whisper_print_timings:   batchd time =  1779.74 ms /   320 runs (    5.56 ms per run)
whisper_print_timings:   prompt time = 15746.24 ms /  4096 runs (    3.84 ms per run)
whisper_print_timings:    total time = 25243.34 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'decode time'
++ awk '{print $11}'
+ decode_time=12.70
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-small.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.41 MB
whisper_init_state: compute buffer (encode) =  128.01 MB
whisper_init_state: compute buffer (cross)  =    6.18 MB
whisper_init_state: compute buffer (decode) =   97.27 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   255.08 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  4464.80 ms /     1 runs ( 4464.80 ms per run)
whisper_print_timings:   decode time =  3250.95 ms /   256 runs (   12.70 ms per run)
whisper_print_timings:   batchd time =  1779.74 ms /   320 runs (    5.56 ms per run)
whisper_print_timings:   prompt time = 15746.24 ms /  4096 runs (    3.84 ms per run)
whisper_print_timings:    total time = 25243.34 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'batchd time'
++ awk '{print $11}'
+ batchd_time=5.56
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-small.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.41 MB
whisper_init_state: compute buffer (encode) =  128.01 MB
whisper_init_state: compute buffer (cross)  =    6.18 MB
whisper_init_state: compute buffer (decode) =   97.27 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   255.08 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  4464.80 ms /     1 runs ( 4464.80 ms per run)
whisper_print_timings:   decode time =  3250.95 ms /   256 runs (   12.70 ms per run)
whisper_print_timings:   batchd time =  1779.74 ms /   320 runs (    5.56 ms per run)
whisper_print_timings:   prompt time = 15746.24 ms /  4096 runs (    3.84 ms per run)
whisper_print_timings:    total time = 25243.34 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep 'prompt time'
++ awk '{print $11}'
+ prompt_time=3.84
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-small.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.41 MB
whisper_init_state: compute buffer (encode) =  128.01 MB
whisper_init_state: compute buffer (cross)  =    6.18 MB
whisper_init_state: compute buffer (decode) =   97.27 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   255.08 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  4464.80 ms /     1 runs ( 4464.80 ms per run)
whisper_print_timings:   decode time =  3250.95 ms /   256 runs (   12.70 ms per run)
whisper_print_timings:   batchd time =  1779.74 ms /   320 runs (    5.56 ms per run)
whisper_print_timings:   prompt time = 15746.24 ms /  4096 runs (    3.84 ms per run)
whisper_print_timings:    total time = 25243.34 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep system_info
+ system_info='system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | '
++ echo 'whisper_init_from_file_with_params_no_state: loading model from '\''/mnt/whisper.cpp/models/ggml-small.bin'\''
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 0
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
whisper_init_with_params_no_state: devices    = 1
whisper_init_with_params_no_state: backends   = 1
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:      CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.41 MB
whisper_init_state: compute buffer (encode) =  128.01 MB
whisper_init_state: compute buffer (cross)  =    6.18 MB
whisper_init_state: compute buffer (decode) =   97.27 MB

system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | 

whisper_print_timings:     load time =   255.08 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =     0.00 ms
whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)
whisper_print_timings:   encode time =  4464.80 ms /     1 runs ( 4464.80 ms per run)
whisper_print_timings:   decode time =  3250.95 ms /   256 runs (   12.70 ms per run)
whisper_print_timings:   batchd time =  1779.74 ms /   320 runs (    5.56 ms per run)
whisper_print_timings:   prompt time = 15746.24 ms /  4096 runs (    3.84 ms per run)
whisper_print_timings:    total time = 25243.34 ms

If you wish, you can submit these results here:

  https://github.com/ggerganov/whisper.cpp/issues/89

Please include the following information:

  - CPU model
  - Operating system
  - Compiler'
++ grep system_info
++ awk '{print $4}'
+ actual_threads=4
+ config=
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\A\V\X\2\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\N\E\O\N\ \=\ \1* ]]
+ config=' NEON'
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\B\L\A\S\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\C\O\R\E\M\L\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\C\U\D\A\ \=\ \1* ]]
+ [[ system_info: n_threads = 4 / 4 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |  == *\M\E\T\A\L\ \=\ \1* ]]
++ git rev-parse --short HEAD
+ commit=e7d9d86
+ printf '| %16s | %13s | %3s | %3s | %7s | %7s | %7s | %7s | %7s |\n' ' NEON' small 4 0 4464.80 12.70 5.56 3.84 e7d9d86
+ tee -a /home/ggml/results/whisper.cpp/e7/d9d8687ac7f649c7adade50d29e9de6d9634c8/ggml-1-arm64-cpu-low-perf/bench-models-table.log
|             NEON |         small |   4 |   0 | 4464.80 |   12.70 |    5.56 |    3.84 | e7d9d86 |
+ cur=0
+ echo 0
+ set +x
